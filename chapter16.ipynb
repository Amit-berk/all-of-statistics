{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Inference about Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter addresses two questions:\n",
    "\n",
    "1. How do we test if two random variables are independent?\n",
    "2. How do we estimate the strength of dependence between two random variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall we write $Y \\text{ ⫫ } Z$ to mean that $Y$ and $Z$ are independent.\n",
    "\n",
    "When $Y$ and $Z$ are not independent, we say they are **dependent** or **associated** or **related**.\n",
    "\n",
    "Note that dependence does not mean causation:\n",
    "- Smoking is related to heart disease, and quitting smoking will reduce the chance of heart disease.\n",
    "- Owning a TV is related to lower starvation, but giving a starving person a TV does not make them not hungry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.1 Two Binary Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that both $Y$ and $Z$ are binary.  Consider a data set $(Y_1, Z_1), \\dots, (Y_n, Z_n)$.  Represent the data as a two-by-two table:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc|c} \n",
    "      & Y = 0  & Y = 1 & \\\\\n",
    "\\hline\n",
    "Z = 0 & X_{00} & X_{01} & X_{0\\text{·}}\\\\\n",
    "Z = 1 & X_{10} & X_{11} & X_{1\\text{·}}\\\\\n",
    " \\hline\n",
    "      & X_{\\text{·}0} & X_{\\text{·}1} & n = X_{\\text{··}}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $X_{ij}$ represents the number of observations where $(Z_k, Y_k) = (i, j)$.  The dotted subscripts denote sums, e.g. $X_{i\\text{·}} = \\sum_j X_{ij}$.  Denote the corresponding probabilities by:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc|c} \n",
    "      & Y = 0  & Y = 1 & \\\\\n",
    "\\hline\n",
    "Z = 0 & p_{00} & p_{01} & p_{0\\text{·}}\\\\\n",
    "Z = 1 & p_{10} & p_{11} & p_{1\\text{·}}\\\\\n",
    " \\hline\n",
    "      & p_{\\text{·}0} & p_{\\text{·}1} & 1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $p_{ij} = \\mathbb{P}(Z = i, Y = j)$.  Let $X = (X_{00}, X_{01}, X_{10}, X_{11})$ denote the vector of counts.  Then $X \\sim \\text{Multinomial}(n, p)$ where $p = (p_{00}, p_{01}, p_{10}, p_{11})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **odds ratio** is defined to be\n",
    "\n",
    "$$ \\psi = \\frac{p_{00} p_{11}}{p_{01} p_{10}}$$\n",
    "\n",
    "The **log odds ratio** is defined to be\n",
    "\n",
    "$$ \\gamma = \\log \\psi$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 16.2**.  The following statements are equivalent:\n",
    "\n",
    "1. $Y \\text{ ⫫ } Z$\n",
    "2. $\\psi = 1$\n",
    "3. $\\gamma = 0$\n",
    "4. For $i, j \\in \\{ 0, 1 \\}$, $p_{ij} = p_{i\\text{·}} p_{\\text{·}j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider testing\n",
    "\n",
    "$$\n",
    "H_0: Y \\text{ ⫫ } Z\n",
    "\\quad \\text{versus} \\quad\n",
    "H_1: \\text{not} (Y \\text{ ⫫ } Z)\n",
    "$$\n",
    "\n",
    "First consider the likelihood ratio test.  Under $H_1$, $X \\sim \\text{Multinomial}(n, p)$ and the MLE is $\\hat{p} = X / n$.  Under $H_0$, again $X \\sim \\text{Multinomial}(n, p)$ but $p$ is subjected to the constraint $p_{ij} = p_{i.} p_{.j}$.  This leads to the following test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 16.3 (Likelihood Ratio Test for Independence in a 2-by-2 table)**. \n",
    "Let\n",
    "\n",
    "$$ T = 2 \\sum_{i=0}^1 \\sum_{j=0}^1 X_{ij} \\log \\left( \\frac{X_{ij} X_{\\text{··}}}{X_{i\\text{·}} X_{\\text{·}j}} \\right)$$\n",
    "\n",
    "Under $H_0$, $T \\leadsto \\chi_1^2$.  Thus, an approximate level $\\alpha$ test is obtained by rejecting $H_0$ when $T > \\chi_{1, \\alpha}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 16.4 (Pearson's $\\chi^2$ test for Independence in a 2-by-2 table)**. Let\n",
    "\n",
    "$$ U = \\sum_{i=0}^1 \\sum_{j=0}^1 \\frac{(X_{ij} - E_{ij})^2}{E_{ij}} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ E_{ij} = \\frac{X_{i\\text{·}} X_{\\text{·}j}}{n}$$\n",
    "\n",
    "Under $H_0$, $U \\leadsto \\chi_1^2$.  Thus, an approximate level $\\alpha$ test is obtained by rejecting $H_0$ when $U > \\chi_{1, \\alpha}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the intuition for the Pearson test: Under $H_0$, $p_{ij} = p_{i\\text{·}} p_{\\text{·}j}$, so the MLE of $p_{ij}$ is $\\hat{p}_{ij} = \\hat{p}_{i\\text{·}} \\hat{p}_{\\text{·}j} = \\frac{X_{i\\text{·}}}{n} \\frac{X_{\\text{·}j}}{n}$.  Thus, the expected number of observations in the $(i, j)$ cell is $E_{ij} = n \\hat{p}_{ij} = \\frac{X_{i\\text{·}} X_{\\text{·}j}}{n}$.  The statistic $U$ compares the observed and expected counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 16.6**. The MLE's of $\\psi$ and $\\gamma$ are\n",
    "\n",
    "$$\n",
    "\\hat{\\psi} = \\frac{X_{00} X_{11}}{X_{01} X_{10}}\n",
    ", \\quad\n",
    "\\hat{\\gamma} = \\log \\hat{\\psi}\n",
    "$$\n",
    "\n",
    "The asymptotic standard errors (computed from the delta method) are\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\text{se}}(\\hat{\\psi}) &= \\sqrt{\\frac{1}{X_{00}} + \\frac{1}{X_{01}} + \\frac{1}{X_{10}} + \\frac{1}{X_{11}}}\\\\\n",
    "\\hat{\\text{se}}(\\hat{\\gamma}) &= \\hat{\\psi} \\hat{\\text{se}}(\\hat{\\gamma})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another test of independence is the Wald test for $\\gamma = 0$ given by $W = (\\hat{\\gamma} - 0) / \\hat{\\text{se}}(\\hat{\\gamma})$. \n",
    "\n",
    "A $1 - \\alpha$ confidence interval for $\\gamma$ is $\\hat{\\gamma} \\pm z_{\\alpha/2} \\hat{\\text{se}}(\\hat{\\gamma})$.\n",
    "\n",
    "A $1 - \\alpha$ confidence interval for $\\psi$ can be obtained in two ways.  First, we could use $\\hat{\\psi} \\pm z_{\\alpha/2} \\hat{\\text{se}}(\\hat{\\psi})$.  Second, since $\\psi = e^{\\gamma}$ we could use  $\\exp \\{\\hat{\\gamma} \\pm z_{\\alpha/2} \\hat{\\text{se}}(\\hat{\\gamma})\\}$.  This second method is usually more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.2 Interpreting the Odds Ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose event $A$ has probability $\\mathbb{P}(A)$.  The odds of $A$ are defined as\n",
    "\n",
    "$$\\text{odds}(A) = \\frac{\\mathbb{P}(A)}{1 - \\mathbb{P}(A)}$$\n",
    "\n",
    "It follows that\n",
    "\n",
    "$$\\mathbb{P}(A) = \\frac{\\text{odds}(A)}{1 + \\text{odds}(A)}$$\n",
    "\n",
    "Let $E$ be the event that someone is exposed to something (smoking, radiation, etc) and let $D$ be the event that they get a disease.  The odds of getting the disease given exposure are:\n",
    "\n",
    "$$\\text{odds}(D | E) = \\frac{\\mathbb{P}(D | E)}{1 - \\mathbb{P}(D | E)}$$\n",
    "\n",
    "and the odds of getting the disease given non-exposure are:\n",
    "\n",
    "$$\\text{odds}(D | E^c) = \\frac{\\mathbb{P}(D | E^c)}{1 - \\mathbb{P}(D | E^c)}$$\n",
    "\n",
    "The **odds ratio** is defined to be\n",
    "\n",
    "$$\\psi = \\frac{\\text{odds}(D | E)}{\\text{odds}(D | E^c)}$$\n",
    "\n",
    "If $\\psi = 1$ then the disease probability is the same for exposed and unexposed; this implies these events are independent.  Recall that the log-odds ratio is defined as $\\gamma = \\log \\psi$.  Independence corresponds to $\\gamma = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider this table of probabilities:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc|c} \n",
    "      & D^c    & D      & \\\\\n",
    "\\hline\n",
    "E^c   & p_{00} & p_{01} & p_{0\\text{·}}\\\\\n",
    "E     & p_{10} & p_{11} & p_{1\\text{·}}\\\\\n",
    " \\hline\n",
    "      & p_{\\text{·}0} & p_{\\text{·}1} & 1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Denote the data by\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc|c} \n",
    "      & D^c    & D      & \\\\\n",
    "\\hline\n",
    "E^c   & X_{00} & X_{01} & X_{0\\text{·}}\\\\\n",
    "E     & X_{10} & X_{11} & X_{1\\text{·}}\\\\\n",
    " \\hline\n",
    "      & X_{\\text{·}0} & X_{\\text{·}1} & X_{\\text{··}}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Now\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(D | E) = \\frac{p_{11}}{p_{10} + p_{11}}\n",
    "\\quad \\text{and} \\quad\n",
    "\\mathbb{P}(D | E^c) = \\frac{p_{01}}{p_{00} + p_{01}}\n",
    "$$\n",
    "\n",
    "and so\n",
    "\n",
    "$$\n",
    "\\text{odds}(D | E) = \\frac{p_{11}}{p_{10}}\n",
    "\\quad \\text{and} \\quad\n",
    "\\text{odds}(D | E^c) = \\frac{p_{01}}{p_{00}}\n",
    "$$\n",
    "\n",
    "and therefore\n",
    "\n",
    "$$ \\psi = \\frac{p_{11}p_{00}}{p_{01}p_{10}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the parameters, we have to consider how the data were collected.  There are three methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial Sampling**.  We draw a sample from the population and, for each sample, record their exposure and disease status.  In this case, $X = (X_{00}, X_{01}, X_{10}, X_{11}) \\sim \\text{Multinomial}(n, p)$.  We then estimates the probabilities in the table by $\\hat{p}_{ij$ = X_{ij} / n$ and\n",
    "\n",
    "$$ \\hat{\\psi} = \\frac{\\hat{p}_{11} \\hat{p}_{00}}{\\hat{p}_{01} \\hat{p}_{10}} = \\frac{X_{11} X_{00}}{X_{01} X_{10}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prospective Sampling (Cohort Sampling)**.  We get some exposed and unexposed people and count the number with disease within each group.  Thus,\n",
    "\n",
    "$$\n",
    "X_{01} \\sim \\text{Binomial}(X_{0\\text{·}}, \\mathbb{P}(D | E^c))\n",
    "\\quad \\text{and} \\quad\n",
    "X_{11} \\sim \\text{Binomial}(X_{1\\text{·}}, \\mathbb{P}(D | E))\n",
    "$$\n",
    "\n",
    "In this case we should write small letters $x_{0\\text{·}},  x_{1\\text{·}}$ instead of capital letters $ X_{0\\text{·}},  X_{1\\text{·}}$ since they are fixed and not random, but we'll keep using capital letters for notational simplicity.\n",
    "\n",
    "We can estimate $\\mathbb{P}(D | E))$ and $\\mathbb{P}(D | E^c)$ but we cannot estimate all probabilities in the table.  Still, we can estimate $\\psi$.  Now:\n",
    "\n",
    "$$\\hat{\\mathbb{P}}(D | E) = \\frac{X_{11}}{X_{1\\text{·}}}\n",
    "\\quad \\text{and} \\quad\n",
    "\\hat{\\mathbb{P}}(D | E^c) = \\frac{X_{01}}{X_{0\\text{·}}}\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$ \\hat{\\psi} = \\frac{X_{11} X_{00}}{X_{01} X_{10}}$$\n",
    "\n",
    "as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case-Control (Retrospective Sampling)**.  Here we get some diseased and non-diseased people and we observe how many are exposed.  This is much more efficient if the disease is rare.  Hence,\n",
    "\n",
    "$$\n",
    "X_{10} \\sim \\text{Binomial}(X_{\\text{·}0}, \\mathbb{P}(E | D^c))\n",
    "\\quad \\text{and} \\quad\n",
    "X_{11} \\sim \\text{Binomial}(X_{\\text{·}1}, \\mathbb{P}(E | D))\n",
    "$$\n",
    "\n",
    "From this data we can estimate $\\mathbb{P}(E | D)$ and $\\mathbb{P}(E | D^c)$.  Surprisingly, we can still estimate $\\psi$.  To understand why, note that\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(E | D) = \\frac{p_{11}}{p_{01} + p_{11}},\n",
    "\\quad 1 - \\mathbb{P}(E | D) = \\frac{p_{01}}{p_{01} + p_{11}},\n",
    "\\quad \\text{odds}(E | D) = \\frac{p_{11}}{p_{01}}\n",
    "$$\n",
    "\n",
    "By a similar argument,\n",
    "\n",
    "$$\\text{odds}(E | D^c) = \\frac{p_{10}}{p_{00}}$$\n",
    "\n",
    "Hence,\n",
    "\n",
    "$$\\frac{\\text{odds}(E | D)}{\\text{odds}(E | D^c)} = \\frac{p_{11} p_{00}}{p_{01} p_{10}} = \\psi$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\\hat{\\psi} = \\frac{X_{11} X_{00}}{X_{01} X_{10}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all three methods, the estimate of $\\psi$ turns out to be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is tempting to try to estimate $\\mathbb{P}(D | E) - \\mathbb{P}(D | E^c)$.  In a case-control design, this quantity is not estimable.  To see this, we apply Bayes' theorem to get\n",
    "\n",
    "$$\\mathbb{P}(D | E) - \\mathbb{P}(D | E^c) = \\frac{\\mathbb{P}(E | D) \\mathbb{P}(D))}{\\mathbb{P}(E)} - \\frac{\\mathbb{P}(E^c | D) \\mathbb{P}(D)}{\\mathbb{P}(E^c)}$$\n",
    "\n",
    "Because of the way we obtained the data, $\\mathbb{P}(D)$ is not estimable from the data.\n",
    "\n",
    "However, we can estimate $\\xi = \\mathbb{P}(D | E) / \\mathbb{P}(D | E^c)$, which is called the **relative risk**, under the **rare disease assumption**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 16.9**.  Let $\\xi = \\mathbb{P}(D | E) / \\mathbb{P}(D | E^c)$.  Then\n",
    "\n",
    "$$ \\frac{\\psi}{\\xi} \\rightarrow 1$$\n",
    "\n",
    "as $\\mathbb{P}(D) \\rightarrow 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, under the rare disease assumption, the relative risk is approximately the same as the odds ratio, which we can estimate.\n",
    "\n",
    "In a randomized experiment, we can interpret a strong association, that is $\\psi \\neq 1$, as a causal relationship.  In an observational (non-randomized) study, the association can be due to other unobserved **confounding** variables.  We'll discuss causation in more detail later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
