{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. Simulation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we will see that by generating data in a clever way, we can solve a number of problems such as integrating or maximizing a complicated function.  For integration, we will study 3 methods:\n",
    "\n",
    "- basic Monte Carlo integration\n",
    "- importance sampling\n",
    "- Markov chain Monte Carlo (MCMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25.1 Bayesian Inference Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation methods are specially useful in Bayesian inference so let us briefly review the main ideas.  Given a prior $f(\\theta)$ and data $X^n = (X_1, \\dots, X_n)$ the posterior density is\n",
    "\n",
    "$$ f(\\theta | X^n) = \\frac{\\mathcal{L}(\\theta) f(\\theta)}{ \\int \\mathcal{L}(u) f(u) \\; du} $$\n",
    "\n",
    "where $\\mathcal{L}(\\theta)$ is the likelihood function.  The posterior mean is\n",
    "\n",
    "$$ \\overline{\\theta} = \\int \\theta f(\\theta | X^n) \\; d\\theta = \\frac{\\int \\theta \\mathcal{L}(\\theta) f(\\theta) \\; d\\theta}{\\int \\mathcal{L}(\\theta) f(\\theta) \\; d\\theta} $$\n",
    "\n",
    "If $\\theta = (\\theta_1, \\dots, \\theta_k)$ is multidimensional, then we might be interested in the posterior for one the components, $\\theta_1$, say.  This marginal posterior density is\n",
    "\n",
    "$$ f(\\theta_1 | X^n) = \\int \\int \\cdots \\int f(\\theta_1, \\dots, \\theta_k | X^n) \\; d\\theta_2 \\cdots d\\theta_k$$\n",
    "\n",
    "which involves high dimensional integration.\n",
    "\n",
    "You can see that integrals play a big role in Bayesian inference.  When $\\theta$ is high dimensional, it may not be feasible to calculate these integrals analytically.  Simulation methods will often be very helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25.2 Basic Monte Carlo Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to evaluate the integral $I = \\int_a^b h(x) dx$ for some function $h$.  If $h$ is an \"easy\" function like a polynomial or a trigonometric function then we can do the integral in closed form.  In practice, $h$ can be very complicated and there may be no known closed form expression for $I$.  There are many numerical techniques for evaluating $I$ such as Simpson's rule, the trapezoidal rule, Gaussian quadrature and so on.  In some cases these techniques work very well.  But other times they might not work so well.  In particular, it is hard to extend them to higher dimensions.  Monte Carlo integration is another approach to evaluating $I$ which is notable for its simplicity, generality, and scalability.\n",
    "\n",
    "Let us begin by writing\n",
    "\n",
    "$$ I = \\int_a^b h(x) dx = \\int_a^b h(x) (b - a) \\frac{1}{b - a} dx = \\int_a^b w(x) f(x) dx$$\n",
    "\n",
    "where $w(x) = h(x)(b - a)$ and $f(x) = 1 / (b - a)$.  Notice that $f$ is the density for a uniform random variable over $(a, b)$.  Hence,\n",
    "\n",
    "$$ I = \\mathbb{E}_f(w(X)) $$\n",
    "\n",
    "where $X \\sim \\text{Uniform}(a, b)$.\n",
    "\n",
    "Suppose we generate $X_1, \\dots, X_n \\sim \\text{Uniform}(a, b)$ where $N$ is large.  By the law of large numbers,\n",
    "\n",
    "$$ \\hat{I} \\equiv \\frac{1}{N} \\sum_{i=1}^N w(X_i) \\xrightarrow{\\text{P}} \\mathbb{E}(w(X)) = I $$\n",
    "\n",
    "This is the **basic monte carlo integration method**.  We can also compute the standard error of the estimate,\n",
    "\n",
    "$$ \\hat{\\text{se}} = \\frac{s}{\\sqrt{N}} \n",
    "\\quad \\text{where} \\quad\n",
    "s^2 = \\frac{\\sum_i (Y_i - \\hat{I})^2}{N - 1},\n",
    "\\quad Y_i = w(X_i)\n",
    "$$\n",
    "\n",
    "A $1 - \\alpha$ confidence interval for $I$ is $\\hat{I} \\pm z_{\\alpha / 2} \\hat{\\text{se}}$.  We can take $N$ as large as we want and hence make the length of the confidence interval very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple generalization of the basic method is to consider integrals of the form\n",
    "\n",
    "$$ I = \\int h(x) f(x) \\; dx $$\n",
    "\n",
    "where $f(x)$ is a probability density function.  Taking $f$ to be $\\text{Uniform}(a, b)$ gives us the special case above.  The only difference is that now we draw $X_1, \\dots, X_N \\sim f$ and take\n",
    "\n",
    "$$ \\hat{I} \\equiv \\frac{1}{N} \\sum_{i=1}^N h(X_i) $$\n",
    "\n",
    "as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
