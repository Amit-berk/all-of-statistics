{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of predicting a discrete variable $Y$ from another random variable $X$ is called **classfication**, **supervised learning**, **discrimination** or **pattern recognition**.\n",
    "\n",
    "In more detail, consider IID data $(X_1, Y_1), \\dots, (X_n, Y_n)$ where\n",
    "\n",
    "$$ X_i = (X_{i1}, \\dots, X_{id}) \\in \\mathcal{X} \\subset \\mathbb{R}^d $$\n",
    "\n",
    "is a $d$-dimensional vector and $Y_i$ takes values in some finite set $\\mathcal{Y}$.  A **classification rule** is a function $h : \\mathcal{X} \\rightarrow \\mathcal{Y} $.  When we observe a new $X$, we predict $Y$ to be $h(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth revisiting the vocabulary:\n",
    "\n",
    "| Statistics     | Computer Science    | Meaning                                      |\n",
    "|----------------|---------------------|----------------------------------------------|\n",
    "| classification | supervised learning | predicting a discrete $Y$ from $X$           |\n",
    "| data           | training sample     | $(X_1, Y_1), \\dots, (X_n, Y_n)$              |\n",
    "| covariates     | features            | the $X_i$'s                                  |\n",
    "| classifier     | hypothesis          | map $h: \\mathcal{X} \\rightarrow \\mathcal{Y}$ |\n",
    "| estimation     | learning            | finding a good classifier                    |\n",
    "\n",
    "In most cases with this chapter, we deal with the case $\\mathcal{Y} = \\{ 0, 1 \\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.2 Error Rates and The Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **true error rate** of a classifier is \n",
    "\n",
    "$$ L(h) = \\mathbb{P}( \\{ h(X) \\neq Y\\} ) $$\n",
    "\n",
    "and the **empirical error rate** or **training error rate** is\n",
    "\n",
    "$$ \\hat{L}_n(h) = \\frac{1}{n} \\sum_{i=1}^n I(h(X_i) \\neq Y_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the special case where $\\mathcal{Y} = \\{0, 1\\}$.  Let\n",
    "\n",
    "$$ r(x) = \\frac{\\pi f_1(x)}{\\pi f_1(x) + (1 - \\pi) f_0(x)} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ f_0(x) = f(x | Y = 0)\n",
    "\\quad \\text{and} \\quad\n",
    "f_1(x) = f(x | Y = 1)$$\n",
    "\n",
    "and $\\pi = \\mathbb{P}(Y = 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Bayes classification rule** $h^*$ is defined to be\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } r(x) > \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The set $\\mathcal{D}(h) = \\{ x : \\mathbb{P}(Y = 1 | X = x) = \\mathbb{P}(Y = 0 | X = x) \\}$ is called the **decision boundary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the Bayes rule has nothing to do with Bayesian inference.  We could estimate the Bayes rule using either frequentist or Bayesian methods.\n",
    "\n",
    "The Bayes rule may be written in several different forms:\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } \\mathbb{P}(Y = 1 | X = x) > \\mathbb{P}(Y = 0 | X  = x)\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } \\pi f_1(x) > (1 - \\pi) f_0(x) \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.5**.  The Bayes rule is optimal, that is, if $h$ is any classification rule then $L(h^*) \\leq L(h)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes rule depends on unknown quantities so we need to use the data to find some approximation to the Bayes rule.  At the risk of oversimplifying, there are three main approaches:\n",
    "\n",
    "1. **Empirical Risk Maximization**.  Choose a set of classifiers $\\mathcal{H}$ and find $\\hat{h} \\in \\mathcal{H}$ that minimizes some estimate of $L(h)$.\n",
    "\n",
    "2. **Regression**.  Find an estimate $\\hat{r}$ of the regression function $r$ and define\n",
    "\n",
    "$$ \n",
    "\\hat{h}(x) = \\begin{cases}\n",
    "1 & \\text{if } \\hat{r} > \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "3. **Density Estimation**.  Estimate $f_0$ from the $X_i$'s for which $Y_i = 0$, estimate $f_1$ from the $X_i$'s for which $Y_i = 1$, and let $\\hat{\\pi} = n^{-1} \\sum_{i=1}^n Y_i$.  Define\n",
    "\n",
    "$$ \\hat{r}(x) = \\hat{\\mathbb{P}}(Y = 1 | X = x) = \\frac{\\hat{\\pi} \\hat{f}_1(x)}{\\hat{\\pi} \\hat{f}_1(x) + (1 - \\hat{\\pi}) \\hat{f}_0(x)} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \n",
    "\\hat{h}(x) = \\begin{cases}\n",
    "1 & \\text{if } \\hat{r} > \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to generalize to the case where $Y$ takes more than two values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.6**.  Suppose that $Y \\in \\mathcal{Y} = \\{ 1, \\dots, K \\}$.  The optimal rule is\n",
    "\n",
    "$$ h(x) = \\text{argmax}_h \\mathbb{P}(Y = k | X = x) = \\text{argmax}_h \\pi_k f_k(x) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\mathbb{P}(Y = k | X = x) = \\frac{f_k(x) \\pi_k}{\\sum_r f_r(x) \\pi_r} $$\n",
    "\n",
    "and $ \\pi_r = \\mathbb{P}(Y = r)$, $f_r(x) = f(x | Y = r)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.3 Gaussian and Linear Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the simplest approach to classification is to use the density estimation strategy and assume a parametric model for the densities.  Suppose that $\\mathcal{Y} = \\{ 0, 1 \\}$ and that $f_0(x) = f(x | Y = 0)$ and $f_1(x) = f(x | Y = 1)$ are both multivariate Gaussians:\n",
    "\n",
    "$$ f_k(x) = \\frac{1}{(2\\pi)^{d/2} | \\Sigma_k |^{1/2}} \\exp \\left\\{ -\\frac{1}{2} (x - \\mu_k)^T \\Sigma_k^{-1} (x - \\mu_k) \\right\\}, \\quad k = 0, 1$$\n",
    "\n",
    "Thus, $X | Y = 0 \\sim N(\\mu_0, \\Sigma_0)$ and $X | Y = 1 \\sim N(\\mu_1, \\Sigma_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.7**.  If $X | Y = 0 \\sim N(\\mu_0, \\Sigma_0)$ and $X | Y = 1 \\sim N(\\mu_1, \\Sigma_1)$, then the Bayes rule is\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } r_1^2 < r_0^2 + 2 \\log \\left( \\frac{\\pi_1}{\\pi_0} \\right) + \\log \\left( \\frac{| \\Sigma_0 | }{ | \\Sigma_1| }\n",
    "\\right) \\\\\n",
    "0 & \\text{otherwise} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ r_i^2 = (x - \\mu_i)^T \\Sigma_i^{-1}(x - \\mu_i), \\quad i = 1, 2 $$\n",
    "\n",
    "is the **Manalahobis distance**.  An equivalent way of expressing Bayes' rule is \n",
    "\n",
    "$$ h(x) = \\text{argmax}_k \\delta_k(x) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\delta_k(x) = -\\frac{1}{2} \\log | \\Sigma_k | - \\frac{1}{2} (x - \\mu_k)^T \\Sigma_k^{-1} (x - \\mu_k) + \\log \\pi_k $$\n",
    "\n",
    "and $|A|$ denotes the determinant of matrix $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary of the above classifier is quadratic so this procedure is often called **quadratic discriminant analysis (QDA)**.  In practice, we use sample estimates of $\\pi, \\mu_0, \\mu_1, \\Sigma_0, \\Sigma_1$ in place of the true value, namely:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "\\hat{\\pi}_0 = \\frac{1}{n} \\sum_{i=1}^n (1 - Y_i) & \\hat{\\pi}_1 = \\frac{1}{n} \\sum_{i=1}^n Y_i \\\\\n",
    "\\hat{\\mu}_0 = \\frac{1}{n_0} \\sum_{i: Y_i = 0} X_i & \\hat{\\mu}_1 = \\frac{1}{n_0} \\sum_{i: Y_i = 1} X_i \\\\\n",
    "S_0 = \\frac{1}{n_0} \\sum_{i: Y_i = 0} (X_i - \\hat{\\mu}_0) (X_i - \\hat{\\mu}_0)^T & \n",
    "S_1 = \\frac{1}{n_1} \\sum_{i: Y_i = 1} (X_i - \\hat{\\mu}_1) (X_i - \\hat{\\mu}_1)^T\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $n_0 = \\sum_i (1 - Y_i)$ and $n_1 = \\sum_i Y_i$ are the number of $Y_i$ variables equal to 0 or 1, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simplification occurs if we assume $\\Sigma_0 = \\Sigma_1 = \\Sigma$.  In that case, the Bayes rule is\n",
    "\n",
    "$$ h(x) = \\text{argmax}_k \\delta_k(x) $$\n",
    "\n",
    "where now\n",
    "\n",
    "$$ \\delta_k(x) = x^T \\Sigma^{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\Sigma^{-1} \\mu_k + \\log \\pi_k $$\n",
    "\n",
    "The parameters are estimated as before, except the MLE of $\\Sigma$ now is\n",
    "\n",
    "$$ S = \\frac{n_0 S_0 + n_1 S_1}{n_0 + n_1} $$\n",
    "\n",
    "The classification rule is\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 &\\text{if } \\delta_1(x) > \\delta_0(x) \\\\\n",
    "0 &\\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\delta_j(x) = x^T S \\hat{\\mu}_j - \\frac{1}{2} \\hat{\\mu}_j^T S^{-1} \\hat{\\mu}_j + \\log \\hat{\\pi}_j $$\n",
    "\n",
    "is called the **discriminant function**.  The decision boundary $ \\{ x : \\delta_0(x) = \\delta_1(x) \\}$ is linear so this method is called **linear discrimination analysis (LDA)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generalize to the case where $Y$ takes on more than two values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.9**.  Suppose that $Y \\in \\{ 1, \\dots, K \\}$.  If $f_k(x) = f(x | Y = k)$ is Gaussian, the Bayes rule is\n",
    "\n",
    "$$ h(x) = \\text{argmax}_k \\delta_k(x) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\delta_k(x) = -\\frac{1}{2} \\log | \\Sigma_k | - \\frac{1}{2} (x - \\mu_k)^T \\Sigma_k^{-1} (x - \\mu_k) + \\log \\pi_k $$\n",
    "\n",
    "If the variances of the Gaussians are equal then\n",
    "\n",
    "$$ \\delta_k(x) = x^T \\Sigma_{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\Sigma^{-1} \\mu_k + \\log \\pi_k $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate $\\delta_k(x)$ by inserting estimates of $\\mu_k$, $\\Sigma_k$, and $\\pi_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another version of LDA due to Fisher.  The idea is to first reduce the dimension of the covariates to one dimension by projecting the data onto a line.  Algebraically, this means replacing the covariate $X = (X_1, \\dots, X_d)$ with a linear combination $U = w^T X = \\sum_{j=1}^d w_j X_j$.  The goal is to choose the vector $w = (w_1, \\dots, w_d)$ that \"best separates the data\".  Then we perform classification with the new covariate $U$ instead of $X$.\n",
    "\n",
    "We need to define what we mean by separation of the groups.  We would like the two groups to have means that are far apart relative to their spread.  Let $\\mu_j$ denote the mean of $X$ for $Y = j$ and let $\\Sigma$ be the variance matrix of $X$.  Then $\\mathbb{E}(U | Y = j) = \\mathbb{E}(w^T X | Y = j) = w^T \\mu_j$ and $\\mathbb{V}(U) = w^T \\Sigma w$.  Define the separation by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J(w) &= \\frac{(\\mathbb{E}(U | Y = 0) - \\mathbb{E}(U | Y = 1))^2}{w^T \\Sigma w} \\\\\n",
    "&= \\frac{(w^T \\mu_0 - w^T \\mu_1)^2}{w^T \\Sigma w} \\\\\n",
    "&= \\frac{w^T (\\mu_0 - \\mu_1)(\\mu_0 - \\mu_1)^T w}{w^T \\Sigma w}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "*The quantity $J$ arises in physics, where it is called the Rayleight coefficient.*\n",
    "\n",
    "We estimate $J$ as follows.  Let $n_j = \\sum_{i=1}^n I(Y_i = j)$ be the number of observations in group $j$, let $\\overline{X}_j = n_j^{-1} \\sum_{i: Y_i = j} X_j$ be the sample mean vetor of $X$'s for group $j$, and let $S_j = (n_j - 1)^{-1} \\sum_{i: Y_i = j} (X_i - \\overline{X}_j)(X_i - \\overline{X}_j)^T $ be the sample covariance matrix in group $j$.  Define\n",
    "\n",
    "$$ \\hat{J}(w) = \\frac{w^T S_B w}{w^T S_W w} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \n",
    "S_B = (\\overline{X}_0 - \\overline{X}_1) (\\overline{X}_0 - \\overline{X}_1)^T\n",
    "\\quad \\text{and} \\quad\n",
    "S_W = \\frac{(n_0 - 1) S_0 + (n_1 - 1) S_1}{(n_0 - 1) + (n_1 -1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.10**.  The vector\n",
    "\n",
    "$$ w = S_W^{-1}(\\overline{X}_0 - \\overline{X}_1) $$\n",
    "\n",
    "is a minimizer of $\\hat{J}(w)$.  We call\n",
    "\n",
    "$$ U = w^T X = (\\overline{X}_0 - \\overline{X}_1)^T S_W^{-1} X $$\n",
    "\n",
    "the **Fisher linear discriminant function**.  The midpoint $m$ between $\\overline{X}_0$ and $\\overline{X}_1$ is\n",
    "\n",
    "$$ m = \\frac{1}{2} (\\overline{X}_0 + \\overline{X}_1) = \\frac{1}{2}  (\\overline{X}_0 - \\overline{X}_1)^T S_B^{-1}  (\\overline{X}_0 + \\overline{X}_1)$$\n",
    "\n",
    "Fisher's classification rule is\n",
    "\n",
    "$$\n",
    "h(x) = \\begin{cases}\n",
    "0 & \\text{if } w^T X \\geq m \\\\\n",
    "1 & \\text{if } w^T X < m\n",
    "\\end{cases}\n",
    "= \\begin{cases}\n",
    "0 & \\text{if } (\\overline{X}_0 - \\overline{X}_1)^T S_W^{-1}x \\geq m \\\\\n",
    "1 & \\text{if } (\\overline{X}_0 - \\overline{X}_1)^T S_W^{-1}x < m\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Fisher's rule is the same as the Bayes linear classifier when $\\hat{\\pi} = 1/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.4 Linear Regression and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more direct approach to classification is to estimate the regression function $r(x) = \\mathbb{E}(Y | X = x)$ without bothering to estimate the densities $f_k$.  For the rest of this section we will only consider the case where $\\mathcal{Y} = \\{ 0, 1 \\}$.  Thus, $r(x) = \\mathbb{P}(Y = 1 | X = x)$ and once we have an estimate $\\hat{r}$, we will use the classification rule\n",
    "\n",
    "$$ \n",
    "h(x) = \\begin{cases}\n",
    "1 &\\text{if } \\hat{r}(x) > \\frac{1}{2} \\\\\n",
    "0 &\\text{otherwise}\n",
    "\\end{cases} \n",
    "$$\n",
    "\n",
    "The simplest regression is the linear regression model\n",
    "\n",
    "$$ Y = r(x) + \\epsilon = \\beta_0 + \\sum_{j=1}^d \\beta_j X_j + \\epsilon $$\n",
    "\n",
    "where $\\mathbb{E}(\\epsilon) = 0$.  This model can't be correct since it doesn't force $Y \\in \\mathcal{Y}$.  Nonetheless, it can sometimes lead to a decent classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the least square estimate of $\\beta = (\\beta_0, \\beta_1, \\dots, \\beta_d)^T$ minimizes the residual sum of squares\n",
    "\n",
    "$$ \\text{RSS}(\\beta) = \\sum_{i=1}^n \\left( Y_i - \\left( \\beta_0  + \\sum_{j=1}^d X_{ij} \\beta_j \\right) \\right)^2 $$\n",
    "\n",
    "Briefly reviewing this estimator:  let\n",
    "\n",
    "$$ \n",
    "X = \\begin{bmatrix}\n",
    "1 & X_{11} & \\cdots & X_{1d} \\\\\n",
    "1 & X_{21} & \\cdots & X_{2d} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & X_{n1} & \\cdots & X_{nd}\n",
    "\\end{bmatrix}\n",
    "\\quad \\text{and} \\quad\n",
    "Y = (Y_1, \\dots, Y_n)^T\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$ \\text{RSS}(\\beta) = (Y - X \\beta)^T (Y - X \\beta) $$\n",
    "\n",
    "and the model can be written as\n",
    "\n",
    "$$ Y = X \\beta + \\epsilon $$\n",
    "\n",
    "where $ \\epsilon = (\\epsilon_1, \\dots, \\epsilon_n)^T$.  The least squares solution $\\hat{\\beta}$ that minimizes RSS is given by\n",
    "\n",
    "$$ \\hat{\\beta} = (X^T X)^{-1} X^T Y $$\n",
    "\n",
    "and the predicted values are\n",
    "\n",
    "$$ \\hat{Y} = X \\hat{\\beta} $$\n",
    "\n",
    "Now we can use $h(x)$ to classify, by taking $\\hat{r}(x) = \\hat{\\beta}_0 + \\sum_k \\hat{\\beta}_k x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems sensible to use a regression model that takes into account that $Y \\in \\{ 0, 1 \\}$.  The most common method for doing so is **logistic regression**.  Recall that the model is\n",
    "\n",
    "$$ r(x) = \\mathbb{P}(Y = 1 | X = x) = \\frac{\\exp \\left\\{ \\beta_0 + \\sum_j \\beta_j x_j \\right\\} }{1 + \\exp \\left\\{ \\beta_0 + \\sum_j \\beta_j x_j \\right\\} } $$\n",
    "\n",
    "We may write this as\n",
    "\n",
    "$$ \\text{logit} \\; \\mathbb{P}(Y = 1 | X = x) = \\beta_0 + \\sum_j \\beta_j x_j $$\n",
    "\n",
    "where $\\text{logit}(a) = \\log (a / (1 - a))$.  Under this model, each $Y_i$ is a Bernoulli with success probability\n",
    "\n",
    "$$ p_i(\\beta) = \\frac{\\exp \\left\\{ \\beta_0 + \\sum_j \\beta_j X_{ij} \\right\\} }{1 + \\exp \\left\\{ \\beta_0 + \\sum_j \\beta_j X_{ij} \\right\\} } $$\n",
    "\n",
    "The likelihood function for the data set is\n",
    "\n",
    "$$ \\mathcal{L}(\\beta) = \\prod_{i=1}^n p_i(\\beta)^{Y_i} (1 - p_i(\\beta))^{1 - Y_i}$$\n",
    "\n",
    "We obtain the MLE numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a better classifier by fitting a richer model.  For example we could fit\n",
    "\n",
    "$$ \\text{logit} \\; \\mathbb{P}(Y = 1 | X = x) = \\beta_0 + \\sum_j \\beta_j x_j + \\sum_{j, k} \\beta_{jk} x_j x_k $$\n",
    "\n",
    "More generally, we could add terms of up to order $r$ for some integer $r$.  Large values of $r$ give a more complicated model which should fit the data better.  But there is a bias-variance tradeoff which we'll discuss later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression can be easily extend to $k$ groups but we shall not give the details here.\n",
    "\n",
    "*(Student note: multiple treatments are easily found searching for \"multinomial logistic regression\")*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.5  Relationship Between Logistic Regression and LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA and logistic regression are almost the same thing.  \n",
    "\n",
    "If we assume each group is Gaussian with the same covariance matrix then\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\log \\left( \\frac{\\mathbb{P}(Y = 1 | X = x)}{\\mathbb{P}(Y = 0 | X = x)} \\right) \n",
    "&= \\log \\left( \\frac{\\pi_0}{\\pi_1} \\right) - \\frac{1}{2} (\\mu_0 + \\mu_1)^T \\Sigma^{-1} (\\mu_1 - \\mu_0) + x^T \\Sigma^{-1}( \\mu_1 - \\mu_0) \\\\\n",
    "&\\equiv \\alpha_0 + \\alpha^T x\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "On the other hand, the logistic model is, by assumption,\n",
    "\n",
    "$$ \\log \\left( \\frac{\\mathbb{P}(Y = 1 | X = x)}{\\mathbb{P}(Y = 0 | X = x)} \\right) = \\beta_0 + \\beta^T x $$\n",
    "\n",
    "These are the same model since they both lead to classification rules that are linear in $x$.  The difference is in how we estimate the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint density of a single observation is $f(x, y) = f(x | y) f(y) = f(y | x) f(x)$.  In LDA we estimated the whole distribution by estimating $f(x | y)$ and $f(y)$; specifically, we estimated $f_k(x) = f(x | Y = k)$, $\\pi_k = f_Y(k)$.  We maximized the likelihood\n",
    "\n",
    "$$ \\prod_i f(x_i, y_i) = \\underbrace{\\prod_i f(x_i | y_i)}_\\text{Gaussian} \\underbrace{ \\prod_i f(y_i) }_\\text{Bernoulli}$$\n",
    "\n",
    "In logistic regression, we maximized the conditional likelihood $\\prod_i f(y_i | x_i)$ but we ignored the second term $f(x_i)$:\n",
    "\n",
    "$$ \\prod_i f(x_i, y_i) = \\underbrace{\\prod_i f(y_i | x_i)}_\\text{logistic} \\underbrace{ \\prod_i f(x_i) }_\\text{ignored}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since classification requires only knowing $f(y | x)$, we don't really need to estimate the whole joint distribution.  Logistic regression leaves the marginal distribution $f(x)$ unspecified so it is more nonparametric than LDA.\n",
    "\n",
    "To summarize:  LDA and logistic regression both lead to a linear classification rule.  In LDA we estimate the whole joint distribution $f(x, y) = f(x | y) f(y)$.  In logistic regression we only estimate $f(y | x)$ and we don't bother estimating $f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.6 Density Estimation and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the Bayes rule is $h(x) = \\text{argmax}_k \\pi_k f_k(x)$.  If we can estimate $\\pi_k$ and $f_k$ then we can estimate the Bayes classification rule.  Estimating $\\pi_k$ is easy, but what about $f_k$? We did it previously by assuming $f_k$ was Gaussian.  Another strategy is to estimate $f_k$ with some nonparametric density estimator $\\hat{f}_k$ such as a kernel estimator.  But if $x = (x_1, \\dots, x_d)$ is high dimensional, nonparametric density estimation is not very reliable.  The problem is ameliorated if we assume that $X_1, \\dots, X_d$ are independent, for then $f_k(x_1, \\dots, x_d) = \\prod_{j=1}^d f_{kj}(x_j)$.  This reduces the problem to $d$ one-dimensional density estimation problems, within each of the $k$ groups.  The resulting classifier is called the **naive Bayes classifier**.  The assumption that the components of $X$ are independent is usually wrong yet the resulting classifier might still be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes Classifier**\n",
    "\n",
    "1.  For each group $k$, compute an estimate $\\hat{f}_{kj}$ of the density $f_{kj}$ for $X_j$, using the data for which $Y_i = k$.\n",
    "\n",
    "2.  Let\n",
    "\n",
    "$$ \\hat{f}_k(x) = \\hat{f}_k(x_1, \\dots, x_d) = \\prod_{j=1}^d \\hat{f}_{kj}(x_j) $$\n",
    "\n",
    "3. Let\n",
    "\n",
    "$$ \\hat{\\pi}_k = \\frac{1}{n} \\sum_{i=1}^n I(Y_i = k) $$\n",
    "\n",
    "where $I(t) = 1$ if $t$ and $I(t) = 0$ otherwise.\n",
    "\n",
    "4. Let\n",
    "\n",
    "$$ h(x) = \\text{argmax}_k \\hat{\\pi}_k \\hat{f}_k(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive Bayes classifier is especially popular when $x$ is high dimensional and discrete.  In that case, $\\hat{f}_{kj}(x_k)$ is especially simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.7 Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees are classification methods that partition the covariate space $\\mathcal{X}$ into disjoint pieces and then classify the observations according to which partition element they fall in.  As the name implies, the classifier can be represented as a tree.\n",
    "\n",
    "Here is how a tree is constructed.  For simplicity, we focus on the case where $\\mathcal{Y} = \\{ 0, 1 \\}$.  First, suppose there is a single covariate $X$.  We choose a split point $t$ that divides the real line into two sets, $A_1 = (-\\infty, t]$ and $A_2 = (t, \\infty)$.  Let $\\hat{p}_s(j)$ be the proportion of observations in $A_s$ such that $Y_i = j$:\n",
    "\n",
    "$$ \\hat{p}_s(j) = \\frac{\\sum_{i=1}^n I(Y_i = j, X_i \\in A_s)}{\\sum_{i=1}^n I(X_i \\in A_s)} $$\n",
    "\n",
    "for $s = 1, 2$ and $j = 0, 1$.  The **impurity** of the split $t$ is defined to be\n",
    "\n",
    "$$ I(t) = \\sum_{s=1}^2 \\gamma_s $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\gamma_s = 1 - \\sum_{j=0}^1 \\hat{p}_s(j)^2 $$\n",
    "\n",
    "This measure of impurity is known as the **Gini index**.  If a partition element $A_s$ contains all 0s or all 1s, then $\\gamma_s = 0$.  Otherwise, $\\gamma_s > 0$.  We choose the split point $t$ to minimize the impurity.  (Other indices of impurity may be used besides the Gini index.)\n",
    "\n",
    "When there are several covariates, we choose whatever covariate and split that leads to the lowest impurity.  This process is continued until some stopping criteria is met.  For example, we might stop when every partition element has fewer than $n_0$ data points, where $n_0$ is some fixed number.  The bottom nodes of the tree are called **leaves**.  Each leaf is assigned a 0 or 1 depending on whether there are more data points with $Y = 0$ or $Y = 1$ in the partition element.\n",
    "\n",
    "This procedure is easily generalized to the multiclass case, $\\mathcal{Y} = \\{ 1, \\dots, K \\}$.  We simply define the impurity by\n",
    "\n",
    "$$ \\gamma_s = 1 - \\sum_{j=1}^K \\hat{p}_s(j)^2 $$\n",
    "\n",
    "where $\\hat{p}_s(j)$ is the proportion of observations in the partition element for which $Y = j$.\n",
    "\n",
    "Our description of how to build trees is incomplete.  If we keep splitting until there are few cases in each leaf of the tree, we are likely to overfit the data.  We should choose the complexity of the tree in such a way that the estimated true error rate is low.  In the next section, we discuss estimation of the error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.8 Assessing Error Rates and Choosing a Good Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to have a classifier $h$ with a low true error rate $L(h)$.  Usually, we can't use the training error rate $\\hat{L}_n(h)$ as an estimate of the true error rate because it is biased downward.\n",
    "\n",
    "There are many ways to estimate the error rate.  We'll consider two:  **cross-validation** and **probability inequalities**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "The basic idea of cross-validation is to leave out some of the data when fitting a model.  The simplest version involves randomly splitting the data into two pieces: the **training set $\\mathcal{T}$** and the **validation set $\\mathcal{V}$**.  Often, about 10 percent of the data might be set aside as the validation set.  The classifier $h$ is constructed from the training set.  We then estimate the error by\n",
    "\n",
    "$$ \\hat{L}(h) = \\frac{1}{m} \\sum_{X_i \\in \\mathcal{V}} I(h(X_i) \\neq Y_i) $$\n",
    "\n",
    "where $m$ is the size of the validation set.\n",
    "\n",
    "Another approach to cross-validation is **K-fold cross-validation** which is obtained as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-fold cross-validation**\n",
    "\n",
    "1.  Randomly divide the data into $K$ chunks of approximately equal size.  A common choice is $K = 10$.\n",
    "\n",
    "2.  For $k = 1$ to $K$ do the following:\n",
    "\n",
    "   (a) Delete chunk $k$ from the data.\n",
    "   \n",
    "   (b) Compute the classifier $\\hat{h}_{(k)}$ from the rest of the data.\n",
    "   \n",
    "   (c) Use $\\hat{h}_{(k)}$ to predict the data in chunk $k$.  Let $\\hat{L}_{(k)}$ denote the observed error rate.\n",
    "   \n",
    "3. Let\n",
    "\n",
    "$$ \\hat{L}(h) = \\frac{1}{K} \\sum_{k=1}^K \\hat{L}_{(k)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation can be applied to any classification method.  To apply it to trees, one begins by fitting an initial tree.  Smaller trees are obtained by pruning tree.  We can do this for trees of various sizes, where size refers to the number of terminal nodes on the tree.  Cross-validation is then used to estimate error rate as a function of tree size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Inequalities\n",
    "\n",
    "Another approach to estimating the error rate is to find a confidence interval for $\\hat{L}_n(h)$ using probability inequalities.  This method is useful in the context of **empirical risk estimation**.\n",
    "\n",
    "Let $\\mathcal{H}$ be a set of classifiers, for example, all linear classifiers.  Empirical risk minimization means choosing the classifier $\\hat{h} \\in \\mathcal{H}$ to minimize the training error $\\hat{L}_n(h)$, also called the empirical risk.  Thus,\n",
    "\n",
    "$$ \\hat{h} = \\text{argmin}_{h \\in \\mathcal{H}} \\hat{L}_n(h) \n",
    "= \\text{argmin}_{h \\in \\mathcal{H}} \\left( \\frac{1}{n} \\sum_i I(h(X_i) \\neq Y_i) \\right) $$\n",
    "\n",
    "Typically, $\\hat{L}_n(\\hat{h})$ underestimates the true error rate $L(\\hat{h})$ because $\\hat{h}$ was chosen to minimize $\\hat{L}_n(\\hat{h})$.  Our goal is to assess how much underestimation is taking place.  Our main tool for this analysis is **Hoeffding's inequality**.  Recall that if $X_1, \\dots, X_n \\sim \\text{Bernoulli}(p)$, then, for any $\\epsilon > 0$,\n",
    "\n",
    "$$ \\mathbb{P}(|\\hat{p} - p| > \\epsilon) \\leq 2 e^{ -2 n \\epsilon^2 } $$\n",
    "\n",
    "where $\\hat{p} = n^{-1} \\sum_{i=1}^n X_i$.\n",
    "\n",
    "First, suppose that $\\mathcal{H} = \\{ h_1, \\dots, h_m \\}$ consists of finitely many classifiers.  For any fixed $h$, $\\hat{L}_n(h)$ converges in almost surely to $L(h)$ by the law of large numbers.  We will now establish a stronger result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.16 (Uniform Convergence)**.  Assume $\\mathcal{H}$ is finite and has $m$ elements.  Then,\n",
    "\n",
    "$$ \\mathbb{P} \\left( \\max_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon \\right) \\leq 2 m e^{-2 n \\epsilon^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof**.  We will use Hoeffding's inequality and we will also use the fact that if $A_1, \\dots, A_m$ is a set of events then $\\mathbb{P}(\\bigcup_{i=1}^m A_i) \\leq \\sum_{i=1}^m \\mathbb{P}(A_i)$.  Now,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{P} \\left( \\max_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon \\right)\n",
    "&= \\mathbb{P} \\left( \\bigcup_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon \\right) \\\\\n",
    "& \\leq \\sum_{h \\in \\mathcal{H}} \\mathbb{P} \\left( |\\hat{L}_n(h) - L(h) | > \\epsilon \\right) \\\\\n",
    "& \\leq \\sum_{h \\in \\mathcal{H}} 2 e^{-2 n \\epsilon^2} = 2 m e^{-2 n \\epsilon^2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.17**.  Let\n",
    "\n",
    "$$ \\epsilon = \\sqrt{\\frac{2}{n} \\log \\left( \\frac{2m}{\\alpha} \\right) } $$\n",
    "\n",
    "Then $\\hat{L}_n(\\hat{h}) \\pm \\epsilon$ is a $1 - \\alpha$ confidence interval for $L(\\hat{h})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof**.  This follows from the fact that\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(|\\hat{L}_n(\\hat{h}) - L(\\hat{h})| > \\epsilon) \n",
    "\\leq \\mathbb{P}( \\max_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon )\n",
    "\\leq 2 m e^{-2 n \\epsilon^2} = \\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\mathcal{H}$ is large the confidence interval for $L(\\hat{h})$ is large.  The more functions there are in $\\mathcal{H}$ the more likely it is we have \"overfit\" which we compensate for by having a larger confidence interval.\n",
    "\n",
    "In practice, we usually use sets $\\mathcal{H}$ that are infinite, such as the set of linear classifiers.  To extend our analysis to these cases we want to be able to say something like\n",
    "\n",
    "$$ \\mathbb{P} \\left( \\sup_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon \\right) \\leq \\text{something not too big} $$\n",
    "\n",
    "All the other results followed from this inequality.  One way to develop such a generalization is by way of the **Vapnik-Chervonenkis** or **VC dimension**.  We now consider the main ideas in VC theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathcal{A}$ be a class of sets.  Given a finite set $F = \\{ x_1, \\dots, x_n \\}$ let\n",
    "\n",
    "$$ N_\\mathcal{A}(F) = \\# \\Big\\{ F \\cap A : A \\in \\mathcal{A} \\Big\\} $$\n",
    "\n",
    "be the number of subsets F \"picked out\" by $\\mathcal{A}$.  Here $\\#(B)$ denotes the number of elements of set $B$.  The **shatter coefficient** is defined by\n",
    "\n",
    "$$ s(\\mathcal{A}, n) = \\max_{F \\in \\mathcal{F}_n} N_\\mathcal{A}(F) $$\n",
    "\n",
    "where $\\mathcal{F}_n$ consists of all finite sets of size $n$.  Now let $X_1, \\dots, X_n \\sim \\mathbb{P}$ and let\n",
    "\n",
    "$$ \\mathbb{P}_n(A) = \\frac{1}{n} \\sum_i I(X_i \\in A) $$\n",
    "\n",
    "denote the empirical probability measure.  The following remarkable theorem bounds the distance between $\\mathbb{P}$ and $\\mathbb{P}_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.18 (Vapnik and Chervonenkis (1971))**.  For any $\\mathbb{P}$, $n$, and $\\epsilon > 0$,\n",
    "\n",
    "$$ \\mathbb{P} \\left\\{ \\sup_{A \\in \\mathcal{A}} | \\mathbb{P}_n(A) - \\mathbb{P}(A) | > \\epsilon \\right\\} \\leq 8 s(\\mathcal{A}, n) e^{-n \\epsilon^2 / 32} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proof, though very elegant, is long and we omit it.  If $\\mathcal{H}$ is a set of classifiers, define $\\mathcal{A}$ to be the class of sets of the form $\\{ x : h(x) = 1 \\}$.  Then we define $s(\\mathcal{H}, n) = s(\\mathcal{A}, n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.19**.\n",
    "\n",
    "$$ \\mathbb{P} \\left\\{ \\sup_{h \\in \\mathcal{H}} | \\hat{L}_n(h) - L(h) | > \\epsilon \\right\\} \\leq 8 s(\\mathcal{H}, n) e^{-n \\epsilon^2 / 32} $$ \n",
    "\n",
    "A $1 - \\alpha$ confidence interval for $L(\\hat{h})$ is $\\hat{L}_n(\\hat{h}) \\pm \\epsilon_n$ where\n",
    "\n",
    "$$ \\epsilon_n^2 = \\frac{32}{n} \\log \\left( \\frac{8 s(\\mathcal{H}, n)}{\\alpha} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These theorems are only useful if the shatter coefficients do not grow too quickly with $n$.  This is where the VC dimension enters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **VC (Vapnik-Chervonenkis) dimension** of a class of sets $\\mathcal{A}$ is defined as follows.  If $s(\\mathcal{A}, n) = 2^n$ for all $n$ set $\\text{VC}(\\mathcal{A}) = \\infty$.  Otherwise, define $\\text{VC}(\\mathcal{A})$ to be the largest $k$ for which $s(\\mathcal{A}, n) = 2^k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the VC-dimension is the size of the largest finite set $F$ that can be **shattered by $\\mathcal{A}$**, meaning that $\\mathcal{A}$ picks out each subset of $F$.  If $\\mathcal{H}$ is a set of classifiers we define $\\text{VC}(\\mathcal{H}) = \\text{VC}(\\mathcal{A})$ where $\\mathcal{A}$ is the class of sets of the form $\\{ x : h(x) = 1 \\}$ as $h$ varies in $\\mathcal{H}$.  The following theorem shows that if $\\mathcal{A}$ has finite VC-dimension then the shatter coefficients grow as a polynomial in $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.21**.  If $\\mathcal{A}$ has finite VC-dimension $v$, then\n",
    "\n",
    "$$ s(\\mathcal{A}, n) \\leq n^v + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.26**.  Let $x$ have dimension $d$ and let $\\mathcal{H}$ be the set of linear classifiers.  The VC dimension of $\\mathcal{H}$ is $d + 1$.  Hence, a $1 - \\alpha$ confidence interval for the true error rate is $\\hat{L}(\\hat{h}) \\pm \\epsilon$ where\n",
    "\n",
    "$$ \\epsilon_n^2 = \\frac{32}{n} \\log \\left( \\frac{8 (n^{d + 1} + 1)}{\\alpha} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.9 Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we consider a class of linear classifiers called **support vector machines**.  Throughout this section, we assume that $Y$ is binary.  It will be convenient to label the outcomes as $+1$ and $-1$ instead of $0$ and $1$.  A linear classifier can then be written as\n",
    "\n",
    "$$ h(x) = \\text{sign}( H(x) ) $$\n",
    "\n",
    "where $x = (x_1, \\dots, x_d)$,\n",
    "\n",
    "$$ H(x) = a_0 + \\sum_{i=1}^d a_i x_i $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\text{sign}(z) = \\begin{cases}\n",
    "-1 &\\text{if } z < 0 \\\\\n",
    "0  &\\text{if } z = 0 \\\\\n",
    "1  &\\text{if } z > 0\n",
    "\\end{cases}$$\n",
    "\n",
    "First, suppose that the data are **linearly separable**, that is, there exists a hyperplane that perfectly separates the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemma 23.27**.  The data can be separated by some hyperplane if and only if there exists a hyperplane $H(x) = a_0 + \\sum_{i=1}^d a_i x_i $ such that \n",
    "\n",
    "$$ Y_i H(x_i) \\geq 1, \\quad i = 1, \\dots, n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof**.  Suppose that the data can be separated by a hyperplane $W(x) = b_0 + \\sum_{i=1}^d b_i x_i$.  It follows that there exists some constant $c$ such that $Y_i = 1$ implies$W(X_i) \\geq c$ and $Y_i = -1$ implies $W(X_i) \\leq -c$.  Therefore, $Y_i W(X_i) \\geq c$ for all i.  Let $H(x) = a_0 + \\sum_{i=1} a_i x_i$ where $a_i = b_i / c$.  Then $Y_i H(X_i) \\geq 1$ for all $i$.  The reverse direction is straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the separable case, there will be many separating hyperplanes.  Intuitively, it seems reasonable to choose the hyperplane \"furthest\" from the data in the sense that it separates the +1s and -1s and maximizes the distance to the closest point.  This hyperplane is called the **maximum margin hyperplane**.  The margin is the distance from the hyperplane to the nearest point.  Points on the boundary of the margin are called **support vectors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.28**.  The hyperplane $\\hat{H}(x) = \\hat{a}_0 + \\sum_{i=1}^d \\hat{a}_i x_i$ that separates the data and maximizes the margin is given by minimizing $(1/2) \\sum_{j=1}^d b_j^2$ subject to $Y_i H(x_i) \\geq 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that this problem can be recast as a quadratic programming problem.  Recall that $\\langle X_i, X_k \\rangle = X_i^T X_k$ is the inner product of $X_i$ and $X_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.29**.  Let $\\hat{H}(x) = \\hat{a}_0 + \\sum_{i=1}^d \\hat{a}_i x_i$ denote the optimal (largest margin) hyperplane.  Then, for $j = 1, \\dots, d$,\n",
    "\n",
    "$$ \\hat{a}_j = \\sum_{i=1}^n \\hat{\\alpha}_i Y_i X_j(i) $$\n",
    "\n",
    "where $X_j(i)$ is the value of the covariate $X_j$ for the $i$-th data point, and $\\hat{\\alpha} = (\\hat{\\alpha}_1, \\dots, \\hat{\\alpha}_n)$ is the vector that maximizes\n",
    "\n",
    "$$ \\sum_{i=1}^n \\alpha_i - \\frac{1}{2} \\sum_{i=1}^n \\sum_{k=1}^n \\alpha_i \\alpha_j Y_i Y_k \\langle X_i, X_k \\rangle $$\n",
    "\n",
    "subject to\n",
    "\n",
    "$$ \\alpha_i \\geq 0 $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ 0 = \\sum_i \\alpha_i Y_i $$\n",
    "\n",
    "The points $X_i$ for which $\\hat{\\alpha}_i \\neq 0$ are called **support vectors**.  $\\hat{\\alpha}_0$ can be found by solving\n",
    "\n",
    "$$ \\hat{\\alpha_i}(Y_i (X_i^T \\hat{\\alpha} + \\hat{\\beta}_0)) = 0$$\n",
    "\n",
    "for any support point $X_i$.  $\\hat{H}$ may be written as\n",
    "\n",
    "$$ \\hat{H}(x) = \\hat{a}_0 + \\sum_{i=1}^n \\hat{\\alpha}_i Y_i \\langle x, X_i \\rangle $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many software packages that will solve this problem quickly.  If there is no perfect linear classifier, then one allows overlap between the groups by replacing the condition $Y_i H(x_i) \\geq 1$ with\n",
    "\n",
    "$$ Y_i H(x_i) \\geq 1 - \\xi_i,\n",
    "\\quad \\xi_i \\geq 0,\n",
    "\\quad i = 1, \\dots, n\n",
    "$$ \n",
    "\n",
    "The variables $\\xi_1, \\dots, \\xi_n$ are called **slack variables**.\n",
    "\n",
    "We now maximize $\\sum_{i=1}^n \\alpha_i - \\frac{1}{2} \\sum_{i=1}^n \\sum_{k=1}^n \\alpha_i \\alpha_j Y_i Y_k \\langle X_i, X_k \\rangle$ subject to\n",
    "\n",
    "$$ 0 \\leq \\xi_i \\leq c, \\quad i = 1, \\dots, n $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\sum_{i=1}^n \\alpha_i Y_i = 0 $$\n",
    "\n",
    "The constant $c$ is a tuning parameter that controls the amount of overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.10 Kernelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a trick for improving a computationally simpler classifier $h$ called **kernelization**.  The idea is to map the covariate $X$ -- which takes values in $\\mathcal{X}$ -- into a higher dimensional space $\\mathcal{Z}$ and apply the classifier in the bigger space $Z$.  This can yield a more flexible classifier while retaining computational complexity.\n",
    "\n",
    "The standard example of this is illustrated in the figure below.  Let the covariate be $x = (x_1, x_2)$.  The $Y_i$'s can be separated into two groups using an ellipse.  Define a mapping $\\phi$  by\n",
    "\n",
    "$$ z = (z_1, z_2, z_3) = \\phi(x) = (x_1^2, \\sqrt{2} x_1 x_2, x_2^2) $$\n",
    "\n",
    "This $\\phi$ maps $\\mathcal{X} = \\mathbb{R}^2$ into $\\mathcal{Z} = \\mathbb{R}^3$.  In the higher dimensional space $\\mathcal{Z}$, the $Y_i$'s are separable by a linear decision boundary.  In other words, a linear classifier in a higher dimensional space corresponds to a non-linear classifier in the original space."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABKAAAAKyCAYAAADil6YWAAAgAElEQVR4AezdB5QUVdrGcd0VIyiCAdO6ooiBJCZEdBEDa8K4ICoIYsCAiGDA1UUUA4KioCRBxcUAggFQUBAkKpJkyTnnnCTq+53nftuzw0x3T89MV3dX1b/P6TNMd3VV3d+tYbqfufe9Bxg3BBBAAAEEEEAAAQQQQAABBBBAAAEEPBQ4wMN9s2sEEEAAAQQQQAABBBBAAAEEEEAAAQSMAIqLAAEEEEAAAQQQQAABBBBAAAEEEEDAUwECKE952TkCCCCAAAIIIIAAAggggAACCCCAAAEU1wACCCCAAAIIIIAAAggggAACCCCAgKcCBFCe8rJzBBBAAAEEEEAAAQQQQAABBBBAAAECKK4BBBBAAAEEEEAAAQQQQAABBBBAAAFPBQigPOVl5wgggAACCCCAAAIIIIAAAggggAACBFBcAwgggAACCCCAAAIIIIAAAggggAACngoQQHnKy84RQAABBBBAAAEEEEAAAQQQQAABBAiguAYQQAABBBBAAAEEEEAAAQQQQAABBDwVIIDylJedI4AAAggggAACCCCAAAIIIIAAAggQQHENIIAAAggggAACCCCAAAIIIIAAAgh4KkAA5SkvO0cAAQQQQAABBBBAAAEEEEAAAQQQIIDiGkAAAQQQQAABBBBAAAEEEEAAAQQQ8FSAAMpTXnaOAAIIIIAAAggggAACCCCAAAIIIEAAxTWAAAIIIIAAAggggAACCCCAAAIIIOCpAAGUp7zsHAEEEEAAAQQQQAABBBBAAAEEEECAAIprAAEEEEAAAQQQQAABBBBAAAEEEEDAUwECKE952TkCCCCAAAIIIIAAAggggAACCCCAAAEU1wACCCCAAAIIIIAAAggggAACCCCAgKcCBFCe8rJzBBBAAAEEEEAAAQQQQAABBBBAAAECKK4BBBBAAAEEEEAAAQQQQAABBBBAAAFPBQigPOVl5wgggAACCCCAAAIIIIAAAggggAACBFBcAwgggAACCCCAAAIIIIAAAggggAACngoQQHnKy84RQAABBBBAAAEEEEAAAQQQQAABBAiguAYQQAABBBBAAAEEEEAAAQQQQAABBDwVIIDylJedI4AAAggggAACCCCAAAIIIIAAAggQQHENIIAAAggggAACCCCAAAIIIIAAAgh4KkAA5SkvO0cAAQQQQAABBBBAAAEEEEAAAQQQIIDiGkAAAQQQQAABBBBAAAEEEEAAAQQQ8FSAAMpTXnaOAAIIIIAAAggggAACCCCAAAIIIEAAxTWAAAIIIIAAAggggAACCCCAAAIIIOCpAAGUp7zsHAEEEEAAAQQQQAABBBBAAAEEEECAAIprAAEEEEAAAQQQQAABBBBAAAEEEEDAUwECKE952TkCCCCAAAIIIIAAAggggAACCCCAAAEU1wACCCCAAAIIIIAAAggggAACCCCAgKcCBFCe8rJzBBBAAAEEEEAAAQQQQAABBBBAAAECKK4BBBBAAAEEEEAAAQQQQAABBBBAAAFPBQigPOVl5wgggAACCCCAAAIIIIAAAggggAACBFBcAwgggAACCCCAAAIIIIAAAggggAACngoQQHnKy84RQAABBBBAAAEEEEAAAQQQQAABBAiguAYQQAABBBBAAAEEEEAAAQQQQAABBDwVIIDylJedI4AAAggggAACCCCAAAIIIIAAAggQQHENIIAAAggggAACCCCAAAIIIIAAAgh4KkAA5SkvO0cAAQQQQAABBBBAAAEEEEAAAQQQIIDiGkAAAQQQQAABBBBAAAEEEEAAAQQQ8FSAAMpTXnaOAAIIxBb4/fffbe/evbZnzx7bvXu3+7ce++OPP2zfvn1Zz+l5fc8NAQQQQAABBBBAAAEEEPCrAAGUX3uO80YAAd8LbNq0yWbOnGkTJ060UaNG2eTJk239+vW2Y8cOW7JkiU2ZMsXGjx9vEyZMsIULF7qgyveNpgEIIIAAAggggAACCCAQSgECqFB2O41GAIF0C2zZssV+/PFHe++99+ytt96yp556yp544gkbOHCgC50+/fRTe/vtt61FixZWt25da9eunW3YsCHdp83xEUAAAQQQQAABBBBAAIECCRBAFYiNFyGAAAIFF9CUusGDB1uPHj1sxowZtnXrVlu+fLk1adLE6tWrZ88995z17dvX5s2bZ506dbIyZcrYTTfdZEuXLi34QXklAggggAACCCCAAAIIIJBGAQKoNOJzaAQQCKfA/Pnz3eimSZMm2W+//eZqPimUevLJJ+3UU0+1Zs2a2dy5c23VqlXWs2dPFz49//zztnbt2nCC0WoEEEAAAQQQQAABBBDwvQABlO+7kAYggIDfBDS9bujQoW5KnYqO66Z6UI8++qhVqFDBTcnbuHGjq/m0evVqVydq5cqVrih5pK27du0ybbNu3Tpbs2aNu2tan4IsFTHnhgACCCCAAAIIIIAAAghkkgABVCb1BueCAAKhEPjqq69yFRX/9ddfrXbt2larVi375ptv3MgoYURWxMseKimsUsHysWPHuvvIkSNtwIAB9vnnn9vPP//swqxIsBUKUBqJAAIIIIAAAggggAACGS9AAJXxXcQJIoBA0AQ0Ymnnzp37jVRSzadq1aq5OlCqC7V3796Yze7fv7+bwjdr1iwXVO3evds0na9Ro0Z222232aBBg2zz5s377T/mzngCAQQQQAABBBBAAAEEEEiBAAFUCpA5BAIIIBBPYN++fda6dWs7++yz7cUXX3S1n7KPeMr52vvuu8+tjjd79uysoEqBVfv27d0UPtWSWrBggWm/3BBAAAEEEEAAAQQQQACBTBAggMqEXuAcEEAg1ALr16+3+++/34VHnTt3dqOXIiCq6aRC5dmn1D3wwANWpUoVGzFihGn0U+SmVfXOPfdca9CggWl0FAFURIavCCCAAAIIIIAAAgggkG4BAqh09wDHRwABXwls377dVAA83gileA3S6zRaKfvrVf/p5ptvtiuuuMLVcdIxIrcVK1bYlClTbMeOHZGHbNSoUW67ZcuWZYVMCqJee+01O+200+zBBx90q+gRQGWR8Q8EEEAAAQQQQAABBBBIswABVJo7gMMjgIC/BBT+qAC4QqiC3FRAXDWetLpdZMU61XSqWrWq1alTx1RQPLJvfR0/frz169fPrXgXOZ7qRymkitSJUpilEU8PPfSQVa9e3bp37+72n33UVOS1fEUAAQQQQAABBBBAAAEE0iFAAJUOdY6JAAK+FFDQo/pKzZs3dwFPQRqhFfAeffRR6927t9vHli1brEOHDm7qnIqIq5i4RjNp9NKiRYtM2w8ePNi2bdsW83AqON6tWze79dZbrVWrVi6MKsworZgH4gkEEEAAAQQQQAABBBBAoIACBFAFhONlCCAQPoGNGze62ktnnnmmTZs2bb+6TIlqaHpcqVKlXBHx6dOn208//WQdO3a0q6++2lRcXHWdNmzYYJp6N2TIEOvTp48tXLgwa7RTzuNoJNT3339vjz/+uL300ktuup5GSHFDAAEEEEAAAQQQQAABBDJJgAAqk3qDc0EAgYwWGDBggJ100kl2wAEH2EcffbRfXaZET1yr3F1zzTWuXtO3337r9jN8+HBTAfF//etf9uGHH9qPP/7oQiUdTyOiYgVKCp8UWGkFPYVYqiWlkVI5a0wlem5shwACCCCAAAIIIIAAAgh4JUAA5ZUs+0UAgUAJqJ5S48aNrWjRoi6Aql27thullN9Grlq1yk2pGzRokA0cONAmTJjg6jspOBo7dqx9+eWX7nEFSxr5pDpR0W4KmbR9u3bt3HS+uXPnuqBq3bp17rwUWmUvdB5tHzyGAAIIIIAAAggggAACCKRKgAAqVdIcBwEEfC2g4Kh8+fJ24IEHugDquOOOs4kTJ2atQpfKxqk+lIqOt2/f3t577z037U5FzRU+afSUpu7p3xQhT2WvcCwEEEAAAQQQQAABBBCIJ0AAFU+H5xBAAIH/Cvz73/92tZs0/S5y17Q3FRFP9W3evHmuEPqdd97ppu116tTJOnfubPr63HPPuVBKNaQIoFLdMxwPAQQQQAABBBBAAAEEYgkQQMWS4XEEEEDgvwKa7nb33Xfb4YcfnhU+KYS69tprbcmSJSl30qp4WjFP9yZNmljTpk3dXf9+/vnn3QgoFUxnCl7Ku4YDIoAAAggggAACCCCAQAwBAqgYMDyMAAIIRATmz59vWvkuMvIp8lX1oMaMGRNzhbrI6/mKAAIIIIAAAggggAACCIRdgAAq7FcA7UcAgTwF3nnnHTv22GNzBVAKol555RXbtGlTnvtgAwQQQAABBBBAAAEEEEAgzAIEUGHufdqOAAJ5Cuzevdtq1aplhxxyiAugIkXII6OgLr30UrdaXZ47YgMEEEAAAQQQQAABBBBAIMQCBFAh7nyajgACeQv85z//sdKlS2eNfvrTn/6U9W+FUAqmhg0bZnv27Ml7Z2yBAAIIIIAAAggggAACCIRUgAAqpB1PsxFAIDGBl19+2UqUKLFf6BQZ/RT52qJFC1u3bl1iO2QrBBBAAAEEEEAAAQQQQCCEAgRQIex0mowAAokJbN++3a666iorUqSIHXbYYZZz9JNWxdNjFStWtDlz5rDqXGKsbIUAAggggAACCCCAAAIhFCCACmGn02QEEEhMYPTo0Xbqqae6EVCVKlVyIVRk1JO+XnbZZVaqVCkXUH311Ve2a9euxHbMVggggAACCCCAAAIIIIBAyAQIoELW4TQXAQQSF3jmmWfslFNOsYceesgaNWpkxYsX328q3gsvvGBNmjSxE044wRo3bmyrV69OfOdsiQACCCCAAAIIIIAAAgiESIAAKkSdTVMRQCBxgc2bN1uNGjWsXr16tmjRImvZsmWuAKpNmza2ePFie+yxx6xKlSo2ffp0+/333xM/CFsigAACCCCAAAIIIIAAAiERIIAKSUfTTAQQyJ/AkCFD7P7773eh0r59++yf//xn1ABq48aNtmrVKmvQoIF9/fXXtmPHjvwdiK0RQAABBBBAAAEEEEAAgRAIEECFoJNpIgII5F/gk08+sVmzZtnevXvdi+MFUNpg3rx51rdvX9u0aVP+D8YrEEAAAQQQQAABBBBAAIGACxBABbyDaR4CCBRMQKOa9uzZk/XivAIobbh8+XLbvXt31mv4BwIIIIAAAggggAACCCCAwP8LEEBxJSCAAAIJCCQSQCWwGzZBAAEEEEAAAQQQQAABBEIpQAAVym6n0QggkF8BAqj8irE9AggggAACCCCAAAIIIPA/AQKo/1nwLwQQQCCmAAFUTBqeQAABBBBAAAEEEEAAAQTyFCCAypOIDRBAAAGLuwoePggggAACCCCAAAIIIIAAAvEFCKDi+/AsAggg4AQYAcWFgAACCCCAAAIIIIAAAggUXIAAquB2vBIBBEIkQAAVos6mqQgggAACCCCAAAIIIJB0AQKopJOyQwQQCKIAAVQQe5U2IYAAAggggAACCCCAQKoECKBSJc1xEEDA1wIEUL7uPk4eAQQQQAABBBBAAAEE0ixAAJXmDuDwCCDgDwECKH/0E2eJAAIIIIAAAggggAACmSlAAJWZ/cJZIYBAhgkQQGVYh3A6CCCAAAIIIIAAAggg4CsBAihfdRcniwAC6RIggEqXPMdFAAEEEEAAAQQQQACBIAgQQAWhF2kDAgh4LkAA5TkxB0AAAQQQQAABBBBAAIEACxBABbhzaRoCCCRPgAAqeZbsCQEEEEAAAQQQQAABBMInQAAVvj6nxQggUAABAqgCoPESBBBAAAEEEEAAAQQQQOC/AgRQXAoIIIBAAgIEUAkgsQkCCCCAAAIIIIAAAgggEEOAACoGDA8jgAAC2QUIoLJr8G8EEEAAAQQQQAABBBBAIH8CBFD582JrBBAIqQABVEg7nmYjgAACCCCAAAIIIIBAUgQIoJLCyE4QQCDoAgRQQe9h2ocAAggggAACCCCAAAJeChBAeanLvhFAIDACBFCB6UoaggACCCCAAAIIIIAAAmkQIIBKAzqHRAAB/wkQQPmvzzhjBBBAAAEEEEAAAQQQyBwBAqjM6QvOBAEEMliAACqDO4dTQwABBBBAAAEEEEAAgYwXIIDK+C7iBBFAIBMECKAyoRc4BwQQQAABBBBAAAEEEPCrAAGUX3uO80YAgZQKEECllJuDIYAAAggggAACCCCAQMAECKAC1qE0BwEEvBEggPLGlb0igAACCCCAAAIIIIBAOAQIoMLRz7QSAQQKKUAAVUhAXo4AAggggAACCCCAAAKhFiCACnX303gEEEhUgAAqUSm2QwABBBBAAAEEEEAAAQRyCxBA5TbhEQQQQCCXAAFULhIeQAABBBBAAAEEEEAAAQQSFiCASpiKDRFAIMwCBFBh7n3ajgACCCCAAAIIIIAAAoUVIIAqrCCvRwCBUAgQQIWim2kkAggggAACCCCAAAIIeCRAAOURLLtFAIFgCRBABas/aQ0CCCCAAAIIIIAAAgikVoAAKrXeHA0BBHwqQADl047jtBFAAAEEEEAAAQQQQCAjBAigMqIbOAkEEMh0AQKoTO8hzg8BBBBAAAEEEEAAAQQyWYAAKpN7h3NDAIGMESCAypiu4EQQQAABBBBAAAEEEEDAhwIEUD7sNE4ZAQRSL0AAlXpzjogAAggggAACCCCAAALBESCACk5f0hIEEPBQgADKQ1x2jQACCCCAAAIIIIAAAoEXIIAKfBfTQAQQSIYAAVQyFNkHAggggAACCCCAAAIIhFWAACqsPU+7EUAgXwIEUPniYmMEEEAAAQQQQAABBBBAYD8BAqj9OPgGAQQQiC5AABXdhUcRQAABBBBAAAEEEEAAgUQECKASUWIbBBAIvQABVOgvAQAQQAABBBBAAAEEEECgEAIEUIXA46UIIBAeAQKo8PQ1LUUAAQQQQAABBBBAAIHkCxBAJd+UPSKAQAAFCKAC2Kk0CQEEEEAAgQwXWLNmjf3000+2du3aDD9TTg8BBBDIW4AAKm8jtkAAAQSMAIqLAAEEEEAAAQRSLfDFF1/Yueeea19++WWqD83xEEAAgaQLEEAlnZQdIoBAEAUIoILYq7QJAQQQQMBrgT/++MO2bdtmy5cvtyVLltiGDRts9+7dpsd1++2332zr1q3u6++//+716fhu/wRQvusyThgBBOIIEEDFweEpBBBAICJAABWR4CsCCCCAAAKJCShkmjdvnn3yySfWqlUra9GihXXs2NF++eUX27Jli23cuNEmTJjgvl+8eLHt2rUrsR2HaCsCqBB1Nk1FIAQCBFAh6GSaiAAChRcggCq8IXtAAAEEEAiXgAKmtm3b2u23327169e3u+++22rVqmXPPfecffPNN/bpp59ajx49bNKkSbZ+/Xrbu3dvuIASaC0BVAJIbIIAAr4RIIDyTVdxogggkE4BAqh06nNsBBBAAAE/CmikU69evWzs2LG2YsUKU0Ht6dOnW+/eva1p06bWrFkzGzBggJuWx/S76D1MABXdhUcRQMCfAgRQ/uw3zhoBBFIsQACVYnAOhwACCCDge4HZs2fb/PnzbceOHVk1nzT17ocffrAuXbrYoEGDbNWqVbZv3z7ft9WrBhBAeSXLfhFAIB0CBFDpUOeYCCDgOwECKN91GSeMAAIIIJBmARUYz15wfPv27TZx4kTr16+fjRw50o2Iyhk+KaxSwfIFCxbY3Llzbc6cOe57PR7GUVIEUGm+iDk8AggkVYAAKqmc7AwBBIIqQAAV1J6lXQgggAACqRBQgKQpeZ9//rkLn1avXr3fyCeFS5s2bbJx48a5ouU9e/a0d99911599VV74403bMiQIS6wCloIpRFg//nPf2zy5MlR7+3bt7fSpUvbm2++GfX5yOu0H2popeJK5hgIIFAYAQKowujxWgQQCI0AAVRoupqGIoAAAggkUUAr4W3bts2tdhcZ+ZQzfNLhFFD17dvXBS0qSq7RUho9NW3aNFcr6rbbbnPhlabwBemmelh16tSxmjVrRr1XqFDBjjjiCDvvvPOiPh953ccff2ybN28OEg1tQQCBAAoQQAWwU2kSAggkX4AAKvmm7BEBBBBAINgCCp82bNjgRjVFG/mkgGnnzp1uJJRWwbvnnnvs/vvvd2GVntNNo3q0Ul6VKlWsRYsWtnjx4kChDRs2zNq0aWPPPPNM1PvNN99sJUuWtFtvvTXq85HXqa6WQjtuCCCAQCYLEEBlcu9wbgggkDECBFAZ0xWcCAIIIICATwQ0pe7777+3r776ysaPH29r167NmnancEph0owZM2zr1q22bt06a9iwoVWuXNnViNKIqMhNI6MUQN17772uLlTkca++KvTKlKl+1IDyqpfZLwIIpEOAACod6hwTAQR8J0AA5bsu44QRCIWARo9ERpCEosE00jcCKkCuVe46d+5sI0aMcAFTpOB4pN7T0KFD3TYKpnQda7s+ffrYvHnzsuoZ7dmzx7p27WrlypWzBx54wK2q5yWCgjHVZFIglgk3AqhM6AXOAQEEkiVAAJUsSfaDAAKBFiCACnT30jgEfCswc+ZMmzp1qm3cuDFjRmz4FpMTT5qAgiYVHH/qqafslVdecbWd9P3SpUtNU+309dtvv3VFxlVcXCOlFPwotFK9KIVO+l53rYb39NNP25VXXmmdOnVyo6iSdqJRdqTg6bHHHrPhw4dnxM8UAVSUTuIhBBDwrQABlG+7jhNHAIFUChBApVKbYyGAQKICGi2iws7Lli3LmtqU6GvZDgGvBBSIqm6TVm777LPP3CioF154wdq2bWvvvPOOC6WaNGlib731ls2aNcsFTtHORVPzVFy7bt26LoSaMmWKK0webdtkPTZgwABT4e8OHTpkRFFvAqhk9Sz7QQCBTBAggMqEXuAcEEAg4wUIoDK+izhBBEInoGlMr7/+ug0cONDV0AkdAA3OWAGFSl9//bUtWrTIBaOa0ta8eXOrVq2aXXTRRW40k4pnjx071q1+F60hqgE1atQoV3i7VatWbluNjtKoKK9uqv2kUVslSpRwRb9VnyrdNwKodPcAx0cAgWQKEEAlU5N9IYBAYAUIoALbtTQMAd8KaMl1jdLQVKHsBZt92yBOPDACmhq6evXqrFF5CktV30mhU6NGjax9+/am0Uyq+xTtpql448aNs9dee82Novr555/daCQFRF4GUJoaqKl+Bx54oJ1wwgn2zTffZLUh2nmm4jECqFQocwwEEEiVAAFUqqQ5DgII+FqAAMrX3cfJIxBIAX3I1/SkadOmeT4tKZCANMozAU3BUygaCYv0dfny5S5U+uGHH2zy5Mn7FSXPfiKqHzVp0iTr2LGjffDBBzZ9+nTbvn27q3OmUGvXrl3ZN0/qvz/55BMrW7asHXDAAe7+8ssvp70YOQFUUruYnSGAQJoFCKDS3AEcHgEE/CFAAOWPfuIsEQiTgFYYGzx48H4jTcLUftoaPAGNcJo/f74rTt6lSxcbP368rVy50oVAGhGl0X4bNmzwpOG7d++2hx9+2IoVK5YVQF199dX266+/enK8RHc6evRoN2pszJgxib6E7RBAAIGMFSCAytiu4cQQQCCTBAigMqk3OBcEEJCAPqB/9913tmXLlqyRJsgg4FcBhU9z58411Xu66667rGXLlvb222+7AuZa/U6Pv//++7Zq1SpPmjh79mxXoyoy+klfixcvbv37949ZJN2TE2GnCCCAQIAFCKAC3Lk0DQEEkidAAJU8S/aEAAIFF9D0JBViXrFihT377LP2+eefx5zKVPCj8EoEUi+guk+qufTQQw9Zw4YN7dFHH7WmTZu6+2OPPWb6PaznVfvMi1vXrl3ttNNOyxr9FAminn76affz5sUx2ScCCCAQNgECqLD1OO1FAIECCRBAFYiNFyGAQJIEVPdGBZI1JWno0KFuVEjjxo1dEXKtgqeCzpqapICKGwII5E9A4Vf9+vXtsMMOyxVAXXLJJe7nLn97ZGsEEEAAgWgCBFDRVHgMAQQQyCFAAJUDhG8RQCBlAiq8rNCpbdu21qJFC+vWrZu99NJLbgpenz597IUXXnCjRXr16mVLliwxTWXihgACiQuo6HmVKlVyhU8aBXX44YebipN7Wfw88TNlSwQQQMDfAgRQ/u4/zh4BBFIkQACVImgOgwACWQJaOWzZsmVuKfo6deq4peu1IphqPrVr186+//57tzKYvu/QoYPVqlXLFW9et25d1j74BwII5C3w5ptv2sknn+wCqAMPPNCKFClif/rTn7ICKU0HVLjLDQEEEECgcAIEUIXz49UIIBASAQKokHQ0zUQggwQ05U71Z6pWrWrdu3d3dWg0uknL22s01IgRI0xTh3SbOXOmK9x8/fXXu2XrM6gZnAoCGS2wdetWq127th188MEucFLwdOSRR2Z9r1FQlSpVMq1Cp1CYGwIIIIBAwQUIoApuxysRQCBEAgRQIepsmopABgjs3LnTXnzxRStdurRbGn7WrFlZU+sUNmkFvMmTJ5uWjtdt48aNrnjzGWecYVqunhsCCCQm8OOPP1rlypWzRjtFio/rq8IojYg66KCDrEePHi78TWyvbIUAAgggEE2AACqaCo8hgAACOQQIoHKA8C0CCHgqoHDp0ksvtdNPP92t/KVAKnLTynefffaZK0oeKTqulcEeeeQRK1GihOkDNTcEEMhbQCOaFPQef/zx7mfn0EMP3S+IKlq0qHtco6MaNGhg8+bNy3unbIEAAgggEFOAAComDU8ggAAC/xMggPqfBf9CAAHvBV5++WU74YQT7J577rHZs2fb77//7g6qr5H6T9u2bcuaErRy5Upr1KiRHXfccTZq1CjvT5AjIBAAAdVL07RV/dxoFbwyZcrsF0Dp8bvuusvKly9vZ511lg0bNizrZzEAzacJCCCAQMoFCKBSTs4BEUDAjwIEUH7sNc4ZAf8K3HTTTa4GjYqLr1+/Pito2r59u73++us2evRoyz4qSqHTtdde6z4oTxF4kOUAACAASURBVJgwwb8N58wRSKHAoEGDrFq1am6a61dffeXqrWWfgqcA6ptvvrG33nrLypYta++8845bBCCFp8ihEEAAgUAJEEAFqjtpDAIIeCVAAOWVLPtFAIFoAtWrV7fDDjvMvv7666w6T9puwYIF1rNnT/vPf/5je/bscS/VNDzVhKpYsaLdfPPNbsRUtH3yGAII/E9ABf1bt25tTZo0sRkzZrifKRX8zxlADR061DTaUFP1mjVrZqrHxg0BBBBAoGACBFAFc+NVCCAQMgECqJB1OM1FIM0CV111lZ144ok2fPhwi9R50ikNHjzYNFJj+fLl7nHVsFEo1bBhQytXrpxFRkyl+fQ5PAIZL7B27Vrr2LGjTZo0yf0sKdSNFUCpMZqup5FQqs8WmRKb8Y3kBBFAAIEMEyCAyrAO4XQQQCAzBQigMrNfOCsEgirQuHFjK1mypH388cemaXeR29tvv23ff/+9mwakD8GrVq2yV155xX1w1kiOiRMn2q5duyKb8xUBBGIILF682FasWJE1kjCvAEq7yfmaGLvmYQQQQACBGAIEUDFgeBgBBBDILkAAlV2DfyOAgNcCQ4YMcbVptLKdpvxoFJSCpRdeeMFGjBjhQikVHu/UqZPdeOONbhqR6kBlL0zu9TmyfwSCJJBIABWk9tIWBBBAIB0CBFDpUOeYCCDgOwECKN91GSeMgK8FNOqpR48eVrduXevVq5er66SpP23atDEVTh4/fry999579uijj7oQSh+e9RpNyeOGAAL5FyCAyr8Zr0AAAQTyK0AAlV8xtkcAgVAKEECFsttpNAJpFdi0aZMNGDDAXnrpJevevbu9/PLLbgSU6tBoJNS7775r48aNM9WyUUFywqe0dhcH97kAAZTPO5DTRwABXwgQQPmimzhJBBBItwABVLp7gOMjEE4BTalTwfGFCxday5Yt7aOPPrIpU6bYvHnzbM2aNW5aHsFTOK8NWp1cAQKo5HqyNwQQQCCaAAFUNBUeQwABBHIIEEDlAOFbBBBIqcCOHTtM/w/98MMPbqodq3CllJ+DhUCAACoEnUwTEUAg7QIEUGnvAk4AAQT8IEAA5Yde4hwRCK7A3LlzrV27dm4JeE2344YAAskVIIBKrid7QwABBKIJEEBFU+ExBBBAIIcAAVQOEL5FAIGUCgwcONB69+5tS5YscSvipfTgHAyBEAgQQIWgk2kiAgikXYAAKu1dwAkggIAfBAig/NBLnCMCwRVQ4fERI0aw0l1wu5iWpVmAACrNHcDhEUAgFAIEUKHoZhqJAAKFFSCAKqwgr0cAgcII9OnTx2bNmmV79+4tzG54LQIIxBAggIoBw8MIIIBAEgUIoJKIya4QQCC4AgRQwe1bWoYAAggggAABFNcAAggg4L0AAZT3xhwBAQQCIEAAFYBOpAkIIIAAAgjEECCAigHDwwgggEASBQigkojJrhBAILgCBFDB7VtahgACCCCAAAEU1wACCCDgvQABlPfGHAEBBHwisGPHDps+fbpb5nzy5Mn7fW3UqJEVK1bMDjjggKz7I488YiNHjtxvO71uzpw5tnv3bp+0mtNEAAEEEEAAAQIorgEEEEDAewECKO+NOQICCPhEYPbs2Va/fn2rWbNmrnvp0qWtSJEiWeGTgqgyZcpYjRo1cm3brFkzW716tU9azWkigAACCCCAAAEU1wACCCDgvQABlPfGHAEBBHwisHTpUmvbtq0988wzue5Vq1a1Qw89dL8A6vLLL7fHH38817ZdunSxjRs3+qTVnCYCCCCAAAIIEEBxDSCAAALeCxBAeW/MERBAIAAC1IAKQCfSBAQQQAABBGIIEEDFgOFhBBBAIIkCBFBJxGRXCCAQXAECqOD2LS1DAAEEEECAAIprAAEEEPBegADKe2OOgAACARAggApAJ9IEBBBAAAEEYggQQMWA4WEEEEAgiQIEUEnEZFcIIBBcAQIo7/t25cqVtn79etu3b5/3B+MICCCAAAIIZBMggMqGwT8RQAABjwQIoDyCZbcIIBAsAQIo7/vzxRdftN69e9uWLVu8PxhHQAABBBBAIJsAAVQ2DP6JAAIIeCRAAOURLLtFAIFgCRBAed+f5513njVt2tRWr17t/cE4AgIIIIAAAtkECKCyYfBPBBBAwCMBAiiPYNktAggES4AAyvv+JIDy3pgjIIAAAghEFyCAiu7CowgggEAyBQigkqnJvhBAILACBFDedy0BlPfGHAEBBBBAILoAAVR0Fx5FAAEEkilAAJVMTfaFAAKBFSCA8r5rCaC8N+YICCCAAALRBQigorvwKAIIIJBMAQKoZGqyLwQQCKwAAZT3XUsA5b0xR0AAAQQQiC5AABXdhUcRQACBZAoQQCVTk30hgEBgBQigvO9aAijvjTkCAggggEB0AQKo6C48igACCCRTgAAqmZrsCwEEAitAAFW4rt27d69t2bLFNm3aFPNeoUIFa9y4sc2dOzfmNlu3brXff/+9cCfDqxFAAAEEEMghQACVA4RvEUAAAQ8ECKA8QGWXCCAQPAECqML16apVq+yDDz6wDh06xLyfdNJJdvnll9tLL70Uc5tPPvnEhVOFOxtejQACCCCAwP4CBFD7e/AdAggg4IUAAZQXquwTAQQCJ0AAVbgunTVrlt1yyy12wQUXxLwffvjhdvzxx1vFihVjbtOwYUNbunRp4U6GVyOAAAIIIJBDgAAqBwjfIoAAAh4IEEB5gMouEUAgeAIEUIXr0+3bt9ucOXNs2rRpMe9nnXWW3X333fbjjz/G3GbevHm2a9euwp0Mr0YgzQK7d+82TSddv369aXTgokWL3M/H9OnTbfLkyfbTTz/ZmDFj3H3EiBE2bNgwGzp0aNy7fm5Gjx7tXjNu3DibMGGCTZ061WbOnGn6uVmyZImtWLHCHXPbtm22b9++NCtweAQyS4AAKrP6g7NBAIFgChBABbNfaRUCCCRZgAAqyaBRdkcR8igoPOQ7gT/++MOFpJs3b7bVq1e7cEkjABUsKRj64YcfrE+fPta5c2d79dVX7ZlnnrFGjRrZbbfdZldddZWdf/75duqpp1qpUqXciECNDDzwwAPtgAMOiHsvVqyYHXfcce41f/nLX+zcc8+1atWq2bXXXmt169Z19dWaN29ur7zyinXr1s0GDBjgwl4FVQq+FixY4AIq1WlTyKt2cEMgTAIEUGHqbdqKAALpEiCASpc8x0UAAV8JEEB5310EUN4bc4TkCWgEkUYSKWRauHChG7U3fvz4rICpY8eO9uyzz7pw6YYbbrALL7zQTjnlFDv44INjBkl6TkHS0Ucf7QKoE044wXQ/+eST7a9//auVLl066l3PR7bVNNYSJUpY0aJF7ZBDDrE//elPMY931FFHuaBKwVe9evXsySeftDfffNMFZBpxpZFYU6ZMcaOzNIJq3bp1ptGMLASQvOuIPWWOAAFU5vQFZ4IAAsEVIIAKbt/SMgQQSKIAAVQSMWPsigAqBgwPp1VAI4F27NjhgiZNZdNIJk11GzRokBtJ9Nxzz9k999xjNWrUsLJly1q0EUtFihRxwdKxxx5rGp105plnWvny5a1y5cp2ySWXuOL7V155pdWuXdseeOAB00ill19+2V5//XV3f/vtt+3999+3Xr16Rb2/9dZbWdu2adPGnnrqKbefO+64w/7+979b9erV7dJLL3UhWKVKlUzTXTXKSiOmFHgddNBBuUZZHXbYYW6bKlWquPptDz30kFsgoGfPnjZ48GAbO3as6QO7wjcFUzt37mTUVFqvVA5eWAECqMIK8noEEEAgbwECqLyN2CIkAvqrrurTbNy4kb/uhqTP89NMAqj8aBVsWwKogrnxquQJaGSPRjWtXLnSjfrR9DRNmfvwww9N/wco0FEhfQU3f/7zn/cbWaTRSxq5pNUcFTCpmP7FF1/swh8V4H/wwQetVatWbupd//793fS3SZMmuaL6mq7nZU0m/X5TrakZM2a4UU0DBw504Vnr1q3d1LybbrrJnedFF13kgrEzzjjDtUMjqRRE5RxFpcBKo64UbGlhAK1cqRUqhw8fbmqT6r2p3tSWLVs8bVfyep49IWAuUK1atep+P9f6WddoQG4IIIAAAskRIIBKjiN7CYCAwif9pXjIkCEUOQ5Afya7CQRQyRbNvT8CqNwmPOKdgAIfBT/Lli1zhbp/+eUXN7Kne/fubirarbfeauXKlbMjjjgia3SQajFphJNGMmkE0TnnnOMCqb/97W/2j3/8w5544gnr0KGD9evXz40Qmj9/vgu0/FBPSRYKjkaOHGmfffaZm4qnkVRaGKBmzZpuBJVGbJ199tmu7SVLlnTTCbPXp9KUPv0cq56VpvOpztW3337rQi/VmVq8eLFt2LDBVITdDybeXX3sORMFGAGVib3COSGAQNAECKCC1qO0p8AC+kv3iSee6GpfaCoBNwSyCxBAZdfw5t8EUN64slezPXv2uNGtqmOkIES1jTSFTnWaHnvsMVeoW9PSDj300KzRDxr1o/BJtZU0oknFwa+44go33e755583BVWaiqZRRVrRLsiByt69e90URE0/VKCktrds2dKFbgrf9LOrUVMqnC6z7COmVIfqtNNOs6uvvtruv/9+N1Xw888/t1GjRtmvv/7qpvAplFIfBdmQn8PMFyCAyvw+4gwRQMD/AgRQ/u9DWpAkAQKoJEEGdDcEUN53bK1atezFF1909WS8PxpHCKpAZBqdpoDNnDnThU1fffWVtW/f3k03U8FtFfTOXgxcgYlqIWn6nIIoFQxXYHLvvfda27ZtTVPmFJZoShkhyf5Xjuo/afSYRk1pVT+ZXXPNNabpfBotpcLrxYsXd3Wmsq/kp7BK0500hU+1rr744gsbM2aMC/Q0Ko3pe/s78533AgRQ3htzBAQQQIAAimsAgf8KEEBxKcQTIICKp5Oc57777jvTzyEjEJPjGZa97Nq1y4WWmu6mETrDhg2z9957z02Hu+6669zom+xhk+oXaaqYahhpCp3qNGn6dePGje2NN94w1UdScKXC44RNBbuKfvvtNzedT6OlOnXqZI8//rgpYFYh9AoVKrg+0RQ+jY6KTOFTv6hAu6b7aVTaO++840aYTZw40VT8XUEXU/cK1h+8KjEBAqjEnNgKAQQQKIwAAVRh9HhtoAQIoALVnUlvDAFU0knZIQIFElBAqYLas2bNcqObNJ1LK7+pVpGmyR155JFZoYZGNul7hU3nnnuuW3HuxhtvtCZNmphWllPNPwVXCja4eSugkWnLly93o5xU1P3ZZ591U/iqVavmCp8rfNJIqezF3VUAXYFV3bp1XR9Hamtp2qNGuCkk1H65IZAMAQKoZCiyDwQQQCC+AAFUfB+eDZEAAVSIOrsATSWAKgAaL0GgkAIagaQV3BQ2qHaTpmhptTWFFxpRU7p0aStSpEhW3SYFFlq1qkyZMq44uEbTPPzww67Wk1ayUg0o1RrilhkCkVDqxx9/tK5du1qzZs3s+uuvd6PSNH1P9bfUp5FRUgoUVfxd/dqiRQv74IMP3Mp7Cg6WLl3qanERSGVG3/rxLAig/NhrnDMCCPhNgADKbz3G+XomQADlGW0gdkwAFYhupBEZLqDAadu2bW5lOn0YVDDx/vvvW/PmzV1NJgUSkREykdFNqjFUvnx500gajYJq3bq1W0xCr2caXYZ3eJTT05RKjUr75ptvXG2o+vXrW/Xq1d1IKIVPmj4ZuQZUU0qBo55/9NFHXYiloFH1uhQ2qjg8gVQUZB6KKkAAFZWFBxFAAIGkChBAJZWTnWWygAqa6i+kWgY62n3AgAF2/PHHu7oTWoo62jZ6TKv18IY2k3vam3MjgPLGlb2GW0CBk0ICFZ2OBE49evRwNYC0uprqBCloUtCgkU4lSpRwo5606poKXWt007vvvuuCqrVr19q+ffvCDRrQ1q9Zs8ZGjx5t3bp1c9MnVbNL0y01Ak7XhOpHRQqcH3300a64uWp6denSxRRI6drSNabRdPz+DuhFkoRmEUAlAZFdIIAAAnkIEEDlAcTTwRH44YcfrGnTpm4ZaC0FnfN+88032+GHH25XXnmlW5Un5/OR7/v06eP+qh4cGVqSiAABVCJKbINA3gIalaQpddOmTXPBUSRUiBY4HXPMMXbGGWe4Veluuukme/LJJ+2jjz4yFabWSCmKhOftHcQtVOR86tSp7lp46qmn3HRMrbqna0WhZfZpmQqkLr/8chdq9uzZ011zms6pOmIabcU1FMQrpGBtIoAqmBuvQgABBPIjQACVHy229bXAoEGD7JZbbjEtwR3trjevWpFHUzlq1KgRdRu9Tqsr6YMPt3AJEECFq79pbfIE9CFfI1hUNHzs2LHWq1cvV7/niiuuyDXCKWfgpFpPn332mXut9sMNgWgCKiKvlQt1rbRs2TJuIHXiiSe60XPPPPOMffrpp+6anD17trtGqQ8WTTc8jxFAhaevaSkCCKRPgAAqffYcOcMEqAGVYR2SYadDAJVhHcLpZKyApsFpqvK8efNs/PjxplXqWrVqZTfccINbjS4yXUp1fDQ65fTTT88a4UTglLHd6qsTSzSQ0vTO0047zTQC+oUXXrAvv/zSfvnlF1u4cKFp2n5eUzr1xyhNIc1rO1/hhfhkCaBC3Pk0HQEEUiZAAJUyag6U6QIEUJneQ+k9PwKo9Ppz9MwVUE0dfVhftGiRTZ482RWPbtu2rdWpU8fOPPNMO/jgg119Hn3YL168uKvbo/o91113nRsJ9fHHH7vRK4xwytw+9vuZZQ+kIisoXnDBBS58yl7UXNfqueeeaw0aNLBOnTq5+lGaKhprup6Cqm+//Zbr1+8XyH/PnwAqIB1JMxBAIKMFCKAyuns4uVQKEEClUtt/xyKA8l+fccbeCSgs0ody1dIZPny4de7c2e677z7Th/rDDjvMBU4HHnigFStWzLRyWaRo+GOPPeam4Kl+z86dO707QfaMQByBSA0prbCoa1IF7StWrOhG6KkWpK5dFTVXPSlNFdV0vb59+9rPP/9sCxYssE2bNrlRTwpf33jjDXv88cddWKUglppSceAz/CkCqAzvIE4PAQQCIUAAFYhupBHJEIgXQOmDklbQoehtMqT9uQ8CKH/2G2edHAF90N68ebObVqcP4VqMQR/KtWhD9pXqFD6pxk65cuVMRcW1EpmKjOv/V61Axofz5PQHe0mugK7tcePGWceOHd3op8suu8zKli1rxx57bFZBc00dPeuss6xevXr21ltv2XfffedW1/vpp59Mq/JVrVrVVORcBfaZkpfc/knV3gigUiXNcRBAIMwCBFBh7n3avp9AvABq/vz5bqqI3mhSpHQ/ttB8QwAVmq6mof8V0LSl1atXu1FOWkX07bfftrp167qaTZFVxjStrkSJElamTBmrUqWK3XXXXdauXTsbMWKErV+/niXvuZp8KbBkyRJXD+r55583rb5YuXJlN5KvaNGipmteo6Miq+u1aNHC/VworCpVqpQ999xzLphiSqn/up4Ayn99xhkjgID/BAig/NdnnLFHAvECqHjPeXQ67DbDBAigMqxDOJ2kC2h0UqSWk/7P++KLL0zXvVb/1IftyLQkjXI66aST3JQlTV168skn3fQk1YAioE96t7DDNAtout6kSZOsa9eubpqpRvZpJFTO0VGauqfC+qojpfpnQ4cOdT9PjPpLcwfm4/AEUPnAYlMEEECggAIEUAWE42XBE4gXMsV7LngStCiaAAFUNBUeC4KAphbPnTvXRo0aZV26dHEfssuXL2+HHHKIG+mhD9WaZqeC4pFRTh06dLAxY8a4FcD4gB2Eq4A2JCqg6fgDBgywf/3rX250lMIo1TrTSMBIwX2NkFKhfabkJaqaGdsRQGVGP3AWCCAQbAECqGD3L63Lh4CK6aqOg+o65Bw6TwCVD8iAbkoAFdCOpVlu5bp77rnH1W5S2KQPzxrldPLJJ1ulSpXs2muvtZYtW1r//v1t8eLFjHLimgm9gEJXTTHVtPymTZvuNy1VPz+R+/HHH2+tWrWyOXPm8HPjg6uGAMoHncQpIoCA7wUIoHzfhTQgWQIaBTBr1izbsGFDrrolBFDJUvbvfgig/Nt3nHl8gSlTpliFChWsePHidsYZZ2SNclJBZhUcZ/GF+H48Gy4BFeRfs2aNff3113bvvffahRde6FZ51Iiniy++2C699FKrVq2a1ahRw01fve2221x4q+mt3DJbgAAqs/uHs0MAgWAIEEAFox9phccCBFAeA/tg9wRQPugkTrFAAhrx+cQTT7iRHJ988oktXLiQ0RoFkuRFYRDYu3evC2aHDBliuqvg/sSJE+3XX3+1BQsW2MqVK23t2rWmIv7c/CVAAOWv/uJsEUDAnwIEUP7sN846xQIEUCkGz8DDEUBlYKdwSkkTUPFwajkljZMdIYCADwX8GkAp8NSdRSB8eNFxygiEUIAAKoSdTpNzC+zcudM2b95smzZtinrXXzi1vPIHH3zgliWPtd2OHTv4EJebNxCPEEAFohtpBAIIIIAAAlEF/BpAvfvuu/bee+/ZqlWroraLBxFAAIFMEiCAyqTe4FzSJjB58mS3+pNWdop2b9GihR111FHWsGFDa9euXdRt9DoFVQqzuAVPgAAqeH1KixBAAAEEEIgI+DWAuuWWW6x+/fpuNdNIW/iKAAIIZKoAAVSm9gznlVKBfv36uYKhF1xwgUW7n3POOVakSBG30k3lypWjbqPXvf32225Z8pSePAdLiQABVEqYOQgCCCCAAAJpESCASgs7B0UAgZAJEECFrMNpbnQBrWgzY8YMmzZtWtR737597bjjjrM333zTJk2aFHUbvXbZsmW2b9++6AfhUV8LEED5uvs4eQQQQAABBOIKEEDF5eFJBBBAICkCBFBJYWQnQRegCHnQezjv9hFA5W3EFggggAACCPhVgADKrz3HeSOAgJ8ECKD81Fuca9oECKDSRp8xByaAypiu4EQQQAABBBBIugABVNJJ2SECCCCQS4AAKhcJDyCQW4AAKrdJ2B4hgApbj9NeBBBAAIEwCRBAham3aSsCCKRLgAAqXfIc11cCBFC+6i5PTpYAyhNWdooAAggggEBGCGRiAKW6olu3brVNmzbFvN9www12xx132MSJE2Nus2XLFtu7d29GOHMSCCAQbgECqHD3P61PUIAAKkGoAG9GABXgzqVpCCCAAAKhF8jEAGrt2rXWp08f69ChQ8x7+fLl7cILL7Rnn3025jb//ve/bfny5aHvYwAQQCD9AgRQ6e8DzsAHAgRQPugkj0+RAMpjYHaPAAIIIIBAGgUyMYBasGCB3XfffXbBBRfEvBcvXtxKlixp5cqVi7nNnXfeab/++msadTk0Aggg8P8CBFBcCQgkIDB16lSrWrWqDRo0yHbt2pXAK9gkaAIEUEHrUdqDAAIIIIDA/wQyMYDasWOHzZ8/36ZNmxbzfuWVV1qtWrXce9RY282ZM8e2b9/+v8byLwQQQCBNAgRQaYLnsP4SWLNmjX399de2cOFC03x8buETIIAKX5/TYgQQQACB8AhkYgCViP4tt9xi9evXt7lz5yayOdsggAACaRUggEorPwdHAAG/CBBA+aWnOE8EEEAAAQTyL0AAlX8zXoEAAgjkV4AAKr9ibI8AAqEUIIAKZbfTaAQQQACBkAgQQIWko2kmAgikVYAAKq38HBwBBPwiQADll57iPBFAAAEEEMi/AAFU/s14BQIIIJBfAQKo/IqxPQIIhFKAACqU3U6jEUAAAQRCIkAAFZKOppkIIJBWAQKotPJzcAQQ8IsAAZRfeorzRAABBBBAIP8CBFD5N+MVCCCAQH4FCKDyK8b2CCAQSgECqFB2O41GAAEEEAiJgF8DqIcffthatGhhixYtCklP0UwEEPCzAAGUn3uPc0cAgZQJEECljJoDIYAAAgggkHIBvwZQY8aMsXHjxtmWLVtSbsYBEUAAgfwKEEDlV4ztEUAglAIEUKHsdhqNAAIIIBASAb8GUCHpHpqJAAIBESCACkhH0gwEEPBWgADKW1/2jgACCCCAQDoFCKDSqc+xEUAgLAIEUGHpadqJAAKFEiCAKhQfL0YAAQQQQCCjBQig0ts9mzZtspkzZ5q+ckudwObNm23WrFm2YcOG1B2UI4VagAAq1N1P4xFAIFEBAqhEpdgOAQQQQAAB/wkQQKW3z4YPH2516tSxYcOGpfdEQnb0kSNH2p133mmDBw8OWctpbroECKDSJc9xEUDAVwIEUL7qLk4WAQQQQACBfAkQQOWLK+kbf/XVV1a+fHnr27dv0vfNDmMLDBw40M477zzr3bt37I14BoEkChBAJRGTXSGAQHAFCKCC27e0DAEEEEAAAQKo9F4DBFDp8SeASo97mI9KABXm3qftCCCQsAABVMJUbIgAAggggIDvBAig0ttlBFDp8SeASo97mI9KABXm3qftCCCQsAABVMJUbIgAAggggIDvBAig0ttlBFDp8SeASo97mI9KABXm3qftCCCQsAABVMJUbIgAAggggIDvBAig0ttlBFDp8SeASo97mI9KABXm3qftCCCQsAABVMJUbIgAAggggIDvBAig0ttlBFDp8SeASo97mI9KABXm3qftCCCQsAABVMJUbIgAAggggIDvBAigvO2yTZs22dKlS23RokVR7926dbOyZcvau+++G/X5yOs2btxo+/bt8/ZkA7T3zZs3x3Xv0aOHnXPOOfbWW2/hHqB+z+SmEEBlcu9wbgggkDECBFAZ0xWcCAIIIIAAAkkXIIBKOul+OxwwYIA98cQTdt9990W9X3XVVXb00UfblVdeGfX5yOs0UmrLli377ZtvYgt888031rx585imV199tZUoUcKuuOKKmNvIvn///qYwixsChRUggCqsIK9HAIFQCBBAhaKbaSQCCCCAQEgFCKC87fiPP/7YateubQo8ot0rVqxoRYsWtQoVIulmtgAAIABJREFUKkR9PvKa3r17E4Tko6s+++wzq1OnTkzTSpUqWbFixaxcuXIxt5F9r169TKPYuCFQWAECqMIK8noEEAiFAAFUKLqZRiKAAAIIhFSAACq9HU8NqPT4UwMqPe5hPioBVJh7n7YjgEDCAgRQCVOxIQIIIIAAAr4TIIBKb5cRQKXHnwAqPe5hPioBVJh7n7YjgEDCAgRQCVOxIQIIIIAAAr4TIIBKb5cRQKXHnwAqPe5hPioBVJh7n7YjgEDCAgRQCVOxIQIIIIAAAr4TIIBKb5cRQKXHnwAqPe5hPioBVJh7n7YjkESBsWPH2ty5c23Pnj1J3Gvm7IoAKnP6gjNBAAEEEEAg2QIEUMkWzd/+CKDy55WsrQmgkiXJfhIVIIBKVIrtEEAgrkDZsmWtRYsWtmHDhrjb+fVJAii/9hznjQACCCCAQN4CBFB5G3m5BQGUl7qx900AFduGZ7wRIIDyxpW9IhA6AQKo0HU5DUYAAQQQQCAwAgRQ6e1KAqj0+BNApcc9zEclgApz79N2BJIoQACVREx2hQACCCCAAAIpFSCASil3roONGDHC7rjjDhs2bFiu53jAO4FRo0bZXXfdZYMHD/buIOwZgWwCBFDZMPgnAggUXIAAquB2vBIBBBBAAAEE0itAAJVe/40bN9qcOXNs8+bN6T2RkB1906ZNroarvnJDIBUCBFCpUOYYCIRAgAAqBJ1MExFAAAEEEAioAAFUQDuWZiGAQEYJEEBlVHdwMgj4V4AAyr99x5kjgAACCCAQdgECqLBfAbQfAQRSIUAAlQpljoFACAQIoELQyTQRAQQQQACBgAoQQAW0Y2kWAghklAABVEZ1ByeDQGYKbN++3aZNm2aTJk2KeT/11FOtXr16piKSsbbT3P7du3dnZiPzOKt//vOfVrx4cTvggAOy7m3atDHVLOCGAAIIIIAAAv4WIIDyd/9x9ggg4A8BAih/9BNniUBaBWbNmmV333231axZM+b9iCOOsL/85S9Wo0aNmNs88cQTtnbt2rS2paAHJ4AqqByvQwABBBBAIPMFCKAyv484QwQQ8L8AAZT/+5AWIOC5wNKlS+21116zli1bxryXKFHCLrzwQnv88cdjbtO1a1ffrm5CAOX5ZcYBEEAAAQQQSJsAAVTa6DkwAgiESIAAKkSdTVMR8FKAGlBe6rJvBBBAAAEEEPBSgADKS132jQACCPy/AAEUVwICCCRFgAAqKYzsBAEEEEAAAQTSIEAAlQZ0DokAAqETIIAKXZfTYAS8ESCA8saVvSKAAAIIIICA9wIEUN4bcwQEEECAAIprAAEEkiJAAJUURnaCAAIIIIAAAmkQIIBKAzqHRACB0AkQQIWuy2kwAt4IEEB548peEUAAAQQQQMB7AQIo7405AgIIIEAAxTWAAAJJESCASgojO0EAAQQQQACBNAgQQKUBnUMigEDoBAigQtflNBgBbwQIoLxxZa8IIIAAAggg4L0AAZT3xhwBAQQQIIDiGkAAgaQINGzY0Lp3725bt25Nyv4ybSf//Oc/rXjx4nbAAQdk3du0aWMbN27MtFPlfBBAAAEEEEAgnwIEUPkEY3MEEECgAAIEUAVA4yUIIBA+AQKo8PU5LUYAAQQQCI8AAVR4+pqWIoBA+gQIoNJnz5ERQMBHAgRQPuosThUBBBBAAIF8ChBA5ROMzRFAAIECCBBAFQCNlyCAQPgECKDC1+e0GAEEEEAgPAIEUOHpa1qKAALpEyCASp89R0YAAR8JEED5qLM4VQQQQAABBPIpQACVTzA2RwABBAogQABVADReggAC4RMggApfn9NiBBBAAIHwCBBAhaevaSkCCKRPgAAqffYcGQEEfCRAAOWjzuJUEUAAAQQQyKcAAVQ+wdgcAQQQKIAAAVQB0HgJAgiET4AAKnx9TosRQAABBMIjQAAVnr6mpQggkD4BAqj02XNkBBDwkQABlI86i1NFAAEEEEAgnwIEUPkEY3MEEECgAAIEUAVA4yUIIBA+AQKo8PU5LUYAAQQQCI8AAVR4+pqWIoBA+gQIoNJnz5ERQMBHAgRQPuosn57q3r17bcuWLbZr1y77448/fNoKThsBBBDwpwABlD/7jbNGAAF/CRBA+au/OFsEEEiTAAFUmuBDdNhVq1bZhx9+aL/++qvt3r07RC2nqQgggED6BQig0t8HnAECCARfgAAq+H1MCxFAIAkCBFBJQGQXcQUUPJ199tnWvXt327p1a9xteRIBBBBAILkCBFDJ9WRvCCCAQDQBAqhoKjyGAAII5BAggMoBwrdJFyCASjopO0QAAR8J/P777270p76m40YAlQ51jokAAmETIIAKW4/TXgQQKJAAAVSB2HhRPgQIoPKBxaYIIBAogT179tiUKVNsyJAhpunI6aiDRwAVqEuKxiCAQIYKEEBlaMdwWgggkHwB/VV1586dtm3bNtu4caO7r1+/3lauXGkrVqzIui9dutQWLFhg8+fPz7o/9NBDduSRR9oBBxyQdW/WrJlNnjw5axttr9dm35f+vW7duqzjqcj0b7/9Zun6C2/yVdljsgQIoJIlyX4QQMBPAjt27LCRI0faDTfcYKeffrp17tzZ/c5MdRsIoFItzvEQQCCMAgRQYex12oxAQARUqHnTpk0WCZGWLFnigqOZM2fatGnTbNKkSfbzzz/bmDFj7IcffrBvv/3WPvnkE+vWrZu98cYb1r59e3v11Vft6aefthYtWmTdmzRpYvfcc4/Vq1cv667aPEWKFMkKnxRElStXzmrXrp21jbZ/5JFHrHnz5ln70n5ffvlla9eunTveu+++a7169bJBgwbZ0KFDbdSoUTZu3DibMGGC6c3vjBkzbN68ebZ48WJbvny5rV271r0RV2iVjr8IB+RS8UUzCKB80U2cJAIIJFFAv8O//PJLu+SSS7J+x+r3bb9+/UzBVCpvBFCp1OZYCCAQVgECqLD2PO1GwAcCGpKvEUOrV6+2RYsW2axZs9yIo7Fjx7pAqU+fPvbWW29lhUiNGze2+vXru7+i1qhRwypXrmxlypSxE044wQ4++OD9wqPsI5nS9e8//elPdswxx9hpp51m5cuXt+rVq9vf//53q1u3rj3wwAP2xBNP2EsvveTCso8++shNTVBgNXHiRBdUaZSWRm9pNJdGdhFQ+eCijnOKBFBxcHgKAQQCKfDTTz/ZpZdean/+85/3+x2t34f6w9GuXbtS1m4CqJRRcyAEEAixAAFUiDufpiOQCQIaxbRhwwbT6KXZs2e7GhAaETR8+HD3F1CNGFL9pUaNGtmNN95oF154of3lL3+xQw45ZL83q+kKkVJ5XAVWxx13nFWqVMkFVRql9dRTT7mA6uOPP7bvvvvOjfbSyC+NAlu4cKGtWbPGTfkjnMqEqz3+ORBAxffhWQQQCJ6Afk9p9HCxYsVy/U7/xz/+4UYy7927NyUNJ4BKCTMHQQCBkAsQQIX8AqD5CKRKYN++fa72kkbszJ07141kUs2Hvn372muvvWYavXTzzTdblSpV3Iigww8/3A488MBcb0hTGfj47ViaInjSSSfZ+eefb9dff701bNjQ/vWvf5lGTw0bNsx++eUXF0wtW7bMTV1M1Zv6VF1jmX4cXfsawfb9999HvXft2tWFq48//rh9/fXXUbfRazUSMJWjAjLdlfNDAAF/C2gKun5nHXbYYfv9zj/ooIPs0UcfddPSU1E3kQDK39cRZ48AAv4QIIDyRz9xlgj4SkAfjlV4W9PmVItJQ+y/+eYbV3tJ9Zbq1KljF1xwgR199NGmUT2pDHoUamn0VNGiRd3xdQ6Ru0YXabreiSeemHX/61//aqVLl456riVKlDA9ryl0Cn6yv0770vORfeur/sKrN9jpCNbU3nPPPddNT3zsscfszTffdHU3Ro8e7UadqYC6pjqq5gajpbz5cfviiy/ssssuc9NCNTU0510j+zRVVNeOCvHmfD7y/QsvvOBGtnlzluwVAQQQSL2A3iNUrVo113R5/e7SVHQF+F7/biKASn2/c0QEEAifAAFU+PqcFiOQVAG9Idy6datpVI3evGmEx6effuoKb99///125ZVXugAnZwHvZIVOCpMU7CjgKVWqlJ1yyikuECpbtqydc845rg7URRdd5GpMqC5UzZo196uxpILhkbs+2Ldt29YVDFfRcN179OjhiobXqlXLNCor+3nffvvt1qVLF+vZs6cLdCKv0dfWrVvbk08+mbVvHePBBx90NaquvfZa07kojLj44ovdiCUVND/rrLNc8KA2KAgrWbKkW3nv0EMP9Sy0UmimUWd33323Pf/88/bBBx+40VJa3U9TI1QgVqPXuBVeQCHfgAEDTLXLot1ff/11F2Sq/teHH34YdRu9TiPZVJSeGwIIIBAUAY1wev/9990fSnLWg9Lvw1SsjEcAFZSriXYggEAmCxBAZXLvcG4IZKCAwggVvVY4oZBCRUI1dahp06Z2xRVX2LHHHpvUUU0KmIoXL+7CJY000uo4Ki6uoqUKt+644w43fU8Fu7WiXceOHV2IotEmgwcPdgW7VVtqxYoVhaqFpDpUOo/sAVSbNm0KvFS0Rolphbs5c+a4EUiaIqdwonfv3vbOO++4IEyjxR5++GEXmF1zzTWuzZpep2BNo7L0plzBW7IDqiOPPNLV2tIUvg4dOrgV+8aPH++mTuqcVbfL679EZ+Cl7/kpUQPKc2IOgAACGSyg3y36Pa7RoDlHR6diZTwCqAy+ODg1BBAIjAABVGC6koYg4I2AVqJT6KC6TRp5oWHy7du3d/WFVBD8qKOOKvToHI0sUnCl6WzRAibVxNGbUv11VMdXke3ly5dbKmsYJTuAym9vqR80BWHKlCkuWNMIGY3WUvB25513WrSA6vjjj3dTDXO+kc8eoiXyb4WACr1UEFajxD7//HNX7HzGjBku2GPaXn57M/r2BFDRXXgUAQTCI6BFSfR7TSvE5vz95PXKeARQ4bnOaCkCCKRPgAAqffYcGYGMFdCUOtVvUuDUv39/N51M4YNCiMJMpdNrNYro5JNPdtPNFGBp1FSDBg1csWxNZUtXwJRXZ6Q7gMrr/KIFVBqhpWmQmnaoaXaqAXXqqae6qX2qNVTQWlQKtLSf6667zk0z7NWrl6mWlEJKjY5LRbHYvDz8+DwBlB97jXNGAIFkC6RrZTwCqGT3JPtDAAEEcgsQQOU24REEQiegaXXr1683TVUbM2aMm1LXqFEjF1gUJHBSsHHEEUeYRuComHLFihWtWrVqbpW7Zs2auWlyWuVr+vTptn37dl9M58r0ACreRavpfqo/9N1332UVgq9du7YL/zSlT/WyVAtKU+8KOlpK0yMVUr7xxhtu9Ta9kVdRcwVj3BITIIBKzImtEEAg+AITJ05M+cp4BFDBv65oIQIIpF+AACr9fcAZIJAWAdVa0JSuqVOn2pAhQ+y1116zW265xQUROQuA5hwGn/N7hRaaiqdRMQqbVGD73nvvdSvXfPzxx250jMIIPxez9nMAFesC02gl1fHSKDcVTn/kkUfcaCmFUgoOtYpfQQJI1aXSNSAz1eLSEtuLFy9mhb1YHfHfxwmg8gDiaQQQCJVAqlfGI4AK1eVFYxFAIE0CBFBpguewCKRDQCNhFARoap3q+KjItVZi0ypy+ZmOddBBB7ni1yqErbBC9YeaNGniRtdoBNXmzZt9MaopP30QxAAqWvtVz0lBiIqhP/XUU3bTTTe5lfrOPPNMO+6449wS2fm5VlQ/6rzzznMrAKqGl6bqzZs3z7Zt2xa4aySaZ34eI4DKjxbbIoBA0AVSvTIeAVTQryjahwACmSBAAJUJvcA5IOChgEYdafSRRrpoCfcHH3zQypUrl6+RLRoFoyLhZ5xxhlsd7cYbb7TmzZu7peJVFNsv0+gKwxyWACqnkabQaWpmv379smqBaTql6oFpFb78rsCnqXpaubBbt242duxYF4ju3LmTMMrM9OHnkksuMdXUUkDHDQEEEAi7QCpXxiOACvvVRvsRQCAVAgRQqVDmGAikWOCPP/4wrSQzc+ZMN71O4clFF11kGo2Sc/pcrO9Vw0lLIVeuXNmNgnn++eft008/Na18Fsa6PmENoHJeuvqL9NKlS+3bb7910zYVJlWtWtWFk5qGmZ8aUmeddZYLRD/77DO3sqGC0lSubJizben+Xis7vvnmm/bzzz+bRityQwABBBAw934mFSvjEUBxtSGAAALeCxBAeW/MERBImYBGIqnY9KhRo1xNH61SplAgkSlTCg5Uu0dTrRQoNGzY0Lp06eLq9/Bh2Fw9I63glz2w0ypzqqMU5psCKU2pUzipaZiq/aTV9jRdL9H6UQpGtUqfQr7Bgwe74JTV9MJ8VdF2BBBAYH+BvFbGU9Hywv5xjABqf3O+QwABBLwQIIDyQpV9IpBCAY0YWbFihQuKVGPn7rvvtpNOOskSKSR+8MEHW6lSpax8+fJ29dVXm/7C2LdvXzfCxc8Fw73gZwRUYqpr1651q+C1bt3arXqoGmEaSXf44YcnFIQqBL3++uvdanojRoywBQsWMBooMXq2QgABBAIt4PXKeARQgb58aBwCCGSIAAFUhnREGE9DH1RXrVrl65XR0tlvqougvwhqBTvVY1KIlMiIE4VOJ598sisefvvtt9srr7xi+qC/detW6vDE6VACqDg4MZ7SyDmtgPfuu+9agwYN7NJLLzUVrk80jNKqivXr13ehqKZ+Urg8BjQPI4AAAiERiLcy3osvvuhW91UZgoLcCKAKosZrEEAAgfwJEEDlz4utkyjw3nvvuVEOW7ZsSeJeg78rTbObNWuW9e/f302T01SnvOru6HkVEVdIdfPNN1uHDh3cSmcKsbglJkAAlZhTvK00PfTDDz+0e+65x9UkO/HEExMKTYsWLWo33HCD6f+MSZMmuWmPmvrHDQEEEEAgXAJeroxHABWua4nWIoBAegQIoNLjzlHNrF69elazZk1bs2YNHgkIqKi4lmn/4IMPTKvQ6UN59npE0f595JFHuppOqsvz3HPP2fDhw92KdQkcjk1yCBBA5QApxLf6AKHVE9u3b2+1atVywWjJkiXznDaqEX5age+NN95wK+ipaDlTRQvREbwUAQQQ8KFAXivjff755wV6r0MA5cOLgVNGAAHfCRBA+a7LgnPCBFB596U+qGuaolbFev31111x8LxWstPzqrlz8cUX20MPPWT9+vUzTXdkxEje3vG2IICKp1Pw5zStbtiwYfbMM8/YlVdeaWXKlHHhal6F8zWaT32i1y5evNgYzVfwPuCVCCCAgN8E9Ee5WCvj/e1vf3O/G/K7gAoBlN+uAs4XAQT8KEAA5cdeC8g5E0DF7kiFRSos/uOPP1rLli3dKKaDDjoo7oinEiVKWIUKFax27drWuXNntzJZmJe0j61bsGcIoArmlp9XKWxVEfz777/fLrnkEjvhhBMsr+te9cwefPBBGzhwoKuJRhCVH3G2RQABBPwrkOyV8Qig/HstcOYIIOAfAQIo//RV4M6UACp3l6pwpqYkjhkzxp588kk3kilefSc9pw/pGu2k7UeNGsWKYblZk/IIAVRSGBPaiQLY6dOnW9u2bd3qjH/9618tr5F/qnHWqFEjGzRokFvFkfA1IWo2QgABBHwtkMyV8QigfH0pcPIIIOATAQIon3RUEE+TAGr/XtVw8l9++cVatWplZcuWjTvyQyvZaYWw6tWr22uvvWZz5swxPnDv75ns7wigki2a2P6WLVvmio/feuut7ucirxX0VNi8SZMmbvoFq2wmZsxWCCCAgJ8FtDKeVlnVe6Ps9TBVKzM/K+MRQPn5KuDcEUDALwIEUH7pqQCeJwHU/3fq1q1bberUqa6w8nnnnRd3VbAjjjjCfQhX4eZu3bq5aXrUdkrNDwcBVGqcYx1Fq2Wqnln9+vXdVNOjjjoq7uqPp59+uqsrNXLkSFu3bh3FymPB8jgCCCDgcwG9D3r//fft3HPPzbWYhUaJqyzBxo0b82wlAVSeRGyAAAIIFFqAAKrQhOwgloA+MG7atCnmvU6dOqbV2ebOnRtzG70+qAHLzp07bcaMGda9e3e77LLL4k4xKl68uPvQ3aBBA+vfv79t3rzZNF2PW+oECKBSZx3vSHv27HGjmzTKqUqVKnbMMcfk+sCR/S/g5cqVszZt2rhC/kH+/ySeGc8hgAACQRdQ/T+NCNciLDlLF5x99tmWyMp4BFDeXyWq2zVp0iT3vt/7o/nvCNu3b3c+CxYsYHEV/3UfZ5ygAAFUglBsln+BHj162Jtvvhnzfv7557vi2hoeHW87BVlBuilQ0y/gPn362LXXXmuHHnrofkPGs3941vBxFRbXh22N5Mjvii5Bckt3Wwig0t0D+x9fP0dTpkyxZ5991q0OefTRR+f60JH9Z0lhVYcOHdxoQ4W/3BBAAAEEgiWgUgbNmzc31QTM/v+//p3IyngEUN5fDy+99JLVrFnTRo8e7f3BfHiE2bNn21VXXeXKcWgFa24IBFGAACqIvZohbbrxxhvtwgsvjHkvWbKkHXnkkVapUqWY2+j1K1euzJAWFf40NN1u3Lhxdt9997m253yDFPleodQ555xj9957L4XFC8+elD0QQCWF0ZOd/Prrr245bv1/of9TDjzwwFwfPvSzpb+KX3/99fbVV1+5Yv/79u3z5HzYKQIIIIBAegT0Bz5N1S5WrFiu3wP/+Mc/TEXLNZI22o0AKppKch8jgIrvSQAV34dngyFAABWMfszIVug/0WnTpsW833DDDW6pdY3sibddrDcKGdnoGCcVGfWkUWEa0RRraXkV0DzzzDNN0xO//fZbY6RGDNA0PEwAlQb0fBxSP2MKdxs3bmwVK1Y01UuLFUSdfPLJ1rp1azeCip+xfCCzKQIIIOADAYVMeo952GGH7RdC6b3Xo48+avPmzYta3oEAyvvOJYCKb0wAFd+HZ4MhQAAVjH70ZSvCUoQ8MupJS8RrdEZklFP2r3pTpKXmNWpMdQq2bdvmyz5N1klrZIqGHutN4uTJk00jXDQffv369WkrJk0Alaze9XY/Cqy///579xdw1f2INcWV0VDe9gN7RwABBNIpUJCV8QigvO8xAqj4xgRQ8X14NhgCBFDB6EdftiLoAVT2UU/ly5ePOupJIzROOukku+aaa9xS81qlJezFxVXza9SoUW7p5DvuuMMuvvhit7zyPffc4wqMapSLArpUOxFA+eu/md9++82++OILq127tpUuXTrm6pKMhvJXv3K2CCCAQCICeg+W35XxCKASkS3cNgRQ8f0IoOL78GwwBAiggtGPvmxFkAOoREY9HX744Va5cmVr3769rVq1KupwcF92bCFOWvW+unXr5upfabSYRoUpvNPSyqeeeqpbKfCCCy6wDz74wNatW5fSEIoAqhAdm8aXKtDUhxCtuKnVJHOujkRtqDR2DodGAAEEPBTI78p4BFAedsZ/d00AFd+YACq+D88GQ4AAKhj96MtWBDWAUojSs2dPF5xEq/WkUU9aJviuu+5yNWv0BombmUas6I1JiRIlTKNS6tata927d7cRI0bYkCFDXDB1yy23WKlSpUwrnum5VE5VJIDy91WqOnNaTfKss84y1VrLPgU28m9dd7oGZ82aFbNIrb8VOHsEEEAgXAKJrIwXqQVIAOX9tUEAFd+YACq+D88GQ4AAKhj96MtWBC2A0nDvuXPnumXhFZBEPtRm/6rCyBrB06lTJ9u0aZMv+82rk1bdHo14Ov744+311183vWnMedOop+eff94tsawg4eeff7a9e/fm3MyT7wmgPGFN6U537dpln376qVsCWj+j0UZDHXLIIdawYUMXDkc+lKT0JDkYAggggEBSBeKtjHf77bdnrYxHAFV4dtXrnDRpUsz7Qw89ZFWqVHF/qI23XVDfI6tdM2fOjOnTv39/u+iii+yBBx6wYcOGxdxO1zTvUQp/vbKH9AgQQKXHnaOaWZACKH2w/eWXX9zqdZpalz100r/1QVfhipYGnjBhAqMrcvwEKESKrFjTrFkzV2w8xyZZ32rUk5ZS1uo2Tz75ZNxts16UhH8QQCUBMUN2oaBY19k555zjpnXm/HnV91dddZUNGDDANm/enNKpnhlCxGmkQUD/D27fvt00bVT1APVVI2S1KIM+aGhqt65H3Xfs2OHC91TXwksDC4dEICkC8VbGe+SRR9wfELXgSdWqVfd7D3fcccfZ0KFDk3IOYdhJZIRTzZo13R97cn49/fTT3Sj2Cy+8MOrzke1VCzSIt7Fjx7rVeiPtzPn10ksvdTMBVLuyevXqMY1eeeUVW7x4cRCJaFMIBAigQtDJmdrEFi1auJEGWtnMzzd9GNBqK/qLTpEiRfZ746IPskWLFrVLLrnETSHTttxyC2jaYuRNid4AajRZvNugQYNc8fZq1arZ0qVL422atOcIoJJGmRE7Umjct29fu/76661kyZJRR0NplJ2meur6VAjADQEvBVavXu0WYPj666/to48+cgGo/sqtv5hPnz7dBg8ebPrruIrr6w8e6VwV1EsH9o2AVwJ5rYynkdh6v5b9jxIEUPnrjd69e1vLli1j3i+77DL3B1mVoYi3nUajBfE2Y8YMe/vtt2O2/f7773c1TxVEPfbYYzG3++STT0y/M7gh4EcBAig/9lpAzvmnn35y9X38PIRUH0y7du3qVtmKNp1Hb1y0etvUqVNTNlXMj5fH8OHDXd2n888/P6G/6CxatMgFVvLVaJZU3PwUQCnA02iJ5cuX25w5c9xXjRzLK9hLhWOmHUMf8BWGKwCNVrNN4dQLL7xAXahM67iAnY9+XkePHu0K5nfs2NF96HjiiSesX79+bqqxwlJN3X766aftzjvvNP31Wx/QqCEYsAuB5ngqoN+BsVbGO/HEE93vggoVKhBAedgLkRFS+v+OW24BakDlNuGR4AkQQAWvT2lRCgQ07SE/G/n4AAAgAElEQVRevScVGj/ttNNcvaJotYxScIq+OoRGNOnN39/+9reERjTpL/9lypQxTXfUL+tU3PwSQMlGQ9e1muDjjz9ut912m/uq78eMGeOm9hBE7X/FaDTUO++8YwpAVQMq+1+/9e/sdaG0LTcEkimgqXeq9aEPxhoBqql3+uOGwqa7777b1RVU7TIVx9eIPK0Met1117nFGTQVjxsCCCQuEG9lPE17Ouqoo/b7HcAIqMRtE9mSACq+EgFUfB+eDYYAAVQw+pFWpFBA4ZOG0GqVtmj1njSKomLFiq7Aoup5cMtbQB+sVCNLqwOqOGNedU0UpGjbSpUqmUZDpeKW6QGUzOTYtm1bNyJPUz+1YqBc9VUhStmyZe2NN95w4emePXtSweabYyiUU80n1X6SnULknEHUNddcYxqt5+dRm77pkBCdqP4P69Kli2lUsH5n6GdZoZRG3p1xxhmmor1axXHVqlWm6S21a9d2I6RUwJdANEQXCk1NmoD+MKgRhsccc0yu/+dz/r9PAJU0drcjAqj4ngRQ8X14NhgCBFDB6EdakUIBhU+33HKLHXroobneuKgwtkbxqGAlHwwS7xRZqe7CwQcfnGdwp221El7x4sWtQYMGKZsDn+kBlIpRqjj7kUce6T60Rqbp9OjRw15++WW79dZbXTCl0FQ1BrQ9I6FyX6MqVCs7fTCJNq32iiuusB9++IEQKjcdjxRQ4Msvv3SjmdauXZv1M6l6gRoBdd5559mrr77q/p9TKKVt9AFF02t/++23/cJ6BVcKRzWtlPpQBewMXhYagfnz57sRhsWKFcv1Xi57CEUAldxLggAqvicBVHwfng2GAAFUMPqRVqRIQG/stWSvgqbsb1D07xIlSrgAQHU59EGBW/4ENDJHb/Q0ekyFQCMjAbLvRXVSVIhX9XoUEPTp08d9CMu+jVf/zuQAStNwVMzz6KOPtgsuuMD+/e9/uxpQ2S1UA6pnz56m+hYa4dO5c2c31Sf7Nvz7/wWWLVvm/jp+6qmnRq0LpRBqxIgRhMxcMEkR0P9pqtWWvZ6Tio4rYL/xxhtd4XH936ebQiYVxNfX7Ld169a5EZCafqsRUypWrql83BBAILaAivlrOmu093SR93gEULH9CvIMAVR8NQKo+D48GwwBAqhg9COtSIGAwqf77rvPjjjiiFzhk+oXabWKFStW5PpgkIJTC8QhtOy4RvDIV6OhFKKoHoqmpyxYsMAVctdoHgUoGuWjZZM1GiBVt0wOoH7++Wc36klvlDWaIt4UMdWCOumkk+zss89OaLpjqnwz7TgK7Nq3b++coq1uqel4Wk45e2iQaW3gfPwhoPAo52gmrYSn6aAPPvigaapdXtfZuHHjXKjcunVrF9CrkLn+T80ZVPlDhLNEIHUCmnodGYEdCZ2yfyWASm5fEEDF9ySAiu/Ds8EQIIAKRj/SCo8F8gqftCKR3uxzK5zAhAkTXAh1/PHHu9E81atXt0aNGlm9evVMS/dq5I7CkzvuuMPVMUrlFLJMDqBU90kjwrTioooXx7spWNEIHoUqQ4YMyfODbbx9Bf05XV8q+lyuXDnnlf1Dif6tAu8K//IKB4LuRPuSK6ARTu3atXNhu0Y2JjJdVjXdFGKpjpSm7RFAJbdP2FtwBfT/vP64dc4559if//znXH9g1Mji7777LrgAKW4ZAVR8cAKo+D48GwwBAqhg9COt8FAgkfCJqQ7J6wAFKK1atbLLL7/cjT455ZRTTFOhFAJUq1bNfTDTyKdU/2U/kwOoe++9N2taXWSqTrwe0Wg9jSLr0KGDqdYMt9gChFCxbXjGGwEVSNYKllpkQVOTs4/0jARNCqmi3TRaqnLlygRQ0XB4DIEYAho1rFprer+RcwEK1aZUQMWiMjHw8vnwxx9/7EoGaGEFbrkFli5dak899ZR99NFHvD/LzcMjAREggApIR9IMbwT0xv+BBx6IOe1OI58In5Jvrw/9c+fOtYEDB1qnTp2sa9eurrC7fjGnq75WJgdQtWrVcqvcffbZZwnVxNJfIEuWLGnPPfecK1ac/B4M1h4TCaGmTp2atmszWNrha43+T9M1Frmp/pMK4WsEaM4PIVoJT1OT9XsnWghPABVR5CsC+RPQVFgt0KE/zuQc7RpZfILFZfJnytYIIIBANAECqGgqPIaAmaujo78+a/h1zjcjqvlE+BSuyySTAyjVw9JKPq+99ppt2rQpbsfoQ6tqmWk6o6aXaUoet7wF8gqhmjZtakuWLNkvSMh7r2wRdgGNqpg1a5abOqupnPr5VPBeo0YNN8VTU3+0yIBuel4BkwqMr169mgAq7BcP7U+6gH7etBBKzvd8+r5OnTo2efJk/tCQdHV2iAACYRMggApbj9PehAT0YVP1cTT1K+dwbMKnhAgDt1EmB1AqLF6qVCm79dZbTUtLZx9NkbMjtMLbxRdf7Eb1jRw5kjfTOYHifB8vhFKgp9F6eQWAcXbPUyEUGD9+vJtu8f7779vy5cvdyKYuXbq4aXSqfadC95oe9H/snQeUVFXWhQmSJIkCikgSFEFARZEkwaygvxGVUVAMgzogyciIgmLANCKIimIYIwiCOoJkxayAIkEwkeMgSUQQ5Pxr35lmqrurqqu7K7zwvbVqdXXVC/d+91bVe/uds49S7iRw/utf/7KJEyfG9BwkAiqEk4guJ42Aqhi3atUqqgClVDylr+f1G5u0xrAjCEAAAgElgAAV0IGlW4UjoDvSOgnJWf1KaUv33XcfaXeFw+vLrb0sQCllR6KSUgckgih1NJoIpdflr6V53K5dO5O/GUv+CGSJUEcccUQuw9q6des6gSBeFcL8HY21g05AYtNRRx3lqnoqukKC1IgRI6xjx4521VVXuRshSg2SN97UqVNtzJgxtmTJEpMXVLQFASoaFV6DQGIE4glQioLSjYbBgwebUmGjpcAmdhTWggAEIBBuAghQ4R5/eh+FgC7Su3XrZvvvv3+2u2ClSpWyHj16mAxiWcJHwMsClEZj+PDhzkC1Tp06zlxcnkS6aNV8VWSF/pd4qgg+PSZMmJCQX1T4RjrvHkuEUrl7VWvMGSF5xhlnuDSpTHmV5d161vASgbFjx1rnzp3toYcesmnTpjmBacaMGc77SWneMuxVFJSiFRX5pEqh8cyQEaC8NLq0xW8E8hKgJELp91PCMZWP/Ta6tBcCEPAKAQQor4wE7fAEAUUuRPN90kWmIkZ++umnqJElnmg8jUgpAa8LUPJy6tOnj9WrV8/dpT377LNdas+QIUPc66oqKJ8ovS8T8o0bN6aUV9B3Ln5du3Z1rHP6hShNAz+ooM+A5PRPn1uZiivySQ+V4JbBuH6L9Pyzzz5zr2cJyrEin7JagwCVRYK/EMg/gUQEKH3fN27c2CQexxOD8390toAABCAQDgIIUOEYZ3qZAAGFU8fyfVJUie5OywSWJZwEvC5AaVRkViwvmVNPPdWUIqYIHYlOVatWdcKTXn/llVds27Zt4RzEJPdawoGEaXmDRIpQWX5QW7ZsSfIR2R0E4hNAgIrPh3chEI9ANAFKVgzFixfP9h2v73tVqZw+fbpRGS8eUd6DAAQgkJsAAlRuJrwSUgJKVzrppJNy+T4dcMAB9vjjj1MtLKTzIqvbfhCgstoqj5g33njDRTrdcMMNds8999hrr71mS5cuxXQ8C1KS/oqzPHxyXqDID2rWrFnwThJndhOfgC6CFZWnmyiKzlCKqCKoVC2PGyfx2fEuBLIIRBOgDjzwQDvyyCPdzZzIGw16rsp4En1Juc4iyF8IQAACeRNAgMqbEWuEgIA8XR555BGT2BR5gqE7X/KDWr9+fQgo0MV4BPwkQMXrB+8ll4BSou666y4XZZbTD6pnz57Ohyu5R2RvEMhNQEblX375pb300kt2+eWXO/FZnlHyjiISLzcvXoFANALRBChFEMuPrUOHDlamTJls54hUxotGkdcgAAEIxCeAABWfD++GhMCyZcusUaNGVqxYsWwnF82aNbP58+e7EtghQUE3YxBAgIoBhpdd1UHdCc9ZuKBKlSo2efJkIlCYIxCAAAR8QCCWAKUKlO+88461bNkyasq1KuMpip7KeD4YZJoIAQhknAACVMaHgAZkmsCePXtcilLFihWziU/yzlHJa0qqZ3qEvHF8BChvjINXW/Hxxx9bkyZNconY1157ra1cudKrzaZdEIAABCDwXwLxBChFyj/33HPWsGHDXCnXVMZjCkEAAhBInAACVOKsWDOgBOSXc/TRR+e6cDz//PNJvQvomBekWwhQBaEWnm10caIqhDnTeBUF9d5772FUG56pQE8hAAGfEognQKlLuiH5wAMPWM2aNS1nyrWi6KmM59OBp9kQgEBaCSBApRU3B/MaARlH3nLLLbnMJRUNNWnSJFJnvDZgGWwPAlQG4fvk0PPmzbPjjz8+193xyy67zBnA+6QbNBMCEIBAKAnkJUAJivzWevfubZUrV84WNU9lvFBOGToNAQgUgAACVAGgsUlwCHz33XeuuklO7yddMOokgwUCWQQQoLJI8DcegTvuuMNUNSmymEGFChXs7bffJgoqHjjegwAEIJBhAokIUGrijz/+aF27ds1185LKeBkeQA4PAQj4ggAClC+GiUamikD//v1znUAcdNBBNnPmTFN1KxYIZBFAgMoiwd94BL7//ntnVLvffvtlE6G6dOmCF1Q8cLwHAQhAIMMEEhWg1ExVnezYsSOV8TI8ZhweAhDwHwEEKP+NGS1OEoHt27fbCSeckCtdRqbBGzduTNJR2E1QCCBABWUkU9+Pe++9N1d6xmGHHWZfffWVySuKBQIQgAAEvEcgPwKUWk9lPO+NIS2CAAS8TwAByvtjRAtTRGDWrFlWrVq1bFEKZcuWtY8++sjkDcUCgUgCCFCRNHgej4CioJo2bZqrsMGLL75oEr5ZIAABCEDAewTyK0DphsKoUaNcIZvixYtnO5+kMp73xpcWQQAC3iCAAOWNcaAVGSAwYMAAkzdLpFdLmzZtbM2aNRloDYf0OgEEKK+PkLfad+WVV5oE7cjvl27dupGG561hojUQgAAE9hHIrwClDamMtw8fTyAAAQgkRAABKiFMrBQ0AjphaNu2rZUoUSLbBeL9999v27ZtC1p36U8SCCBAJQFiiHbx/PPPm9LuIgWoI4880r755hvbu3dviEjQVQhAAAL+IFAQAUo9U9GaPn365Eq91vd/+/btbfr06RSh8McUoJUQgEAaCCBApQEyh/AeAV0EKjw68uKwdOnS9vnnn9uePXu812BalHECCFAZHwJfNWDJkiV2zDHHWNGiRfd9z6ja5tixY90dc191hsZCAAIQCAGBggpQQvPTTz9RGS8Ec4QuQgAChSeAAFV4huzBhwQeeeQRO+CAA/ZdGEqIkiH56tWrfdgbmpwOAghQ6aAcnGPIG+Siiy4yCduRQnfv3r1t7dq1wekoPYEABCAQEAKFEaCEgMp4AZkIdAMCEEgpAQSolOJl514lcO6551qpUqWyXRjefffdtnXrVq82OaXtUtSX+r5y5UpT5MayZcts8+bNmLFHUEeAioDB04QI/OMf/7BDDjkk2/fM8ccfb4sXL05oe1YKFoE//viDKojBGlJ6U0gCKviic43ly5ebijesWLEio+cehRWghIPKeIWcFGwOAQgEngACVOCHmA7mJLBr1y6rW7dutotCpcbMnDnTdIEQtmXLli2mioBPPvmk3XTTTS5qo3v37vbYY4/ZpEmTnCk7aYlmCFBh+2QUvr+zZ8+2+vXrZ/uuUeGDuXPnFn7n7MF3BHSRPW/ePFu6dKn99ttveIH5bgRpcDIJbNiwwWbMmGGPP/643XjjjXbJJZdYjx493P/yTNL76T73SIYARWW8ZM4S9gUBCASRAAJUEEeVPsUlsGrVKqtRo0a2i8Ly5cu7i4K4GwbwTUU8PfPMM9agQQMrV66cVatWzY444girVauWqxBYtWpV69+/v3399dehFOcihxwBKpIGzxMhoKjCpk2bZvuuUTreRx99RCRMIgADto68BwcNGmQ333yzvfzyy85zUN/BO3fuRIwK2FjTndgEJND88MMP9uCDD5oKM8gOoXr16lavXj1XuEHVQw8//HC79957beHChaabhulakiFAqa1UxkvXiHEcCEDAjwQQoPw4arS5UAQkpuQ0INfJjkK/w7Qo8umWW26xAw880GrWrGmdOnWyIUOG2OjRo+2pp56y66+/3po0aeJSFZWyOH/+/LTfjfTSeCBAeWk0/NMWVdtUhGWkDxRG5P4Zv2S39Oeff3bRHqqQeOyxx1qvXr2cMb1+l9avX0/ac7KBsz/PEVAEYLdu3VzFOIlOV199tSld+fXXX7ehQ4c6I29FjurG4JVXXmkLFixI27lHsgQoQc+rMt60adOojOe52UmDIACBdBBAgEoHZY7hKQJKK1NkT+QFYatWrVyqmacamsLGKKxdd+DFoU6dOu7kTz4MkYvuUk6cONF0AV2yZEmXnifz5LCWkEeAipwdPE+UwMUXX5zLiHzkyJG2bdu2RHfBegEjIKFJ4r8icYsXL26K+GjdurXddddd9t5777moj19++SVtF90Bw0t3PEzg119/tQEDBjhvvBNPPNGdh+Q891B6qs5Pmjdv7kQoRQ3qM5OOJZkClNobrzKeUg7nzJmD6JyOgeUYEICApwj4ToCSObJyw6dMmcIDBgWaAxISKlasmE2AatasmY0ZM6ZA+/PjXHz33XetUaNG7uLnggsusHHjxsXs+2233eZC5JWiN3z4cHv//fdjrutHFom2+S9/+YtLU4wULnUX96233golj0S5hX29s88+28qUKZPt+0bRhePHj2fehPg3TN+5J598ci5xUr9NHTp0sIceesgUISFjZomVuiHAAgG/E5Df5HHHHeei0F977TXnhRarTxKhFAmlCHWd96fjM5BsAUp9i1cZr2fPni4dMR19i8WZ1yEAAQikm4DvBCidlOluYeRFIM+LwKMIDPgcMAeYA8wB5kBw5oBSxZUaPWLECOcbpvS9HTt2hDYKNd0nyBwv+QQeeeQR5/d07bXXmuZzvEWRUJ07d3Y2AM8++2xcsSrefvLzXioEKB0/XmU8eV2tWbOGz3V+Bop1IQABXxNAgEK4QLxiDjAHmAPMAeYAcyCDc6B06dK5vMIixUQVh5BXjqJC5Be1fft2Llh9ffodzsYr+lPR1BKiNm3alCcEpetVqVLFbr31Vlu9enWe6xd2hVQJUIpwGjVqlB199NEu8jzysy2hWSJzIjwK2z+2hwAEIOAFAghQGTzhjPwB4nlw7lozlowlc4A5wBxgDuRnDugiu1SpUjFFQBnZH3TQQS596c477zTZEYTVj88LJ8+0oWAElMouT8lEI5qU9SCB5oYbbkhLpeJUCVCiRWW8gs0ZtoIABIJHAAEKASrmCW9+Tp5Zl4st5gBzgDnAHGAOFGwOFC1aNNdvsV5TiXqVqj/ttNPsjjvucL5QW7duRXwK3vl4KHokT0lV3pWx+IYNG+L2WVFDffv2dZ+B++67z1WVi7tBEt5MpQCl5lEZLwmDxC4gAAHfE/CdACXTwtNPP91OOukkHjAo0BxQKsN+++2X7WS/cuXKruJKWOZVixYt9nmpyeCzZcuWMVk2btzY3bHUHXg9V7WmsHCK7KcqVuWcN7Vq1TKxjFyP53w3R86BQw45JFfKBfOGOaLv0dq1a1uJEiWy/RZJwFOKkr6XNY9uuukmGzt2rLtYJ+LJ9+fcoe+A0tA0tzt27Ghz586Nayy+fPlyUxEHfR7eeOMN27VrV8r5pVqAUgeyKuNVqFAh12c/KJXxJC7q8ccff6R8zDgABCDgPwK+E6Dke6ByrOvWreMBgwLNgWHDhlmlSpWy/fBL1Jw/f36B9ufHuagTIFVaUspH165dncHtqlWrcvX/u+++swceeMDdsaxXr55NnjzZ+TD4sc+FbXOvXr1yVU+8/fbbbcmSJbm4FfZYbB+c73elnOQsnKEUqsWLFzNvQvobJi+bDz74wDQ3siqy6rtYIrcqssqg+cUXXzRdgO/evdt/Z5a0GAIxCMi/7IwzzjCJLzLfXrFihe3Zsyfb2hJadZ5/9913u/Q7ibWzZ8/Otk6q/kmHAKW2f/XVV06Ey1khVemJQaiMJ0+rkSNHOnP1VI0V+4UABPxLwHcClH9R03KvEHjvvfesatWq2QQonfSnw+DSKwzUjg8//NCaNGniLo51l/2TTz5xviIbN250LBYuXGhDhw61unXrOu8RCXcqBx7W5e9//7tLBYhMMRo8eDDGoWGdEAn2+6KLLjIZTEfOG0UB/PrrrwnugdWCREARAYr8uPTSS92NEEXIqSy9qt0NHz7c9L2bjkiPIDGlL/4i8MILL9hRRx3lBFeJTJ9//rmtXLnSpafpRticOXPsnnvucRGCEmX/+c9/pu37Ml0ClEYsyJXx9LvXpUsXd6PFX7OT1kIAAukggACVDsocw1MEdAdOppaRF4R16tRxd+I81dA0NObJJ590d9x1gSwRrnv37i7iqV+/fnbmmWc6cUppIj169MjTryENzc3oIRCgMorflweXh0n79u1zpeBNmDDBdu7c6cs+0eiCE5AJ8aeffuqiTvV9qyjU+++/37744gvbsWNHwXfMlhDwEYHffvvNCUyqCKdIqFatWrmoH93Q6d27t7MEUJS6oq71WjpvDqZTgApyZTwEKB99IGkqBDJAAAEqA9A5ZGYJKLS7Zs2a2QQopUEoLS2My7Rp0+zCCy+0Ro0auTuSqrQkgU7Gt23btnVh1Fu2bAkjmmx9RoDKhoN/EiAgs2hFt0SK3fJSU/ShLj5YwkXghx9+cObLAwcOtClTppi+V/F1CtccoLf/ISAxdvTo0XbeeedZw4YNrXr16iYvTv1VdJS8n1599VXbvHlzWpGlU4BSx8ThwQcfdOekOQsR6JxM/m+yHvHbggDltxGjvRBILwEEqPTy5mgeIKAUiPr161vOH3t5coTVb0OVWd5//31Tmp2q1Kj08ZtvvunKHoeVSc6pigCVk0hy/tfdcF2Yf/nllzZjxgybOXOm8/vQa4oK8fMFunw+9F0TKUDpjr9SsFjCR0B+cUpxRnwM39jT4+gE5AE1adIke+yxx6x///726KOP2ttvv+1S8nJ6Q0XfQ3JfTbcApdYHsTIeAlRy5yV7g0DQCCBABW1E6U9CBFSBRWaPkReGOvkh0ichfKFcCQEqucOui3CZLOsu92WXXebugsuQVRWPjj32WPeaKh/JEyQTFyLJ6K0upg4++OBs3zMnnHACvhjJgMs+IAABCCSZQCYEKHUhaJXxEKCSPDHZHQQCRgABKmADSncSI/CPf/wjl6G0PDlkhMkCgWgEEKCiUSn4azJblvm90i6qVatmTZs2dX5J8kxS2ppSQatUqWK33nqrOzn3mwglI+mLL744lwF53759XfW7gpNjSwhAAAIQSAWBTAlQ6kuQKuMhQKVidrJPCASHAAJUcMaSnuSDgE4yVF0lMgKqRIkSziCWlLN8gAzRqghQyRvsX375xRkxKx1NlRjvu+8+l3anynCqtKgT8dtvv91FRckg/6677vKdCb7SrWSyG/kdo6hLpbbK94MFAhCAAAS8RSCTApRI+KEynm4G6Xda/lyxHueee66r9Knf8ljryCOR821vzX9aA4F0EUCAShdpjuMpAvKBatOmje23337ZLhBVcUU/iiwQyEkAASonkYL//9xzz7moJ/kjTZw4MaogoxQ9ld9WJSSZ4ms9P1WOGzVqlDPUjRSgZOy/YMGCgoNjSwhAAAIQSBmBTAtQ+t3Tb4duXhQvXjzb+al+B0eMGGGbNm1KWf8T2bE8q2QgL9+uWA/dWFK6+R133BFzHf2+k3WQCHHWgUDwCCBABW9M6VGCBO655x5T9bvIC0SJUmvWrElwD6wWJgIIUMkZbaWmKc1OkU1KhY3nuyahuEePHq5U91//+lfffDZ1h7hLly5WtmzZbN8vV199tfO0Sg5J9gIBCEAAAskkkGkBSn3JqzKeomgzWRnv559/Nv0ey7Yi1qNSpUoujb5x48Yx1/nLX/5iX3/9dTKHj31BAAI+IYAA5ZOBopnJJzBr1iwXWREpQOmiWK8TFpx83n7fIwJUckZQZqsNGjRwKbDygcpr+fDDD61u3brWsmVLVy0vr/W98P7333/vjNQjK23qbrbu+GbywsELbGgDBCAAAa8S8IIAJTbxKuO1a9fOpk6dGjVyOB1cVZ1Wv+Pz58+P+TjttNNMaXjvvvtuzHX0O8nvYTpGjGNAwHsEEKC8Nya0KE0EdJepefPmucKcr7rqKt/5zaQJme8Po/TKZcuWmU4yP//8c3f3TSdSej2v0ugIUMkZ/unTp1udOnXslFNOMd1JzWtZvXq1NWrUyKXs6YTX64uinwYNGuTM1SPF7erVq9ucOXNs7969Xu8C7YMABCAQSgJeEaAEP6/KeLNnz/bszVJMyEP58aHTEEiYAAJUwqhYMYgE7rzzTpfeE3mhqLQ8XSQr/YclGAQkLknsGDlypHXv3t1OPvlk5y2kqJorr7zS+SooGifemCNAJWcuKKLp8MMPt5NOOsl+/PHHPHcqjwj5YRx22GG+8E+S+bi8L4oVK0b6XZ6jywoQgAAEvEPASwKUqPi1Mh4ClHfmNC2BgBcJIEB5cVRoU9oILFq0yF3c5rxYvPTSS23t2rVEK6RtJFJ3IIlPOomT/46qrlWrVs1F1Cj6TUaZikwpU6aMderUySSOxDK6RoBKzhgpokm+EFWrVrXPPvvMFDEUbxk3bpzVrFnTzjrrLFu6dGm8VTP+ngRMzZODDjoom/gkPwylIsSaWxlvOA2AAAQgAAEXHd2qVats39/6rVLKW6aWeJXx5GUq31KvRdYiQGVqtnBcCPiDAAKUP8aJVqaQgMq9ly9fPtsJx/7779hJmKIAACAASURBVG+TJk0yGSaz+JvADz/84EyvJT4df/zxdt9997kIN70uvy9VcWnbtq0zjG7RooV9+eWXUcPaEaCSNw8uvvhiZ0I+YMAAW79+fcyTZ/lgdO3a1RULEH/97+VFd88lakZ6P+n5FVdcYStWrPBy02kbBCAAgdAT8FoElAbED5Xxck4cBKicRPgfAhCIJIAAFUmD56EkoJSZY445JpcX1IUXXugqVnntzlIoB6mAnZbBZa9evZyAIVPMTz75JKqoOG/ePDvnnHNcJNS1115ritLJOe4IUAUchCibKRpIRuRVqlSxZ5991n3OIiOhdMItr66HH37YDj74YBexpmgpLxcHkKdc3759TdFOkSm9ar/EbKKfokwEXoIABCDgIQJeFKCEx+uV8XIOIQJUTiL8DwEIRBJAgIqkwfPQElBUjLyfIi8cS5QoYW+88UbGKo2EdjCS2HEZjdeqVcul3U2ZMiWq+JR1OIlT8hoqV65cVA8wBKgsUoX/K4FJ/mtKrVN6wy233OJEGpl0K11SYyWvrsqVKzvvJ4lUMor38vLRRx9Z/fr1c0U/qR8SNFkgAAEIQMDbBLwqQImalyvj5RxVBKicRPgfAhCIJIAAFUmD56ElsHz5cmvatGmuKCilZM2dO9fTkRehHbQEOj5ixAgXZdOtWzdbt25dnlso+qls2bI2dOjQXIIHAlSe+PK1woYNG2zw4MEuLVKinwRgpUiq4p1SYvXasccea48++qj98ssv+dp3uleWwCTfOM2dSBFbfmPTpk2La26f7rZyPAhAAAIQiE7AywKUWqzKeCqcIkuByN8aPb/kkkvMK5XxevToYf369XPtjU6aVyEAgTATQIAK8+jT92wEdKGbM31GP+rXXXed829R1AaLvwj07t3bnag98sgjuQSlaD35xz/+4aJuevbsaRJIIhcEqEgayXmuz5SinST8qTKhRGBVkGvXrp1dc801zhReqQdeXrZt22YDBw508ybygkCFDW666SZXzMDL7adtEIAABCDwHwJeF6DUSkUJZ1kGRP7mlCxZ0nTuIn/LTJ+vKqJcD69HLjPvIQCBzBBAgMoMd47qQQKKkGnfvr0p9S7yR7106dL2xBNP8EPqwTHLq0k33HCDi6R58sknTUJBXstTTz3lUsIkiOSMmEKAyote4d7ftGmTu3v7zTff2JYtWzJ+Ap1Ib+Rb9eabb1qdOnWypd7p++OII46wTz/9lOjJRECyDgQgAAEPEPCDACVM8lFUtT6JTpHnq4oc9mplPA8ML02AAAQ8QgAByiMDQTO8QUA/6vJxKV68eLYfdXnVTJ48Oa6HkDd6QCsiCWRFNMmHR9XW4i0SE/72t7+59C9Fw+W8c4cAFY9eON+TWKaLgJyi9UEHHWTDhg2zzZs3hxMMvYYABCDgQwJ+EaAU4fT8888738qc56uHHnqoyX5AN3VYIAABCHiRAAKUF0eFNmWUwP333++iYCJLqesO0ymnnGILFy60yGpdGW0oB8+TwPTp06127drWsGFDF43yxx9/xNzmu+++c+lf8lZ4//33c4mNCFAx0YXyjbVr19oVV1zhIuwi70ArYlKRdxiPh3Ja0GkIQMDHBPwiQAmx0tOHDBniCq3kPF+Vl6Kic1UJmAUCEICA1wggQHltRGhPxgkoVUsmjzkNhXWRKVNFXVju3bs34+2kAXkTUCqXzKHLlCljXbp0cSleu3btyrahBMUff/zReX3JCFveCjKlz7kgQOUkEt7/9R2hyplVqlTJFikp3ycJ1QsWLPBFCmF4R5CeQwACEMhNwE8ClFqvynh9+/bN5UGo81V5KU6dOpVKzrmHmVcgAIEME0CAyvAAcHhvEliyZIm1bds2V2rN/vvvb0rrUjoXIpQ3xy5nq1QVRmlSikxRaeB33nnHlDolo8758+e7E7TLL7/cmZU3aNDAZs6cmSv6SftEgMpJNpz/S3x69dVXXWRdzrvO8n1S9NzOnTvDCYdeQwACEPAxAb8JUELtl8p4Pp4WNB0CEEgyAQSoJANld8EhEMsPSlEyjz/+OCKUj4Z6zJgxduqpp5rG7uCDD7aTTjrJOnfu7F6rWrWq831q3ry5ExZ+/fXXqD1DgIqKJVQvZolPEpoU7RSZeofvU6imAp2FAAQCSMCPApSGwQ+V8QI4XegSBCBQQAIIUAUEx2bhICA/KKXZ5Ix0QITy3/jLv0sm423atDH5I9StW9f9bdmypV111VU2Z84ci+cR5TUBShF48neQF9GKFSuc4eju3bv9NzA+aXE88UkpnjfeeCO+Tz4ZS5oJAQhAIBoBvwpQ6guV8aKNKK9BAAJeJIAA5cVRoU2eIaCLzm7dutkBBxyACOWZUSl4Q1Q5Rv5O06ZNc9FO+rt06VJLRLjxkgAl0WnWrFmuCs7tt99uPXr0MFXumzBhgksr3LFjR8EhsWUuAnmJTx07djSZ2Gt+sUAAAhCAgD8J+FmAyqsy3pNPPkllPH9OS1oNgcARQIAK3JDSoWQTWLNmjTMlR4RKNll/7c8LApQM0xctWmQDBgwwlVqWJ5ki9A455BCXXliyZEk744wz7K233rKNGzciiCRhiiUiPslTLBERMwnNYRcQgAAEIJAiAn4WoIQkr8p4siOgMl6KJg+7hQAEEiaAAJUwKlYMM4FERKhVq1ZxwR/gSeIFAUpRNueff74zTK9fv77zsbrzzjtt8ODB1rNnTzv55JNNXkS1atWyESNGmKoAshScgPi98sorFs3zqVSpUqbIJ8SngvNlSwhAAAJeIuB3AUosqYznpRlFWyAAgWgEEKCiUeE1CEQhkCVCVahQIWo6noSAxYsXEwkRhV0QXsq0ACUxRB5WisSTifrYsWNz3clUNZx+/fo5o3V5XCnFcNeuXUHAn/Y+SFB++umn7fDDD89lOF6iRAk75ZRTbO7cuXze0z4yHBACEIBAaggEQYASmXiV8Tp16mSqDkzUbmrmEHuFAATyJoAAlTcj1oDAPgISoS655BIrV65ctgpYqoZVvHhxu/rqq+3zzz+nDPs+YsF5kmkBavz48XbYYYc583T5P8UyTP/tt9/smmuucXP08ssvxxg7n1NQaY7ff/+93XbbbaYKiTkLEEh8kpH9Rx99hLiXT7asDgEIQMDLBIIiQIlxvMp48o3U7xy+hV6ejbQNAsElgAAV3LGlZykisGTJErvwwgutbNmyuUQoCVHt2rWziRMnmrxjVKmMJRgEMi1AZYlKgwYNytNI9Ouvv7YjjzzSCSg6oWYeJjYH5Z/xxRdf2KWXXhpVZEZ8Sowja0EAAhDwI4EgCVDiH68y3r333uuq6HJ+4MeZSpsh4G8CCFD+Hj9anyECEqEUCVWpUqVcERISoXTx//zzz9u6deu4w5ShMUr2YTMpQClUXlE38h2aOnVqzOinyD4rRWy//fazKVOmJLR+5LZhfL5582Z75513rFWrVo6zPseRDxm+t2/f3j7++GMin8I4QegzBCAQeAJBE6DiVcZTRPUzzzxj+u1jgQAEIJBOAghQ6aTNsQJFYOXKlc74uUaNGi79LvJiVc8PPPBAu++++1yYM7n2/h/6TApQiqZr1KiRq3qXaEST0u8kmrz88sumtDyW6AR09zfL76levXq5/J70Wa5cubLJN2POnDmIedEx8ioEIAAB3xMImgClAYlXGa9JkyZR/SR9P5B0AAIQ8DQBBChPDw+N8zoBXdgPGTLEGjdubErPySlC6bXrrrvO5NlDSp7XRzN++zIpQOkupiKg5DMmY/FY/k9ZPZDgefrpp1vp0qVt0qRJROxkgcnxd8eOHa6K3c0332xVqlTJFc0o/6eaNWua3l+2bBnRjDn48S8EIACBIBEIogCl8YlXGU/Vc6dPn453aZAmMn2BgMcJIEB5fIBonvcJyLRYFcnatm1rZcqUySVCSZQ69thjbeTIka4yCdFQ3h/TaC3MpACl9nTv3t35Eg0YMMA2btwYrYn7Xvvmm2+cWfnBBx9sixYt2vc6T/5DQFFPKiigz63S6iTU5RSPlb6oqLNhw4bl6bkFVwhAAAIQ8D+BoApQGpkffvjBunTpYuXLl8/1e9e5c2eTdyTnp/6fw/QAAn4ggADlh1Gijb4g8OWXX9pFF10U0xdK6VB//etf7cMPP7StW7diDO2LUf1fIzMtQL355pt2+OGHO2FJUU0Kq4+2yHdM1RgrVKhgVMHLTUhRi3PnzrU77rjDqlWrlivqSUKUPqsSlGXgSvpiboa8AgEIQCCIBIIsQGm8PvvsM+vQoUOum6UlS5a0Xr162Y8//kikbxAnNn2CgMcIIEB5bEBojr8JZPlCKW1H6VI5oyr0v9L1RowYYTIy526Tf8Y70wLUzp077YYbbnDC0mmnnWYTJkyw5cuXOzFz+/btLsR+wYIFNnDgQOdZJD8jiZ15pev5ZwQK11JFPenz+dprr7l0xmhRT/p84vdUOM5sDQEIQMCvBIIuQGlc3n77bWvZsqVJdIo8R9VNKyrj+XXm0m4I+IsAApS/xovW+oCAIiYeffRRO/HEE10khXxkIn/k9VwXv127drUZM2bYli1biIbywbhmWoASosWLF9uFF17oouwkct544402fPhwGzVqlDO8l++TTiJVhVGva26xmEmgk4F4nz59ono96TOplLv69evbbbfdht8TkwYCEIBACAmEQYCSp+Rzzz1nDRs2zHWjVJXxnn76aSrjhXDu02UIpJMAAlQ6aXOsUBGQ8fhll11m+kGPFQ111FFHOaFg3rx5JkNkRWmweJOAFwQokZGPw0033WSqXnPIIYc4kVN3MlV1sVatWnbKKafYmDFj7Ndff/UmyDS2ateuXY7XSy+9ZK1atbJSpUrlEoMlPomdosqU5gi3NA4Qh4IABCDgIQJhEKCEWzdKH3jgAVMV55w3SRWlL39E3bhhgQAEIJAKAghQqaDKPiHwXwK//PKLPfLII9a8eXMrW7Zsrh96XfyqUt6ZZ55pr7zyiotw0UUzi/cIeEWAEhml402cONGdQHbr1s06depkt956K0b3/502Sm1V1TqlGshc9YADDoj62ZNwp6invn37OqFKBQVYIAABCEAgnATCIkBpdFUZr3fv3i7tXOeikQ8q44Vz/tNrCKSLAAJUukhznFAT+Oijj1z1EUWoxIqGkvHxJZdcYm+99ZYtXboU7x6PzRgvCVAeQ+OZ5ii1YPXq1TZ16lRXNbBKlSpRhSedaOs9mbHqTi9RT54ZQhoCAQhAIGMEwiRACXJelfFUsAOv0oxNRw4MgcASQIAK7NDSMa8R2LZtmz3xxBPWunXrmNFQujCuWLGiq5anSmerVq0yojK8MZIIUN4Yh2itUOrqhg0bTEKvIsGUVlCsWLFsd3Sz7u4q6qlBgwauCp6EXolWLBCAAAQgAIGwCVAa8c8//zxmZTyl+0uk4neSzwYEIJBMAghQyaTJviCQAIGvvvrKrrzySlOVMqXfZV0Y5/xbvXp1lxr0wQcfuItrTgASgJvCVRCgUgi3ELtWmqs+U6reo3Q6mYnn/CzpfwlShx56qHXs2NGl5gXN32LNmjWu6iHG84WYTGwKAQiEmkAYBSgN+DvvvBO3Mp5+X/AoTd5HQzfMPv30U1u7dm3ydsqeIOAjAghQPhosmhocAkr5kTGyLoYVrRErLU8XzjIqHzhwoLu4VHoR4dCZmQcIUJnhHu2oEmPXr19vs2fPdhUnmzVrFtNgXAarSrdT5OGQIUNsxYoVgbyb+89//tN9l+huNgsEIAABCOSfQFgFKP2mxquM99RTT1EZL//TKeYWEvyOOeYYe/3112OuwxsQCDIBBKggjy598zwBXUQPHTrUZPh48MEHx0wbkhB1xBFHWL9+/UypeT/++KMzovZ8BwPUQASozA+mxFelpX744Yc2aNAgO/7442MKT/rMVKpUyU444QS78847beHChYH2VUOAyvz8pAUQgIC/CYRVgNKo5VUZT1VigxY5nKnZigCVKfIc1ysEEKC8MhK0I9QEJCjdc889LgRaF82x/Gt0UV21alVnaD5mzBhbsGCBOyEgNDr10wcBKvWMYx3h999/t59//tnef/9969Onj9WpUydu1GC5cuVMpaTlX/HFF1+EQqxFgIo1e3gdAhCAQGIEwixAiVC8ynjt27e3adOmheL3NLHZUvC1EKAKzo4tg0EAASoY40gvAkJgzpw5zvdJURu6iFb6kESnaA9VzVMVr1GjRrlUJHnh4BOVuomAAJU6trH2rFRVRS6NHj3aunXr5lLp4n0mSpcu7VJWr776aps+fbrt2LEj1q4D9zoCVOCGlA5BAAJpJhB2AUq441XGu+yyy4zKeIWflAhQhWfIHvxNAAHK3+NH6wNIQCKSqnldc8011qRJkzyFKEVLtWrVyh566CGbNWuWLV++nDtUKZgXCFApgBpll0qzkzGnTnKfffZZ55NWoUKFuGKshCelqHbq1MnGjx9vEq7CtiBAhW3E6S8EIJBsAghQ/yFKZbxkz6zs+0OAys6D/8JHAAEqfGNOj31C4I8//nApR9ddd53zujnwwAPjpuYpSkoX4TfccIMpPU8X8PKY2rNnj0967O1mIkClbnyUQrpp0yZbtGiRTZw40fr3728nnniiSViKFv2X9ZqEqYYNG9qll15qb7zxhjNJDWs6KgJU6uYne4YABMJBAAHqf+MskaRly5ZWsmTJbL/D+t2VZQSV8f7HKr/PEKDyS4z1g0YAASpoI0p/AkdAEVGffPKJ3XLLLXbSSSe5UvLxqubp4rxEiRIuKuquu+5yIpYu7FWenRS9gk8PBKiCs4u1pQxNf/rpJxe59+ijj9q5557rjMPjpdnpvcqVK9txxx1n119/vb333nsYo5oZAlSsWcbrEIAABBIjgAD1P046X4xVGa969epGZbz/scrvMwSo/BJj/aARQIAK2ojSn0AT+O677+yRRx6x008/3Rkx57wzlRUZEvlXpua6sH/iiSdc9TCZOcsbJ6yRIgWdIAhQBSWXfTtF9q1evdq++uore/HFF+3KK6+0mjVrxjUV13yW6FqtWjV3R/b2228Pjbl4Fr0VK1bYN998Y/KJi/bQHWlV0nzppZeivp+1zYYNG4iKzILKXwhAAAIRBBCgImBEVMbTb3TOG0Mq9EFlvOy8sv6TjcC8efNi/hY/9thjduSRR9r9998fcx39ZutcSbYELBAIGgEEqKCNKP0JBQGFPst8/IILLnCmy2XLls11chApQmU9r127tjNzfvnll90F/LJly6iil+CMQYBKEFSU1Xbu3OnC9SWgTJgwwW6++WY79thjrVSpUtlC+7PmaeRfRfNp3p566qn24IMP2uLFi00iVtiWESNG2IUXXmhnnnlm1MfRRx/tUhZbtGgR9f2s7d59911Xbjts/OgvBCAAgbwIIEDlJqTKeKo+q8jjyN9mPacyXm5eekWWAJ07d475W3zMMcc4f1f9zfptjvZXN+k2b94c/SC8CgEfE0CA8vHg0XQIyGx53LhxdtVVV1mzZs1cet5+++2X6yQh50mDLuolACiFSUKWzMuXLFliVNKLPacQoGKzifbOtm3bbOnSpU7oVBU7RS21adMmT1N9zVUZ6x900EHWqFEjO++882zkyJHuTmCYU0glHA0aNMjuuOOOqI+OHTuavDkUURZrHb3+2WefUaQg2oTlNQhAIPQEEKCiT4Eff/zRunbt6n5jcp5PUhkvN7MPPvjARTfF+i2+6KKLrGrVqnb++efH/b2eMmVKKIuq5CbKK0EjgAAVtBGlP6EkoIiQ2bNnu0p455xzjrtwT8S0POtEQhEmF198sQ0ZMsQmT55sOglTlNWuXbtI1fvvjEKAiv/Rktm97pTKb0yCpvwhrr32WlNkTiKpopqL5cuXd0b6p5xyit122202depUk5BFumh89noXD6i8GbEGBCAAgXgEEKBi01FlPN3oKFOmTLabnPp9v+mmm+yHH37AZzQ2vmzv4AGVDQf/hJAAAlQIB50uB5uAoqJ010Sm5bqQV555uXLlEkrRkwhQsWJFF1YtAUD5/TrpkG9U2E3MEaByf25kIr5y5UrnTTRp0iQbPHiw8xs75JBD8vR0yhI/lYYnf4nmzZtb9+7dTdFS69at40Q2N+64ryBAxcXDmxCAAATyJIAAFR+RhJNWrVrluqlEZbz43HK+iwCVkwj/h40AAlTYRpz+hoqAopjGjBnjIlFUTlcX+on47mSJA0rVUwTL1Vdf7UzM33//fRdppXDsjRs3hsocMewClNLfJEIuX77cCU4ffvihPf/88+7OZ+vWrfMlcipNVIbZSgPt1KmTPfnkk6H1dkrWFxICVLJIsh8IQCCsBBCg4o+8zgNk26DzwpzVmKmMF59d5LsIUJE0eB5GAghQYRz1NPZZFZdUDULpOSyZJbBw4UJ3oa8L/hNOOMGJUfvvv3/CkVESpbT+8ccfb1dccYU98MADzlBanjIyhtY4y2w6qOlSYROgVHlFIqPERqV3SnwcNmyY3Xjjjc7LSR5N8mrKEivz+qswfUVGNWnSxDp06GCq2vbpp5/a77//ntkPRkCOjgAVkIGkGxCAQMYIIEDljf63335z539UxsubVaw1EKBikeH1sBBAgArLSGeon88++6w9+uijtnXr1gy1gMPmJCCRSIKCqmrJsFjRK0cccYQdcMAB+RIUJDgoQkopfqrGJ7PF119/3fn/zJ8/31Q2XhEzQSkhG2QBSnc1lbqpiLnvvvvOGVWPHz/enWRKbDzuuOOc+JizDHNeopNSP+UvJoN8eYxJtJQ5p+ZFUIXKnJ+3dP2PAJUu0hwHAhAIKgEEqMRGlsp4iXGKtRYCVCwyvB4WAghQYRnpDPWzS5cursTo+vXrM9QCDpsXAUW4qGSsyuyedtppzsBc6VESl/ISGKK9rzDs008/3Xr27GlDhw51UVIfffSRS9v66aefTHNBUS9+EyCCIkDJsF7VDpctW2YSChXBJv+mZ555xhl/qyqLBMmCjL9C8mV+X79+fSds/vWvfzWJ0Dqpl/DJkjoCCFCpY8ueIQCBcBBAgEp8nKmMlzirnGsiQOUkwv9hI4AAFbYRT3N/EaDSDLyQh9u0aZNNmzbN7r33XlceVul2tWrVcqV385NuFSlMaTuJUm3atLGrrrrKBg4caK+++qo7jiKxFHGzevVqFyWnSByvLn4ToMRSJuFKjfz+++9t7ty5Jt+msWPHumqH119/vRMcJTYlWqUuclyznists1q1ai617swzz7Rbb73VHUPm5KTepm82I0CljzVHggAEgkkAASp/40plvPzxylobASqLBH/DSgABKqwjn6Z+I0ClCXQKDpOVqqfIGPn+nHHGGda0aVM7/PDDXZRLTgPKLEEi0b9Kz1JqlyJubr75Zhs+fLj961//ciLJF1984aJmVNZXQoa8iOQ7kMmoKa8JUBKYduzY4aKZVq1a5byaFNH05ZdfOoYTJ0605557zvr372+XXXaZqzJXpUqVXMahiY6X1pOYqGo38n6Ql1Pbtm1dGueQIUNIrUvBZzA/u5RwfPnllztBNz/bsS4EIACBTBPQ79muXbsyXv0UASr/M0FiCpXx8sdNkee6CThz5sz8bcjaEAgIAQSogAykV7uBAOXVkcl/u+QRpIill156yW655RY799xznaihdKuqVau66nr59QiKJn5UrlzZVVg55ZRTrHPnzta7d2/nHaSKaxJVFMWTU6BSWp/SyiRS6SQ2FUJVOgUopclJXNq8ebPJyD+WwPTiiy+6aKa+ffs68UEplI0bN3bjUViBUGOjanUyG5foKPFRIqTESFWtk5eTfCC8HLWW/1nOFhCAAAQgkA4C8odUKrhumigNXFYA+o1XVI1ez0TaNgJU/kde5wB5VcZTdD0LBMJAQBYj8lPV+bHO5VmiE0CAis6FV5NEAAEqSSA9uBt9sSp97q233rJBgwa5KJuTTjrJiUeHHXaYVaxY0QkY0USmwrwWTaBSWp+icCRSjR492p3MzpgxY59YpfQzRQctWbLE5EOlqKp169Y50UrCVeRDQpvEn5wPmazLqD2y7YMHD3YpbjnXVeqbTrgi96vnEsqUbqg2KC1uwYIFLjVOJ+DyydLdsClTptibb77phL7HHnvMsZU/l6Jbki0wRfZF0U2KSlM6nUTF5s2bO5HxtttuMwldX331lW3bti0l4p4HpzdNggAEIACBFBHQzRXdTLrhhhvcTROlcuuGh/6qsIn8AyVK6XcznTc5EKAKNuB5VcYbM2aMswQo2N7ZCgL+IaDz/LffftuJsqoevWjRInc9gCVF9jFEgMrOg/+STAABKslAPb675cuXu5NGmY/fdNNNdt5555lEqWOPPdZF0ShSSieYyYiUihRPoj2XmKLjHX300XbiiSfaqaee6iqxde3a1UVVDRgwwIlWDz/8sEU+lHKoKC956kQ+OnXq5ASayGOpiuDIkSOzradtsqo/Ru5Xz++++24XPSYvrEsuucTOOussJ/Qoakk+WRK4khG5FNnGaM9LlSrlIpvk79WoUSNr0aKFa4tO+h988EEbN26cExcVTcYCAQhAAAIQSBYB3eRRxMwxxxzj0vn1+6eIZ6Xjq4CJ0ruV6q3fJlXrVSRBuhYEqIKTpjJewdmxZbAIKGtB5/s6t9Z1kKrBT58+3WQrou+/VGRp+I0gApTfRsxj7d26datLE9LdrGiPSy+91J1YKNoj2vtZr6XzDpfHEAa6ORpXfRF//PHHLopGkVISX3SSKVGoQYMGVqNGDSe86O5nNLGE14oUmIvELAlxhx56qLurLFP5du3auWg1RTY99dRTNnXqVBeNhdgU6I8inYMABCCQcQI6J5BnkG4MHXLIIe58QBdmW7ZscZFOOqdUevd1113nfrfq1q3rilooyjgdCwJU4SjnVRlvzpw5ptRLFggEnYCiN3XjWdc5qiqtG76yFdFN608+hOxIkgAAIABJREFU+cSlGWfa2zaTY4AAlUn6ATi2Ij2UJhTrId8YhVNLeIi1jl7XSQdLeAjoS1dhqe+++64NGzbMlGJ2wQUX2Mknn+zuGOjOqOaNzK5lnF22bFlngI0YlV2MUtpcmTJl3F1kRVDpZF13kyXuSWg655xzXCrDQw895NL6dPKX7pSG8MxqegoBCEAAAvEIrFixwkUEHHjggS4aWOnw0RbdnFRFVf3+y29SKfTpWKIJUGqrznWVMs8jbwaKblOBmZzR3Kq2Kw9JWQ1oPGGZN0sY+ZuR/Gp79erlMhx0vq5rGN1sP+qoo9y5+csvv+w88GTNEbabwAhQ6fhFC/AxdGLQrFmzmA8ZGCuUWj9G8daTYRsLBHQXVNFy8kMaO3asM7u+66677Nprr3ViSvv27V3KmkL0jzjiCBc9pTmm1LUsD4l0pPelQwjTj1Tp0qXd50cnwIpikhm47hzrs6QKdGeffbarQqcTdYX4vvLKKy7Md+HCha5yIDnnfKYgAAEIQMArBOQnqBsl+v1SUZN4qSiLFy92qfO6ySJfxHQY+kYToCScKHpYRTh4JMZAUR8at5znSooE0U0y+VnCMjGWcPI3J9l/1KtXzxVqyvl50GdE3y2qBC4/XX3/KJU1DFGCCFBe+VX2aTtk6qw7GbEeisBo2bKlM5uMtY5eT8eJhU8R0+wIAjL2lvG5QvRlNv7EE0/Y7bff7u4wKLVPUVRnnnmmi/5p3bq1E2okfspLQoJVnTp13J2Igw8+2EUNVapUaZ94pR+CrIdOOAsqZOkES8JR1r70V4bsOpYeuqMro2+1RSfiDRs2dF4Y+hFSm3VirpMz5Y3LePxvf/ubuxOsKCZ5U8nUUD9SMjpEYIqYHDyFAAQgAAFPE1AxD900UlS8KrzmtagKrn4/5U2o6N1UL9EEqJwXjfyfPRIbHvBgDhR+DihYQ1kg9957r6sGqiwRRYIG9TwfASrVv2Yh3z8m5CGfABnqvoQqhfZL3Pzss8+cz5FKPKtKnlI+77nnHifq6K6DwmMlXmmuZj2yDMIj7zzVrl07V1U/CUj6wYhc7+KLL7Yrrrhi3760Txmy61h6KKJLFfuee+45F7GkstOK+FKlPpm466Q8DHc/MjQ1OCwEIAABCGSIgH4PdYNG/oMy481rkfCkGza6EaPfx1QvS5cudUVK9JuuarBqKxfXhb+4hiEMmQOJzwHZj+g7T9cGqqodxAUBKoij6qE+6WRDESmK1mCBgJ8JyLRbd2Ijf0QHDhzoyqv6uV+0HQIQgAAEIJAOAkqnV7q8opcT8f5UpJQilvv27etuKqWjjVnHePzxx12af+RvPs8Tv4iGFayYA4nPAWVPqDCDsjZUwEv+uLqJ/vvvv2d9JQXqLwJUoIbTe51BgPLemNCighH4+9//7tL1In9QBw8ejABVMJxsBQEIQAACISOgVHL5GXbv3t0UbRRvUYSUziElWD399NMJRUzF219+33vhhRfspJNOcqnyinbmUXAGurCWtUHk+ZOey+pAKZlZlgQwLjhj2HmTnbxb5eOa05Rf81+vaf7L2/X//u//7P777zcZlwc16inyOxgBKpIGz5NOAAEq6UjZYYYIIEBlCDyHhQAEIACBQBCQh6Hu8MukesKECTHv7sv35J133nH+jRKspkyZYn/++WdaGchvcty4cfbPf/6TRyEZPPDAA9aqVatcxuS6AJdPrHxvZFAPa+ZakOaAbD/69+/v/GjlB5sluiqbQpW+Tz/9dOdjO3ny5NDdzEaASuvPWfgOhgAVvjEPao8RoII6svQLAhCAAATSQeC3335z6XSKCNAdf3kgylw8S1zSX/0v7xP5MKnC7S233JKS9DuJXCp9nnXsdPQ/zMd49913nQiVMxJK5svy5VQ17HhVEcPMjr77j8DOnTvtyy+/tM6dO1v58uWtXLlyLtKvTZs21rNnT1fpe/Xq1aH9/kGA8t+c9lWLEaB8NVw0Ng4BBKg4cHgLAhCAAAQgkACBBQsWWKdOnUzCQ9OmTV1RjkmTJtnHH3/sqrwqTe/YY491VWPPPvtsV6Aj2cKELvymT59ub775pn366acJ+VEl0DVWiUNAQt+oUaNculHOdKTq1as7Y3oVkGGBgN8JSGifOXOmqSiRKnA3a9bMrr76alcI6eeffw5sZbv8jBsCVH5osW6+CajqV7du3Wzjxo353pYNIOAlAghQXhoN2gIBCEAAAn4l8Pnnn9t1113nLs7k8aTogBo1arhIAf0vT6CuXbvaJ598YookSOYiU195rajS1H777WfHHHOMSQBTNBRLagnowlyVDcVe/k+RnlCNGze2MWPGhML/JrWU2XsmCej7RZFPKpygIAwVXPj2229jphtnsq2ZPDYCVCbph+DYn332mVOBg+riH4IhpIv/JYAAxVSAAAQgAAEIJIfA5s2bne/PVVddZSeffLK1aNHC/ZXwpEiZVFVPXrRokbVu3Tqb+JGJKnvJoei/vfz73/92F+eVK1fONgYSo9q3b2/Tpk1LuujoP0q02K8E9L01depUJ0KpkAJLdAIIUNG58CoEIACBbAQQoLLh4B8IQAACEIBAUghs2LDBvv/+e+f/JG+mVC6qMiWxKzIC5/rrr8+zKl8q2xS2ff/444925ZVXujTMyCgoPb/ssstszpw5tnv37rBhob8QCA0BBKjQDDUdhQAECkMAAaow9NgWAhCAAAQgkHkCisi/9dZbrX79+qYKe40aNbLx48eTIpPmoVEaZseOHXNVxpNJeY8ePZwgiUF8mgeFw0EgTQQQoNIEmsNAAAL+JoAA5e/xo/UQgAAEIAABEZAJ+euvv24PP/ywS5fZunUrYDJAIF5lvEGDBlEZLwNjwiEhkA4CCFDpoMwxIAAB3xNAgPL9ENIBCEAAAhCAAAQ8QiCvyngjRowwKuN5ZLBoBgSSSAABKokw2RUEIBBcAghQwR1begYBCEAAAhCAQPoJUBkv/cw5IgQyTQABKtMjwPEhAAFfEECA8sUw0UgIQAACEAg5gb1795oeLP4gkFdlPFUV27lzpz86QyshAIE8CSBA5YmIFSAAAQiYIUAxCyAAAQhAAALeJiB/p08++cSmT59uCxYsMEXYsHifQLzKeJdeeimV8bw/hLQQAgkTQIBKGBUrQgACYSaAABXm0afvEIAABCDgdQISm+677z6rV6+eVapUyTp06GBffPGF7dmzx+tNp31mRmU8pgEEwkEAASoc40wvIQCBQhJAgCokQDaHAAQgAAEIpJDA119/bS1atLAiRYrsezz66KO2efPmFB6VXSeTgCrjtW7d2kqWLLlvDDWeFSpUMCrjJZM0+4JA5gggQGWOPUeGAAR8RAABykeDRVMhAAEIQCB0BD788EM7/vjj9wkXxYoVswEDBti6detCx8KvHVZlvOeff96OPvpoK168+L6xlAhVvXp1ozKeX0eWdkPgfwQQoP7HgmcQgAAEYhJAgIqJhjcgAAEIQAACGSewdetWu/HGG61GjRpWuXJla9KkicnAevfu3RlvGw1InIBSKYcMGWI1a9a0okWLZhOhGjdubGPGjLHt27cnvkPWhAAEPEUAAcpTw0FjIAABrxJAgPLqyNAuCEAAAhCAwH8ILFq0yIYOHWr9+/e3f/3rX7ZlyxbQ+JDAxo0brW/fvk5IjEyp1PP27ds7YZHKeD4cWJoMATNDgGIaQAACEEiAAAJUApBYBQIQgAAEIAABCCSBAJXxkgCRXUDAgwQQoDw4KDQJAhDwHgEEKO+NCS2CAAQgAAEIQCC4BFTF8JxzzrEyZcpkS8WTSXmPHj3s+++/N/lGsUAAAv4hgADln7GipRCAQAYJIEBlED6HhgAEIAABCEAglASojBfKYafTASaAABXgwaVrEIBA8gggQCWPJXuCAAQgAAEI5JfAmjVrTBExn376qf3888+GB1B+CfpzfSrj+XPcaDUEYhFAgIpFhtchAAEIRBBAgIqAwVMIQAACEIBAGgmowt0DDzxgDRs2tDp16ti1115rMhzfu3dvGlvBoTJFgMp4mSLPcSGQfAIIUMlnyh4hAIEAEkCACuCg0iUIQAACEPAFgZkzZ9pxxx23zwdov/32s1GjRpmECZZwEKAyXjjGmV4GnwACVPDHmB5CAAJJIIAAlQSI7AICEIAABCBQAAJvvPGG1a9ff58AVaxYMXvwwQdNogRLeAhQGS88Y01Pg0sAASq4Y0vPIACBJBJAgEoiTHYFAQhAAAIQyAcBVTvr1KmTHXjggVahQgU7+uijberUqbZnz5587IVVg0CAynhBGEX6IG+zf//73/btt986bzuJq7/++qur6qjUYqUdr1271nbs2BE4WAhQgRtSOgQBCKSCAAJUKqiyTwhAAAIQgEBiBD744AO7+eabrUePHjZ27FjbtGlTYhuyVuAIxKuMN3DgQFu9ejX+YIEb9eB0SAKTBKdhw4bZueeea82aNbPrrrvOJk2a5KI69d2mtOO33nrLVqxYEZyO/7cnCFCBG1I6BAEIpIIAAlQqqLJPCEAAAhCAQOYJ6IJQ0QgLFy60Tz75xKZNm2azZs2yuXPn2qpVq2zXrl2ZbyQt2EeAynj7UPDEhwS2bNliw4cPt0svvdS6dOliV155pV1wwQV266232oQJE2zMmDH23HPP2eeff27bt2/3YQ/jNxkBKj4f3oUABCDgCCBAMREgAAEIQAACwSPw+++/24IFC2zIkCHWoUMHq127tpUsWdKqVq1qLVq0sD59+jhBavPmzUTVeGj441XGa9SokY0ePTqQF+8eGgKaUkAC33zzjb3yyiumqM6VK1fahg0b7LvvvnNzVlGevXr1sjfffNPWr18fyO8cBKgCThw2gwAEwkUAASpc401vIQABCEAg+AT++OMP5yWlNBj5S0l8UjrMySefbK1bt7YGDRpYuXLlXAW+Z555xl0oBp+Kf3oYrzJeu3bt3Nju3LnTPx2ipaEg8NNPP5l87eT5pOhLLdu2bbOPPvrIRo4c6aKgJEzl9LhT5J+EV4nmeu7XBQHKryNHuyEAgbQSQIBKK24OBgEIQAACISKg9DdFBeihu/67d+9OS++//vprJzZVqlTJTjnlFJPINH/+fGcArAtAeQ117drVqlWrZrVq1bLXXnuNqJq0jEziB8mrMt7s2bPTNp8SbzVrhpmABCSl9WaJTxKV9N0nz6fp06c7D7Oc34FaV8bkM2bMsK+++srX30MIUGGe/fQdAhBImAACVMKoWBECEIAABCCQMAH5ociMt02bNi7q6IEHHnC+SwnvoIAr6rg33XSTValSxS666CKbM2dOVKFC4tgtt9zi1jvrrLPcen6OPiggLk9vRmU8Tw8PjYtDQFXu5DU3btw4Jy7JQD+n+CRT8iVLljhjcgni+o5cs2bNPgErzu49+RYClCeHhUZBAAJeI4AA5bURoT0QgAAEIBAEAu+//741adLEihQp4h6VK1e2d955J9dFWLL7qkiC4447zg4//HCbOHFi3OPp4k/iU5kyZezZZ5/1dfRBsjl6ZX95VcbTBTsLBLxCQBFNMhiX+KTIJ30fRROf1N558+Y5U/J7773Xjj/+eLvjjjsQoLwykLQDAhCAQKoIIECliiz7hQAEIACBMBN46qmnnPdSlgBVokQJ54Mif5RULk8++aRLq+vWrZsriZ7XsQYNGmQHH3yw9evXzxkH57U+76eXQFZlPBmQFy9efJ+gqXlVvXp1e/rpp01G8iwQyDQBiU+ai19++WXUyCd50ylNL8sDShFRipRSyvDZZ5+NAJXpAeT4EIAABNJBAAEqHZQ5BgQgAAEIhI2AIgDOOeccK1u2rIswUlTSJ598kvL0kttvv90OOuggGzBggK1bty5P7M8//7zVrVvXlU5XxSoW7xHIqownv66iRYtmE6EUZafKYkEsa++9kaBF8Qgo/VcV8MaPH2+fffaZrV27dl8EpsQp+c+pMqdS7yKXRYsWWceOHRGgIqHwHAIQgEBQCSBABXVk6RcEIAABCGSSgO7uK+VOkUjyNxk9enSuC69UtC9LgLrzzjsTEqCee+45l6532WWXuZLpqWgT+yw8AVXGU5SaUjmzouqy/spoXibPVMYrPGf2UDACimyaOnWqKfJzypQp2cQnRfFliVNKKV21alW2gyBAZcPBPxCAAASCTQABKtjjS+8gAAEIQCCzBFQVKivlJB0tyRKULrnkkjwFJYlkWYJV//793UVjOtrIMQpGIKsyXvny5bOJUMWKFbO//OUvzncnp9FzwY7EVhBInIBS65RGd9ddd5lSel9//XX79NNPbdmyZaZiBytWrNgnTkmU37BhQ7adI0Blw8E/EIAABIJNAAEq2OObrt5t27bNPv74Y3dXK50XWunqH8eBAAQg4BcCSvNr1aqVS6tTapY8VmItSoc5/fTTXcreSy+9ZEr1YvE2AY1vhw4dXFpnVgSU/pYsWdJ69eplP/zwg1HN0NtjGLTWLV++3JmJP/LII058euaZZ5wQdf/999sTTzzhqttpbj788MPOeDxnpB4CVNBmBP2BAAQgEIcAAlQcOLyVMAHd+TrqqKNcFaVUG+wm3ChWhAAEIBBCAkqFUTRTlSpVnFChSnhKf5EHS9aiqKzFixfb9ddfb1WrVrWLLrrIFi5cmPU2fz1OQFEkLVu2dKJTpAhVsWJFu+eee4hk8/j4Ba15kydPthdeeMF9pygCT98t8qBr3769NWvWzJQiqvTRmTNnmm5Y5lwQoHIS4X8IQAACASaAABXgwU1j1xCg0gibQ0EAAhknIDFHqSUqIy7hRqa6Xoo6WbJkiTMVL1eunDVv3tyGDx9uH374oUvR+uKLL1yFqgsvvNAOPPBAa9y4sUmkkijF4g8CmmtKtWzYsGGuyng1atQwRaBQGc8fYxmEVsp4XNGUWRHwmp9z5syxRx991G699VYbMWKEffPNNzGjMRGggjAL6AMEIACBBAkgQCUIitXiEkCAiouHNyEAgYARkIfJ0KFD3R3+s846y13wr1+/3lO9nDVrlnXp0sUkSJQpU8YOO+wwa9GihRMtVJmvUqVK1rZtW3v11VcRKzw1cok1RtHGSnHS+FIZLzFmrJUaAoq6lA9U5CJBe+vWre67RVFP+j8yCjNyXQSoSBo8hwAEIBBwAghQAR/gNHUPASpNoDkMBCDgCQKvvfaaHXnkkfuMoGvVquUqP2VFAHiikWYuFevxxx+38847z0VCNWnSxE444QSXEtO3b18XlZAK02px0MWnyq4rGktmxL/88kuui1SvcPJrOySE9unTh8p4fh1A2u0IIEAxESAAAQiEiAACVIgGO4VdRYBKIVx2DQEIeI7AwIEDnXdSlv9OiRIl7OWXXzZFAnhxUbskBMmDRd/XSs9KVcqghCZFXz355JPWu3dvUzW+v/71r86AeNKkSbZmzZp9qTpeZOW3Nn3//ffWtWtXozKe30aO9ioqSt8XSuE79dRT7W9/+5v7flq7dm3MdD0vUyvi5cbRNghAAAJeIYAA5ZWR8Hc7EKD8PX60HgIQyB8BmUArnU3Ck6qPHXPMMabqZLFSTPK3d3+urb7/9NNPpoirRo0aWYUKFezQQw+1I444whQhJoGkZs2aziBdvxleFev8SD9eZbybbrqJynh+HNQQtFlCuL4L3njjDSdS33HHHfb22287v7p169b5jgAClO+GjAZngsD27dvt22+/depzqu6EZaJfHDNxAghQibMq6JoKLV6xYkWgUw8QoAo6O9gOAhDwIwGll8no+fzzz7dOnTrZP//5T9u4caMfu5K0Nq9evdpuvPFGV33v8MMPt8svv9weeughGz16tD311FPWvXt3J9RJiFLVPZkUey1lMWkwMrCjvCrjKfKMBQIQSB0BBKjUsWXPASIwf/58k3nm+++/bzt37gxQz+hKogQQoBIlVfD1sk7CFWbs10UXVhKrdcEQ7SE/lNq1a9udd95pH330UdR1tN3y5csDLcT5dXxpNwQgUDACv/32m6XCQ6lgrcncVopmeuSRR5whtnymRo4cmUuQU7rNu+++ayeffLKLhlJ1rFWrVmWu0QE7MpXxAjagdMd3BBCgfDdkNDgTBL766isXHq27U4RCZ2IEMn9MBKjUj8Fxxx1nvXr1Mj+GE2fRmTx5srubfeaZZ1q0h1JRVFWpQYMGLo8/2jp6bdiwYbkuSrKOwV8IQAACEPAnAd2gaNOmjR100EH29NNP25YtW2J2ZPz48S4SSul5EqSIgoqJKt9v5FUZb8yYMabsBxYIQCD5BBCgks+UPQaQAAJUAAc1n11CgMonsAKsHgQBavbs2fbggw+a8vOjPbp16+YuPBRR2a9fv6jraLsJEyaYyvGyQAACEIBAcAgoBVFeT6q2p+j6eIsioa677jp30+Kxxx6LK1bF2w/vRScQrzKeos+mTZtG1kN0dLwKgUIRQIAqFD42DgsBBKiwjHTsfiJAxWaTrHeCIEDlxQIPqLwI8T4EIOAnAvJ4UnWxZcuWuWpMYTYXjzdu4qI0xNtuu80qV65st99+u6tyF28bvad0vcMOO8x69uzpUrPzWp/380cgXmW8zp0729y5c0kdzR9S1oZAngQQoPJExAoQMEOAYhYgQKV+DiBApZ4xR4AABCCQLAL//ve/7cUXX7RLLrnErr/+eps0aRKRmzngKtVr4cKFNmPGDHvhhResVatWriJg3759bcmSJXl6/T377LMmo/IuXbq49XPsnn+TQIDKeEmAyC4gkA8CCFD5gMWq4SWAABXesc/qOQJUFonU/UWASh1b9gwBCEAg2QSUTlavXj0rUqSIe0hc0fkSUVBmMrpWVVcxOvvss61SpUpWpkwZK126tBUrVsxFNfXp08cVo4iVbi2Od999t1WtWtVuvvlmjMiTPYEj9qfKeJq/JUuW3DefNa8rVqxo99xzT0LRahG74ykEIBCHAAJUHDi8BYEsAghQWSTC+xcBKvVjjwCVesYcAQIQgECyCCidTGbaWQLUAQcc4KKgJL6Effnpp59M1etkIF69enVr2bKlixQ7//zz7eCDD3bMJES1bt3a3nrrraiRY2vWrLGLL77YVcJ75plnMMVO4aSiMl4K4bJrCOQggACVAwj/hpOAPAxU9nzp0qVRH2+//bY7YRg+fLgtXrw46jraViXYOfEK5hxCgCrcuKp65MqVK2N+dvT5Ofroo+2qq65yd9BjfRZXr16dZ8pC4Vqa2q3xgEotX/YOAQikj8Arr7xijRo1suLFi7u0MlV3mzNnTvoa4NEjKe1u4MCBTnwSnyFDhpgEqd27d7vfwIsuushFQmUJdxKhZs6cme23TemN2q5mzZqmmzMff/wxkWUpHu+synhiXrRo0X3CqsapSZMmRmW8FA8Auw8NAQSo0Aw1HY1HYPr06XbTTTfZtddeG/WhaiX777+/nXLKKe4COdZ6b7zxhjOZjHcs3vMnAQSowo3bzz//7Cq+xfrs6HXdSW/YsKH95S9/ifo51Dr33XefrV+/vnCNyeDWCFAZhM+hIQCBpBJQhM79999vp59+up177rn26quv2qZNm5J6DD/ubMqUKXbsscc68ei1117LFbk0btw4JypJuJO4oUio3r17O6+oVatW2bfffuvEp7p167qbn08//TQV8NI0EVQZT/5cMorPEgiz/lIZL02DwGECTwABKvBDTAcTIfDee++Z7kidccYZUR/Nmze3UqVKuTsgp512WtR1tO1zzz1nuoPCEjwCCFCFG9Mff/zRunXrFvOzo89P+fLl3Ql7+/btY67Xq1cvUxSUXxcEKL+OHO2GAARiEZAQpUhyIsD/Q0i/UxUqVLB+/fpF9W1SRLCq2ymySb5QEjhq165tPXr0cOKHbnbqhozMx/v37+8qDMZiz+vJJ/DDDz9Y165d3RhmiU/6K6GQynjJ580ew0cAASp8Y06PC0AAD6gCQAvYJghQqR/QMHhASYi75pprbOLEia5keeqpcgQIQAACEEgXAYlLF1xwgYuaHzt2rEu7i3bsXbt22bvvvus8nqpUqeLEjbJly7q0vaOOOsp0s/P555931g7Rtue11BKgMl5q+bL3cBNAgAr3+NP7BAkgQCUIKsCrIUClfnDDIEClniJHgAAEIACBTBFQ5TtFMMl4fNq0aXk2QxG9EqxUfa1jx4720EMPmXxHly1bls0TKs8dsULSCVAZL+lI2SEEHAEEKCYCBBIggACVAKSAr4IAlfoBRoBKPWOOAAEIQCBRAkqrk3+fUuwUscOSN4FffvnFOnTo4FLoZO+QV1rizp07rVOnTi5iSibXMipn8QYBKuN5YxxoRfAIIEAFb0zpUQoIIEClAKrPdokAlfoBQ4BKPWOOAAEIQCARAhKdlAKmyqS33nqrq8L222+/JbJp6NdRwQwVrpHP0+bNm+PymDdvnqkKngzHVQmPxVsEqIznrfGgNcEggAAVjHGkFykmgACVYsA+2D0CVOoHCQEq9Yw5AgQgAIFECAwdOtRq1KixrxLY2WefbfPnz09k09CvM3LkSGcgLmFJVZZjRY+pYuCdd95p1apVc1FQixYtCj07LwKgMp4XR4U2+ZkAApSfR4+2p40AAlTaUHv2QAhQqR8aBKjUM+YIEIAABBIhcPXVV7sonqwqYBJJiNBJhJzZ2rVr91VR69Kli+O2ceNG27Nnj9uBjMqXLl1qw4cPtyOOOMJVfx09ejSFKRLDm5G1qIyXEewcNKAEEKACOrB0K7kEEKCSy9OPe0OASv2oIUClnjFHgAAEIJAIgfvuu89VZCtatKir0NamTRubO3duIpuyjpnNmDHDeUGpsp0ioe6//35X9U4RUa+88oopTU+inszKBw0aZDIjZ/E2ASrjeXt8aJ1/CCBA+WesaGkGCSxcuNCdSEyZMiVmKHUGm8eh00AAASr1kK+44grnmSETVxYIQAACEMgcgW+//dZuvPFGa96Fryu4AAAgAElEQVS8ubVv3975QfHdnPh4yMBaItTll1/u0vHKlStnpUuXtjJlyri/Bx54oDVt2tSGDBmC+JQ41oyvGa8ynoREeaexQAAC8QkgQMXnw7sQcARkQvjdd9+ZTr7yqmgCsmASQIBK/bj++OOPtnLlSkpPpx41R4AABCCQJwGlikmI0kV1VvpYnhuxQjYCSseTmXv37t3trLPOcmLehRde6IzdP/jgA9u+fXu29f36j86N5ZW0ZMkSU9bAl19+abp5u2rVKlOlv6AseVXGe/rpp/M0ng8KC/oBgYISQIAqKDm2gwAEQkUAASpUw01nIQABCEAAAkkloCqCW7ZsCdxNFt2kleA0ePBgu/jii+2YY46xxo0bm4zr+/TpY4oaWrduXWBETCrjJfVjwc5CSAABKoSDTpchAIH8E0CAyj8ztoAABCAAAQhAILgElBnwxhtvmDzCDjroIKtdu7Ydf/zx1qxZM2vQoIFVrFjR6tSpY3fddZeLjtq9e3cgYFAZLxDDSCcyRAABKkPgOSwEIOAvAghQ/hovWgsBCEAAArEJ7Nixw3kPKSIHa4HYnHgnNoFdu3a59MIjjzzSGapfdtll9txzz9ns2bNt3rx5LvLpb3/7mx111FFWvnx5Fw21fPny2Dv02Tt5VcabM2eOBUVw89nQ0FyPE0CA8vgA0TwIQMAbBBCgvDEOtAICEIAABApHQL5E48aNs5tvvtmGDRvmPC4lJrBAID8EJLDIoL5KlSrWv39/k7i0d+/ebLtQ2uFLL71kTZo0scMOO8xefvll02tBWVQZr2PHjs5cvkiRIpb1KFmypPXs2dMkUiHwBmW06UeyCCBAJYsk+4EABAJNAAEq0MNL5yAAAQiEgoAuhocOHWo1atRwF8vFihUzRakEKTIlFAOZ4U5KaJKAecABB5gq2C5evDhmiyRuKgWvatWqpiipRYsWxVzXj2/Eq4x37733Ov8rP/aLNkMgVQQQoFJFlv1CAAKBIoAAFajhpDMQgAAEQkngjz/+sM6dO1upUqX2RWs0bdrUmUiHEgidLhCBrVu32v/93/+5yJ8xY8bkaTCutLzWrVu7dLyZM2cW6Jhe3ShWZbz99tvPGbGr7ywQgMD/CCBA/Y8FzyAAAQjEJIAAFRMNb0AAAhCAgE8I6GK5X79+duCBB+6LgDr33HNt4cKFPukBzfQCAc2Xdu3aOYPxadOm5dmkzZs32znnnGOlS5e2sWPH5krVy3MHHl9BlfEeeOABq1mzphUtWtQJcy1btjSJc9u2bfN462keBNJLAAEqvbw5GgQg4FMCCFA+HTiaDQEIQAAC2Qh89tlndtVVV9mxxx5rbdu2tddff90U0cICgUQJKKqnVatWVq9ePZsxY0aem8n0/rzzzjN5I7322muBNOdWZTyJu3Xr1rUOHTqYIr3wVstzarBCCAkgQIVw0OkyBCCQfwIIUPlnxhYQgAAEIOBNAps2bbJZs2bZ0qVLAykGeJN6cFq1fv16Z76t6najR4/Ocw6pKl6bNm2sdu3aNnXq1OCAyNETmY6PHDnSvv766zzTEnNsyr8QCA0BBKjQDDUdhUDwCHz88ce2ZMkSk6dFqhcEqFQTZv8QgAAEIAABCPiFQI8ePaxcuXLWq1evuCb2O3fudMb3Ep+U7ikxigUCEAgvAQSo8I49PYeA7wk0aNDAhTtv3Lgx5X1BgEo5Yg4AAQhAAAIQgIBPCLz77rvWrFkzq169uhOY1q5dmyvqR6mdinhSul7lypXdeoq+Y4EABMJLAAEqvGNPzyHgewIIUL4fQjoAAQhAAAJJJiC/nXXr1tn27dsDZ/acZFTsrhAE5G8k421FNsl8+84773S+RzIoV3T6nDlz7JlnnrEWLVpYpUqVnO/Y4sWLC3FENoUABIJAAAEqCKNIHyAQUgIIUCEdeLoNAQhAAAJRCaxatcpVGZMY8MILL+DxFJUSLyaLwOrVq23gwIHWpEkTl44nA+6OHTvaRRddZCeccIJVqFDBDj30ULvkkktM5ve7d+9O1qHZDwQg4FMCCFA+HTiaDQEImCFAMQsgAAEIQAAC/yHw559/2pAhQ9wFf5EiRVzFsQEDBphSo1ggkCoCv//+u40bN846d+5sJ554ojs3O/LII+24446zU045xR566CHnEbV3795UNYH9QgACPiKAAOWjwaKpEIBAdgIIUNl58B8EIAABCISXgMyeVep+v/32MwlQeqjy2Ny5c8MLhZ6njcBvv/1mSr975513XBSeIp7+/e9/5/KFSluDOBAEIOBJAghQnhwWGgUBCCRCAAEqEUqsAwEIQAACYSCgSJTLL7/cypQps0+AOuecc5woEIb+00cIQAACEPA+AQQo748RLYQABGIQQICKAYaXIQABCEAglATGjh1rHTp0MKVAyYPnlVdeMVUiY4EABCAAAQh4gQAClBdGgTZAAAK5CKh6z/z5810VFVVSifaoU6eOXXHFFTZ9+vSo72sbVVxRpZbCLn//+9/tgAMO2HdXWakNgwcPNsoJF5Ys20MAAhCAQDIJfPfdd/bmm2/avHnzTGl5LBCAAAQgAAGvEECA8spI0A4IQCAbAQlHXbp0sTPPPDPmo2zZslajRg07+eSTY67Tt29fW79+fbZ9F+QfBKiCUGMbCEAAAhCAAAQgAAEIQAAC/yGAAMVMgAAEPElgxYoVrprPHXfcYbEeBx10kDVr1sx69+4dc52nn37aNm/eXOg+IkAVGiE7gAAEIAABCEAAAhCAAARCTAABKsSDT9ch4HcCeED5fQRpPwQgAAEI5IfAH3/84Tyd9JcFAhCAAAQg4DcCCFB+GzHaCwEI7COAALUPBU8gAAEIQCDgBNasWWPvv/++DR8+3P71r3+59PI///wz4L2mexCAAAQgECQCCFBBGk36AoGQEUCACtmA010IQAACISWwZ88ee+ihh6xWrVpWrFgxq1KliinFfMuWLSElQrchAAEIQMCPBBCg/DhqtBkCEHAEEKCYCBCAAAQgEAYCqrh6+umnO/FJVVj1uPTSS23JkiVh6D59hAAEIACBgBBAgArIQNINCISRAAJUGEedPkMAAhAIH4F169ZZx44drUSJEk58kgDVuXNn+/7778MHgx5DAAIQgIBvCSBA+XboaDgEIIAAxRyAAAQgAIGwEFDKXbt27axu3brWtGlTGzNmjG3fvj0s3aefEIAABCAQAAIIUAEYRLoAgbASQIAK68jTbwhAAALhI7B792776quv7OWXX7bZs2fbjh07wgeBHkMAAhCAgK8JIED5evhoPATCTeCaa66xZ555xpWkTjWJv//973bAAQfsS31Q+sPgwYNNvhwsEIAABCAAAQhAAAIQgAAEIBCfAAJUfD68CwEIQMARQIBiIkAAAhCAAAQgAAEIQAACECg4AQSogrNjSwhAIEQEEKBCNNh0FQIQgEAGCCjFTml1e/bsycDROSQEIAABCEAg9QQQoFLPmCNAAAIBIIAAFYBBpAsQgAAEPEpg5cqVNnnyZOfvNHPmTNu8ebPt3bvXo62lWRCAAAQgAIGCEUCAKhg3toIABEJGAAEqZANOdyEAAQikicCuXbts4MCBVr16dStWrJjVq1fPxo8fj8l4mvhzGAhAAAIQSB8BBKj0seZIEICAjwkgQPl48Gg6BCAAAQ8TWLVqlbVt29aKFi26r9DFjTfeaMuXL/dwq2kaBCAAAQhAIP8EEKDyz4wtIACBEBJAgArhoNNlCEAAAmkg8NNPP1m7du1c9JMqrOrRvXt3W7ZsWRqOziEgAAEIQAAC6SOAAJU+1hwJAhDwMQEEKB8PHk2HAAQg4GECf/75p919993WuHFjl4bXpEkTmzBhAil4Hh4zmgYBCEAAAgUjgABVMG5sBQEIhIwAAlTIBpzuQgACEEgjgQ0bNthbb71ljz76qMmE/Ndff03j0TkUBCAAAQhAID0EEKDSw5mjQAACPieAAOXzAaT5EIAABCAAAQhAAAIQgEBGCSBAZRQ/B4cABPxCAAHKLyNFOyEAAQhAAAIQgAAEIAABLxJAgPLiqNAmCEDAcwQQoDw3JDQIAhCAgG8IyOdpz549tnfvXt+0mYZCAAIQgAAEkk0AASrZRNkfBCAQSAIIUIEcVjoFAQhAIOUE1qxZYx999JG99957NmfOHNu+fXvKj8kBIAABCEAAAl4kgADlxVGhTRCAgOcIIEB5bkhoEAQgAAHPE9i5c6c9+OCDdsQRR9j+++9vrVu3tlmzZtkff/zh+bbTQAhAAAIQgECyCSBAJZso+4MABAJJAAEqkMNKpyAAAQiklMDixYutefPmVqRIkX2PQYMGmaresUAAAhCAAATCRgABKmwjTn8hAIECEUCAKhA2NoIABCAQagKfffaZNW3a1IoWLbpPgOrXr5+tWrUq1FzoPAQgAAEIhJMAAlQ4x51eQwAC+SSAAJVPYKwOAQhAAAL2+++/W69evezwww+3qlWr2tFHH20TJ060Xbt2QQcCEIAABCAQOgIIUKEbcjoMAQgUhAACVEGosQ0EIAABCCjaadSoUXb33XfbpEmTbOvWrUCBAAQgAAEIhJIAAlQoh51OQwAC+SWAAJVfYqwPAQhAAAIQgAAEIAABCEDgfwQQoP7HgmcQgAAEYhJAgIqJhjcgAAEIQAACEIAABCAAAQjkSQABKk9ErAABCEDADAGKWQABCEAAAtEI/Pnnn7Z3795ob/EaBCAAAQhAAAIRBBCgImDwFAIQgEAsAghQscjwOgQgAIHwElizZo19/PHHNn36dFu8eLEzHQ8vDXoOAQhAAAIQiE8AASo+H96FAAQg4AggQDERIAABCEAgksCOHTvswQcftPr161vlypXt4osvtm+++cYUEcUCAQhAAAIQgEBuAghQuZnwCgQgAIFcBBCgciHhBQhAAAKhJiCx6YQTTrAiRYq4R7FixezJJ5+kyl2oZwWdhwAEIACBeAQQoOLR4T0IQAAC/yWAAMVUgAAEIACBSAKTJ0+2o48+OpsAddddd9n69esjV+M5BCAAAQhAAAL/JYAAxVSAAAQgkACBwgpQW7duteXLl9uuXbsSOBqrQAACEICA1wls2rTJrrrqKqtatapVrFjRiVFTp061P/74w+tNp30QgAAEIACBjBBAgMoIdg4KAQj4jUBhBagPPvjA+vTpY6tWrfJb12kvBCAAAQjEIDB37ly7++67rWfPnjZu3DjbvHlzjDV5GQIQgAAEIAABBCjmAAQgAIEECBRWgBo1apQdcsghNn/+/ASOxioQgAAEIAABCEAAAhCAAASCRQABKljjSW8gAIEUEUCAShFYdgsBCEAAAhCAAAQgAAEIhIIAAlQohplOQgAChSWAAFVYgmwPAQhAAAIQgAAEIAABCISZAAJUmEefvkMAAgkTQIBKGBUrQgACEAgEAVWzmz17tn355Ze2cuVKzMUDMap0AgIQgAAEMkkAASqT9Dk2BCDgGwIIUL4ZKhoKAQhAoNAEtm3bZo899pg1bdrUGjVqZH379rWffvrJ9u7dW+h9swMIQAACEIBAWAkgQIV15Ok3BCCQLwIIUPnCxcoQgAAEfE1g5syZ1rhxYytSpIh7lC5d2saMGWM7d+70db9oPAQgAAEIQCCTBBCgMkmfY0MgRQQWLFhgc+bM4UQ5iXzzEqC2b9/uym+rBHe0x7Bhw6xq1ar26aefRn0/axtd3HCHPYkDx64gAAEIRCHw22+/2e7du6O885+XXnzxRTv88MP3CVDFihWzJ554wrZs2RJzG96AAAQgAAEIQCA+AQSo+Hx4FwK+JHD11VfbmWeeaatWrfJl+73Y6LwEqMmTJ5tEJqVsRHtcdtllVr58ebvllluivp+1zbfffovPiBcnAG2CAAQCQ0Di0+eff24bN26M2afvvvvOzjvvPKtYsaKVK1fOpeHNmjXL/vzzz5jb8AYEIAABCEAAAvEJIEDF58O7EPAlAQSo5A9bXgLU/fffb+3atbNmzZpFfdSpU8dKlCjhLmJiraPX3333XduxY0fyO8AeIQABCEDAEfjkk09s6NCh9vPPP8clMnXqVOvZs6d1797d3nzzTdu0aVPc9XkTAhCAAAQgAIH4BBCg4vPhXQj4kgACVPKHLS8BShWSFi5caPPnz4/6uPfee61y5co2fvz4qO9nbac78txhT/74sUcIQAACIqA055tvvtnuueceooSZEhCAAAQgAIE0E0CASjNwDgeBdBBAgEo+5bwEqLyOOGrUKDvkkEOc+JTXurwPAQhAAAKpIfD111+7KNXb/r+9ewuxqvrjAF5Y9Ieegooi6ApBD0FFRBcqH4JI6UpBPRQFSQTpQ0VWZFfpQml2VbCgLLGsLEVN0XC0wmoQStLSsquO91tapqbrz9p0Bie3esazzpl99v4MDDOzZ+/fXuvzG3z4uvbaQ4eGrq6u5txEVQIECBAgQCBXQACVy+IggfYWEECl758AKr2pigQIEGilwI4dO8LDDz+cvRDiscceC2vWrGnl7d2LAAECBAhUXkAAVfk/AQBlFBBApe+qACq9qYoECBBopcDixYvDhRdeGOIb7R566KHQ0dERvv766yyI+ueff1o5FPciQIAAAQKVFBBAVbLtJl12AQFU+g4LoNKbqkiAAIFWCcSAafjw4dmj0Icccki4+OKLwznnnJN9ffbZZ8PKlStbNRT3IUCAAAEClRUQQFW29SbezgLffvttWLBgwT4/r7rqqnD++eeHjz/+eJ/nxOvjZqw+6hMQQNXn5CwCBAgUUSC+8a5///6hX79+IQZQe34ec8wxYebMmWHnzp1FHLoxESBAgACB0ggIoErTShOpkkBthdPll18e8j6PP/74cNRRR4VLL7009/e1a5YvX14ltobmKoBqiM/FBAgQ6DOB+GbRkSNHhhNOOKFH8FQLoQ477LDw5ptvhj///LN7jDGM2rZtW6jn0bzdu3dn18Y9peJKqs2bN/cIs+J/9sTa9dTqHoBvCBAgQIBACQUEUCVsqimVX2DEiBHhgQce2OfnmWeeGU4++eRw11137fOceP3atWvLj5Voho0GUBMnTgwXXHBBWLp0aaIRKUOAAAEC9QjE/2yJ//Fy+OGHdwdQRxxxRLYaKu4HdfTRR4cXXngh2xNq9uzZ2WqoWbNmhfjGvD/++CPEgGl/H3Fz887OzjBq1Kjw+OOPh2nTpoXVq1eHGHzFa5csWZKtRo7BlA8CBAgQIFBlAQFUlbtv7qUVqK2QssIpXYsbDaB++OGHMHny5LBp06Z0g1KJAAECBPYrEAOg0aNHhxNPPLE7fIorn+Iq4RhCxVDquOOOy1ZH1b6effbZYdCgQWHGjBlhy5YtB6y/aNGiEN+qd+6552b/+XPbbbeFGGTFf+/XrVsXpkyZEiZNmuSte/uV9EsCBAgQqIKAAKoKXTbHygkIoNK3vNEAKv2IVCRAgACBAwnElUhXX311FjbVHrn779dDDz00WwUVg6fBgweHuXPn9ngcb3/3WL9+fXjyySfDDTfcEG699dZwyy23hGuuuSYMGzYsWwk1fvz48Nprr4WFCxfad3F/kH5HgAABApUQEEBVos0mWTUBAVT6jgug0puqSIAAgWYLxL2dTj311B6rn2oBVHz87thjjw3nnXdeGDp0aJg/f37466+/ejWkL774IowbNy67dsWKFdkqp/iikLfeeisMGTIk3H333WHq1Klh48aNB3yUr1c3djIBAgQIEGhDAQFUGzbNkAkcSEAAdSCh3v9eANV7M1cQIECgLwVi6BNXJv3vf//rEUDF4Ck+bnfRRRdlK5XiXk8H+1bY7777LixbtixbMVXbKyo+ehcfwYuP/k2fPr17P6hoETcjjxuV//rrr+HHH38M8fHs+HPc8Lx2fV+auTcBAgQIEGimgACqmbpqE+gjAQFUengBVHpTFQkQINBMgffffz+cfvrp3eFTv379sr2e+vfvH5544omwePHiEDcQb+QjrpiKNWrhUdwz6quvvgrx3vPmzctWRNXefrd9+/YwZ86cMGHChPDuu++GN954Izz11FPZG/o6OjqyVVLx3FqtRsblWgIECBAgUEQBAVQRu2JMBBoUEEA1CJhzuQAqB8UhAgQIFFQgvr3u5ptvDkceeWS20fhJJ50ULrvssvDcc8+Fn376KdRCoZTD37p1a4iP5L333nt7hU/xPr///nu44447wssvv5yNIb4V74MPPgjXXnttuP3228Nnn33WHUKlHJdaBAgQIECgKAICqKJ0wjgIJBQQQCXE/LeUACq9qYoECBBolkB8g13cVPyUU04JAwYMyB6Hi4+9NSN4iiuWYuD15Zdfdq98ipuf//deS5cuDfENeXHT8vj9zp07Q2dnZ7Z5+cCBA7OVUXGMcaWUDwIECBAgUEYBAVQZu2pOlRcYMWJEePDBB7PXP1ceIxGAACoRpDIECBBoskAMdp555pks2Bk7dmzo6uoKu3btaspdY/i0bt268Pnnn3evfNozfIphUnxML4ZRcf+nTz75JHzzzTchPqoXxxT3irr++uuzz2nTpoVVq1ZlwVRTBqsoAQIECBDoYwEBVB83wO0JEGgPAQFUe/TJKAkQIFB7FG7NmjVN309p/fr1YebMmWHy5MnZ3k9r167tXvkUw6mff/45xLfixcAp/hzHFj9jGBXDpjFjxoSbbropPP3009mm5DGwiuf5IECAAAECZRQQQJWxq+ZEgEByAQFUclIFCRAg0NYCMUSaMmVKePXVV8PcuXPDnuFTXN20YcOGLJyKK5vi72ofMRhbtGhReOedd8Kdd94Z7r///mz/p1jPBwECBAgQKLOAAKrM3TU3AgSSCQigklEqRIAAgbYWiCuU4kql+fPnh3vvvTd7k93EiROzPaB+++23LGz65ZdfwtSpU7MNx+MKqU2bNnXPOZ4Tr3377bfDkCFDwuDBg7PNyFeuXNnjjXrdF/iGAAECBAiUREAAVZJGmgYBAs0VEEA111d1AgQItItA3GMqbiL+0ksvheeffz7E8CmugnrkkUeyR+lefPHFMHz48CxYit8vWbIkC5bi/GJ4FR/Hi4/fxcfzPvroo+zNePHlIfH7GE7t2LGjXSiMkwABAgQI9EpAANUrLicTIFBVAQFUVTtv3gQIEOgpEDcVj6ubJkyYEGpv1lu4cGH28o8rr7wyXHHFFeG6664Ljz76aLYqKp4fP+Kb8lasWJHtAVXb5ymueho2bFg466yzwj333BM+/fTT7Pc97+gnAgQIECBQDgEBVDn6aBYECDRZQADVZGDlCRAg0CYCcYVSfJNd3NepFiTFr8uWLQszZswIkyZNyvZ0iuFSXC1V+4hvyhs5cmRYsGBB9ghfPP7333+HUaNGhdNOOy3ceOONWbC1efPm2iW+EiBAgACBUgkIoErVTpMhQKBZAgKoZsmqS4AAgWoIvP766yGukIobl9dWRW3cuDHbQ+qMM84IgwYNCrNmzcpWSlVDxCwJECBAoGoCAqiqddx8CRA4KAEB1EGxuYgAAQIE/hX48MMPs8f0Ojo6wvr167OgqbOzM9uIfODAgWH06NFh8eLFYdu2bcwIECBAgEApBQRQpWyrSREgkFpAAJVaVD0CBAhUSyDuFzVv3rwwe/bsMGfOnOxxvVdeeSXcd9992Sbm33//fbb/065du6oFY7YECBAgUBkBAVRlWm2iBAg0IiCAakTPtQQIECAQ94lavnx5mD59ehg/fnwYM2ZMiAFU3Deqq6urx35RtAgQIECAQBkFBFBl7Ko5ESCQXEAAlZxUQQIECFROYPv27WHDhg1hzZo1IW5SHj/jPlDxeG1D88qhmDABAgQIVEZAAFWZVpsoAQKNCAigGtFzLQECBAgQIECAAAECVRcQQFX9L8D8CRCoS0AAVReTkwgQIECAAAECBAgQIJArIIDKZXGQAAECPQUEUD09/ESAAAECBAgQIECAAIHeCAigeqPlXAIEKisggKps602cAAECBAgQIECAAIEEAgKoBIhKECBQfgEBVPl7bIYECBAgQIAAAQIECDRPQADVPFuVCRAokYAAqkTNNBUCBAgQIECAAAECBFouIIBqObkbEiDQjgICqHbsmjETIECAAAECBAgQIFAUAQFUUTphHAQIFFpAAFXo9hgcAQIECBAgQIAAAQIFFxBAFbxBhkeAQDEEBFDF6INRECBAgAABAgQIECDQngICqPbsm1ETINBiAQFUi8HdjgABAgQIECBAgACBUgkIoErVTpMhQKBZAgKoZsmqS4AAAQIECBAgQIBAFQQEUFXosjkSINCwgACqYUIFCBAgQIAAAQIECBCosIAAqsLNN3UCBOoXEEDVb+VMAgQIECBAgAABAgQI/FdAAPVfET8TIEAgR0AAlYPiEAECBAgQIECAAAECBOoUEEDVCeU0AgSqLSCAqnb/zZ4AAQIECBAgQIAAgcYEBFCN+bmaAIGKCAigKtJo0yRAgAABAgQIECBAoCkCAqimsCpKgEDZBARQZeuo+RAgQIAAAQIECBAg0EoBAVQrtd2LAIG2FRBAtW3rDJwAAQIECBAgQIAAgQIICKAK0ARDIECg+AICqOL3yAgJECBAgAABAgQIECiugACquL0xMgIECiQggCpQMwyFAAECBAgQIECAAIG2ExBAtV3LDJgAgb4QEED1hbp7EiBAgAABAgQIECBQFgEBVFk6aR4ECDRVQADVVF7FCRAgQIAAAQIECBAouYAAquQNNj0CBNIICKDSOKpCgAABAgQIECBAgEA1BQRQ1ey7WRMg0EsBAVQvwZxOgAABAgQIECBAgACBPQQEUHtg+JYAAQL7EhBA7UvGcQIECBAgQIAAAQIECBxYQAB1YCNnECBAIAig/BEQIECAAAECBAgQIEDg4AUEUAdv50oCBCokIICqULNNlQABAgQIECBAgACB5AICqOSkChIgUEYBAVQZu2pOBAgQIECAAAECBAi0SjhuQgsAAAlwSURBVEAA1Spp9yFAoK0FBFBt3T6DJ0CAAAECBAgQIECgjwUEUH3cALcnQKA9BARQ7dEnoyRAgAABAgQIECBAoJgCAqhi9sWoCBAomIAAqmANMRwCBAgQIECAAAECBNpKQADVVu0yWAIE+kpAANVX8u5LgAABAgQIECBAgEAZBARQZeiiORAg0HQBAVTTid2AAAECBAgQIECAAIESCwigStxcUyNAIJ2AACqdpUoECBAgQIAAAQIECFRPQABVvZ6bMQECByEggDoINJcQIECAAAECBAgQIEDgXwEBlD8FAgQI1CEggKoDySkECBAgQIAAAQIECBDYh4AAah8wDhMgQGBPAQHUnhq+J0CAAAECBAgQIECAQO8EBFC983I2AQIVFRBAVbTxpk2AAAECBAgQIECAQBIBAVQSRkUIECi7gACq7B02PwIECBAgQIAAAQIEmikggGqmrtoECJRGQABVmlaaCAECBAgQIECAAAECfSAggOoDdLckQKD9BARQ7dczIyZAgAABAgQIECBAoDgCAqji9MJICBAosIAAqsDNMTQCBAgQIECAAAECBAovIIAqfIsMkACBIggIoIrQBWMgQIAAAQIECBAgQKBdBQRQ7do54yZAoKUCAqiWcrsZAQIECBAgQIAAAQIlExBAlayhpkOAQHMEBFDNcVWVAAECBAgQIECAAIFqCAigqtFnsyRAoEEBAVSDgC4nQIAAAQIECBAgQKDSAgKoSrff5AkQqFdAAFWvlPMIECBAgAABAgQIECCwt4AAam8TRwgQILCXgABqLxIHCBAgQIAAAQIECBAgULeAAKpuKicSIFBlAQFUlbtv7gQIECBAgAABAgQINCoggGpU0PUECFRCQABViTabJAECBAgQIECAAAECTRIQQDUJVlkCBMolIIAqVz/NhgABAgQIECBAgACB1goIoFrr7W4ECLSpgACqTRtn2AQIECBAgAABAgQIFEJAAFWINhgEAQJFFxBAFb1DxkeAAAECBAgQIECAQJEFBFBF7o6xESBQGAEBVGFaYSAECBAgQIAAAQIECLShgACqDZtmyAQItF5AANV6c3ckQIAAAQIECBAgQKA8AgKo8vTSTAgQaKKAAKqJuEoTIECAAAECBAgQIFB6AQFU6VtsggQIpBAQQKVQVIMAAQIECBAgQIAAgaoKCKCq2nnzJkCgVwICqF5xOZkAAQIECBAgQIAAAQI9BARQPTj8QIAAgXwBAVS+i6MECBAgQIAAAQIECBCoR0AAVY+ScwgQqLyAAKryfwIACBAgQIAAAQIECBBoQEAA1QCeSwkQqI6AAKo6vTZTAgQIECBAgAABAgTSCwig0puqSIBACQXGjh0bBgwYEC655JLuz3HjxoUtW7aUcLamRIAAAQIECBAgQIAAgbQCAqi0nqoRIFBSgRg0rV69Oqxatar7c+vWrWH37t0lnbFpESBAgAABAgQIECBAIJ2AACqdpUoECBAgQIAAAQIECBAgQIAAAQI5AgKoHBSHCBAgQIAAAQIECBAgQIAAAQIE0gkIoNJZqkSAAAECBAgQIECAAAECBAgQIJAjIIDKQXGIAAECBAgQIECAAAECBAgQIEAgnYAAKp2lSgQIECBAgAABAgQIECBAgAABAjkCAqgcFIcIECBAgAABAgQIECBAgAABAgTSCQig0lmqRIAAAQIECBAgQIAAAQIECBAgkCMggMpBcYgAAQIECBAgQIAAAQIECBAgQCCdgAAqnaVKBAgQIECAAAECBAgQIECAAAECOQICqBwUhwgQIECAAAECBAgQIECAAAECBNIJCKDSWapEgAABAgQIECBAgAABAgQIECCQIyCAykFxiAABAgQIECBAgAABAgQIECBAIJ2AACqdpUoECBAgQIAAAQIECBAgQIAAAQI5AgKoHBSHCBAgQIAAAQIECBAgQIAAAQIE0gkIoNJZqkSAAAECBAgQIECAAAECBAgQIJAjIIDKQXGIAAECBAgQIECAAAECBAgQIEAgnYAAKp2lSgQIECBAgAABAgQIECBAgAABAjkCAqgcFIcIECBAgAABAgQIECBAgAABAgTSCQig0lmqRIAAAQIECBAgQIAAAQIECBAgkCMggMpBcYgAAQIECBAgQIAAAQIECBAgQCCdgAAqnaVKBAgQIECAAAECBAgQIECAAAECOQICqBwUhwgQIECAAAECBAgQIECAAAECBNIJCKDSWapEgAABAgQIECBAgAABAgQIECCQIyCAykFxiAABAgQIECBAgAABAgQIECBAIJ2AACqdpUoECBAgQIAAAQIECBAgQIAAAQI5AgKoHBSHCBAgQIAAAQIECBAgQIAAAQIE0gkIoNJZqkSAAAECBAgQIECAAAECBAgQIJAjIIDKQXGIAAECBAgQIECAAAECBAgQIEAgnYAAKp2lSgQIECBAgAABAgQIECBAgAABAjkCAqgcFIcIECBAgAABAgQIECBAgAABAgTSCQig0lmqRIAAAQIECBAgQIAAAQIECBAgkCMggMpBcYgAAQIECBAgQIAAAQIECBAgQCCdgAAqnaVKBAgQIECAAAECBAgQIECAAAECOQICqBwUhwgQIECAAAECBAgQIECAAAECBNIJCKDSWapEgAABAgQIECBAgAABAgQIECCQIyCAykFxiAABAgQIECBAgAABAgQIECBAIJ2AACqdpUoECBAgQIAAAQIECBAgQIAAAQI5AgKoHBSHCBAgQIAAAQIECBAgQIAAAQIE0gkIoNJZqkSAAAECBAgQIECAAAECBAgQIJAjIIDKQXGIAAECBAgQIECAAAECBAgQIEAgnYAAKp2lSgQIECBAgAABAgQIECBAgAABAjkCAqgcFIcIECBAgAABAgQIECBAgAABAgTSCQig0lmqRIAAAQIECBAgQIAAAQIECBAgkCMggMpBcYgAAQIECBAgQIAAAQIECBAgQCCdgAAqnaVKBAgQIECAAAECBAgQIECAAAECOQICqBwUhwgQIECAAAECBAgQIECAAAECBNIJCKDSWapEgAABAgQIECBAgAABAgQIECCQIyCAykFxiAABAgQIECBAgAABAgQIECBAIJ2AACqdpUoECBAgQIAAAQIECBAgQIAAAQI5AgKoHBSHCBAgQIAAAQIECBAgQIAAAQIE0gkIoNJZqkSAAAECBAgQIECAAAECBAgQIJAjIIDKQXGIAAECBAgQIECAAAECBAgQIEAgncD/Ac2ov5LukAsxAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a potential drawback.  If we significantly expand the dimension of the problem, we might increase the computational burden.  For example, if $x$ has dimension $d = 256$ and we wanted to use all fourth order terms, then $z = \\phi(x)$ has dimension 183,181,376.  What saves us is two observations.  First, many classifiers do not require that we know the values of the individual points but, rather, just the inner product between pairs of points.  Second, notice in our example that the inner product in $\\mathcal{Z}$ can be written\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\langle z, \\tilde{z} \\rangle &= \\langle \\phi(x), \\phi(\\tilde{x}) \\rangle \\\\\n",
    "&= x_1^2 \\tilde{x}_1^2 + 2 x_1 \\tilde{x_1} x_2 \\tilde{x}_2 + x_2^2 \\tilde{x}_2^2 \\\\\n",
    "&= ( \\langle x, \\tilde{x} \\rangle )^2 \\\\\n",
    "&\\equiv K(x, \\tilde{x})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Thus, we can compute $\\langle z, \\tilde{z} \\rangle$ without ever computing $Z_i = \\phi(X_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, kernelization means finding a mapping $\\phi: \\mathcal{X} \\rightarrow \\mathcal{Z}$ such that:\n",
    "\n",
    "1. $\\mathcal{Z}$ has higher dimension that $\\mathcal{X}$ and so leads to a richer set of classifiers.\n",
    "\n",
    "2. The classifier only requires computing inner products.\n",
    "\n",
    "3. There is a function $K$, called a kernel, such that $\\langle \\phi(x), \\phi(\\tilde{x}) \\rangle = K(x, \\tilde{x})$\n",
    "\n",
    "Then, everywhere the term $\\langle x, \\tilde{x} \\rangle$ appears in the algorithm, replace it with $K(x, \\tilde{x})$.\n",
    "\n",
    "In fact, we never need to construct the mapping $\\phi$ at all.  We only need to specify a kernel $K(x, \\tilde{x})$ that corresponds to $\\langle \\phi(x), \\phi(\\tilde{x}) \\rangle$ for some $\\phi$.  This raises an interesting question:  given a function of two variables $K(x, y)$, does exist a function $\\phi(x)$ such that $K(x, y) = \\langle \\phi(x), \\phi(\\tilde{x}) \\rangle$ ?  The answer is provided by **Mercer's theorem** which says, roughly, that if $K$ is positive definite -- meaning that\n",
    "\n",
    "$$ \\int \\int K(x, y) f(x) f(y) dx dy \\geq 0 $$\n",
    "\n",
    "for square integrable functions $f$ -- then such a $\\phi$ exists.  Examples of commonly used kernels are:\n",
    "\n",
    "- polynomial: $K(x, \\tilde{x}) = (\\langle x, \\tilde{x} \\rangle + a)^r$\n",
    "- sigmoid: $K(x, \\tilde{x}) = \\text{tanh} (a \\langle x, \\tilde{x} \\rangle + b)$\n",
    "- Gaussian: $K(x, \\tilde{x}) = -\\exp \\left( - \\Vert x - \\tilde{x} \\Vert^2 / (2 \\sigma^2) \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now see how we can use this trick in LDA and in support vector machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the Fisher linear discriminant method replaces $X$ with $U = w^T X$ where $w$ is chosen to maximize the Rayleigh coefficient\n",
    "\n",
    "$$ J(w) = \\frac{w^T S_B w}{w^T S_W w} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ S_B = (\\overline{X}_0 - \\overline{X}_1)(\\overline{X}_0 - \\overline{X}_1)^T $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ S_W = \\left( \\frac{(n_0 - 1) S_0}{(n_0 - 1) + (n_1 - 1)} \\right) + \\left( \\frac{(n_1 - 1) S_1}{(n_0 - 1) + (n_1 - 1)} \\right) $$\n",
    "\n",
    "In the kernelized version, we replace $X_i$ with $Z_i = \\phi(X_i)$ and find $w$ to maximize\n",
    "\n",
    "$$ J(w) = \\frac{w^T S_B w}{w^T S_W w} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ S_B = (\\overline{Z}_0 - \\overline{Z}_1)(\\overline{Z}_0 - \\overline{Z}_1)^T $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ S_W = \\left( \\frac{(n_0 - 1) \\tilde{S}_0}{(n_0 - 1) + (n_1 - 1)} \\right) + \\left( \\frac{(n_1 - 1) \\tilde{S}_1}{(n_0 - 1) + (n_1 - 1)} \\right) $$\n",
    "\n",
    "Here, $\\tilde{S}_j$ is the sample covariance of the $Z_i$'s for which $Y_i = j$.  However, to take advantage of kernelization, we need to reexpress this in terms of inner products and then replace the inner products with kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown that the maximizing vector $w$ is a linear combination of the $Z_i$'s.  Then we can write\n",
    "\n",
    "$$ w = \\sum_{i=1}^n \\alpha_i Z_i $$\n",
    "\n",
    "Also,\n",
    "\n",
    "$$ \\overline{Z}_j = \\frac{1}{n_j} \\sum_{i=1}^n \\phi(X_i) I(Y_i = j) $$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "w^T \\overline{Z}_j &= \\left( \\sum_{i=1}^n \\alpha_i Z_i \\right)^T \\left( \\frac{1}{n_j} \\sum_{i=1}^n \\phi(X_i) I(Y_i = j) \\right) \\\\\n",
    "&= \\frac{1}{n_j} \\sum_{i=1}^n \\sum_{s=1}^n \\alpha_i I(Y_s = j) Z_i^T Z_s \\\\\n",
    "&= \\frac{1}{n_j} \\sum_{i=1}^n \\alpha_i \\sum_{s=1}^n I(Y_s = j) \\phi(X_i)^T \\phi(X_s) \\\\\n",
    "&= \\frac{1}{n_j} \\sum_{i=1}^n \\alpha_i \\sum_{s=1}^n I(Y_s = j) K(X_i, X_s) \\\\\n",
    "&= \\alpha^T M_j\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $M_j$ is a vector whose $i$-th component is\n",
    "\n",
    "$$ M_j(i) = \\frac{1}{n_j} \\sum_{s=1}^n K(X_i, X_s) I(Y_s = j) $$\n",
    "\n",
    "It follows that\n",
    "\n",
    "$$ w^T \\tilde{S}_B w = \\alpha^T M \\alpha $$\n",
    "\n",
    "where $M = (M_0 - M_1)(M_0 - M_1)^T$.  By similar calculations, we can write\n",
    "\n",
    "$$ w^T \\tilde{S}_W w = \\alpha^T N \\alpha $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ N = K_0\\left( I - \\frac{1}{n_0}\\mathbf{1}\\right) K_0^T + K_1\\left( I - \\frac{1}{n_1}\\mathbf{1}\\right) K_1^T$$\n",
    "\n",
    "$I$ is the identity matrix, $\\mathbf{1}$ is a matrix of all 1s, and $K_j$ is the $n \\times n_j$ matrix with entries $(K_j)_{rs} = K(x_r, x_s)$ with $x_s$ varying over the observations in group $j$.  Hence, we now find $\\alpha$ to maximize\n",
    "\n",
    "$$ J(\\alpha) = \\frac{\\alpha^T M \\alpha}{\\alpha^T N \\alpha} $$\n",
    "\n",
    "Notice that all the quantities are expressed in terms of the kernel.  Formally, the solution is $\\alpha = N^{-1}(M_0 - M_1)$.  However, $N$ might be non-invertible.  In this case, one replaces $N$ by $N + bI$ for some constant $b$.  Finally, the projection onto the new subspace can be written as\n",
    "\n",
    "$$ U = w^T \\phi(x) = \\sum_{i=1}^N \\alpha_i K(x_i, x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector machine can be similarly kernelized.  We simply replace $\\langle X_i, X_j \\rangle$ with $K(X_i, X_j)$.  The hyperplane can be written as $\\hat{H}(X) = \\hat{\\alpha}_0 + \\sum_{i=1}^n \\hat{\\alpha}_i Y_i K(X, X_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.11 Other Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other classifiers and space precludes a full discussion of them.  Let us briefly mention a few.\n",
    "\n",
    "The **k-nearest neighbors** classifier is very simple.  Given a point $x$, find the $k$ data points closest to $x$.  Classify $x$ using the majority vote of these $k$ neighbors.  Ties can be broken randomly; the parameter $k$ can be chosen by cross-validation.\n",
    "\n",
    "**Bagging** is a method for reducing the variability of a classifier.  It is most helpful for highly non-linear classifiers such as a tree.  We draw $B$ bootstrap samples from the data.  The $b$-th bootstrap sample yields a classifier $h_b$.  The final classifier is\n",
    "\n",
    "$$ \n",
    "\\hat{x} = \\begin{cases}\n",
    "1 & \\text{if } \\frac{1}{B} \\sum_{b=1}^B h_b(x) \\geq \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Boosting** is a method for starting with a simple classifier and gradually improving it by refitting the data giving higher weight to misclassified samples.  Suppose that $\\mathcal{H}$ is a collection of classifiers, for example, trees with only one split.  Assume that $Y_i \\in \\{ -1, 1 \\}$ and that each tree classifier $h$ is such that $h(x) \\in \\{ -1, 1 \\}$.  We usually give equal weight to all data points in the methods we have discussed.  But one can incorporate unequal weights quite easily in most algorithms.  For example, in constructing a tree, we could replace the impurity measure with a weighted impurity measure.  The original version of boosting, called AdaBoost, is as follows.\n",
    "\n",
    "1. Set the weights $w_i = 1 / n$, $i = 1, \\dots, n$.\n",
    "\n",
    "2. For $j = 1, \\dots, J$, do the following steps:\n",
    "\n",
    "    (a) Construct a classifier $h_J$ from the data using weights $w_1, \\dots, w_n$.\n",
    "    \n",
    "    (b) Compute the weighted error estimate:\n",
    "    \n",
    "    $$ \\hat{L}_j = \\frac{\\sum_{i=1}^n w_i I(Y_i \\neq h_j(X_i) }{\\sum_{i=1}^n w_i} $$\n",
    "    \n",
    "    (c) Let $\\alpha_j = \\log (( 1 - \\hat{L}_j) / \\hat{L}_j)$\n",
    "    \n",
    "    (d) Update the weights:\n",
    "    \n",
    "    $$ w_i \\leftarrow w_i e^{\\alpha_j I(Y_i \\neq h_j(X_i)} $$\n",
    "    \n",
    "3. The final classifier is\n",
    "\n",
    "    $$ \\hat{h}(x) = \\text{sign} \\left( \\sum_{j=1}^J \\alpha_j h_j(x) \\right) $$\n",
    "    \n",
    "There is an enormous literature trying to explain and improve on boosting.  Whereas bagging is a variance reduction technique,  boosting can be thought of as a bias reduction technique.  We starting with a simple -- and hence highly biased -- classifier, and we gradually reduce the bias.  The disadvantage of boosting is that the  final classifier is quite complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.13 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 23.13.1**.  Prove Theorem 23.5.\n",
    "\n",
    "The Bayes rule is optimal, that is, if $h$ is any classification rule then $L(h^*) \\leq L(h)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
