{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of predicting a discrete variable $Y$ from another random variable $X$ is called **classfication**, **supervised learning**, **discrimination** or **pattern recognition**.\n",
    "\n",
    "In more detail, consider IID data $(X_1, Y_1), \\dots, (X_n, Y_n)$ where\n",
    "\n",
    "$$ X_i = (X_{i1}, \\dots, X_{id}) \\in \\mathcal{X} \\subset \\mathbb{R}^d $$\n",
    "\n",
    "is a $d$-dimensional vector and $Y_i$ takes values in some finite set $\\mathcal{Y}$.  A **classification rule** is a function $h : \\mathcal{X} \\rightarrow \\mathcal{Y} $.  When we observe a new $X$, we predict $Y$ to be $h(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth revisiting the vocabulary:\n",
    "\n",
    "| Statistics     | Computer Science    | Meaning                                      |\n",
    "|----------------|---------------------|----------------------------------------------|\n",
    "| classification | supervised learning | predicting a discrete $Y$ from $X$           |\n",
    "| data           | training sample     | $(X_1, Y_1), \\dots, (X_n, Y_n)$              |\n",
    "| covariates     | features            | the $X_i$'s                                  |\n",
    "| classifier     | hypothesis          | map $h: \\mathcal{X} \\rightarrow \\mathcal{Y}$ |\n",
    "| estimation     | learning            | finding a good classifier                    |\n",
    "\n",
    "In most cases with this chapter, we deal with the case $\\mathcal{Y} = \\{ 0, 1 \\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.2 Error Rates and The Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **true error rate** of a classifier is \n",
    "\n",
    "$$ L(h) = \\mathbb{P}( \\{ h(X) \\neq Y\\} ) $$\n",
    "\n",
    "and the **empirical error rate** or **training error rate** is\n",
    "\n",
    "$$ \\hat{L}_n(h) = \\frac{1}{n} \\sum_{i=1}^n I(h(X_i) \\neq Y_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the special case where $\\mathcal{Y} = \\{0, 1\\}$.  Let\n",
    "\n",
    "$$ r(x) = \\frac{\\pi f_1(x)}{\\pi f_1(x) + (1 - \\pi) f_0(x)} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ f_0(x) = f(x | Y = 0)\n",
    "\\quad \\text{and} \\quad\n",
    "f_1(x) = f(x | Y = 1)$$\n",
    "\n",
    "and $\\pi = \\mathbb{P}(Y = 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Bayes classification rule** $h^*$ is defined to be\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } r(x) > \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The set $\\mathcal{D}(h) = \\{ x : \\mathbb{P}(Y = 1 | X = x) = \\mathbb{P}(Y = 0 | X = x) \\}$ is called the **decision boundary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the Bayes rule has nothing to do with Bayesian inference.  We could estimate the Bayes rule using either frequentist or Bayesian methods.\n",
    "\n",
    "The Bayes rule may be written in several different forms:\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } \\mathbb{P}(Y = 1 | X = x) > \\mathbb{P}(Y = 0 | X  = x)\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } \\pi f_1(x) > (1 - \\pi) f_0(x) \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.5**.  The Bayes rule is optimal, that is, if $h$ is any classification rule then $L(h^*) \\leq L(h)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes rule depends on unknown quantities so we need to use the data to find some approximation to the Bayes rule.  At the risk of oversimplifying, there are three main approaches:\n",
    "\n",
    "1. **Empirical Risk Maximization**.  Choose a set of classifiers $\\mathcal{H}$ and find $\\hat{h} \\in \\mathcal{H}$ that minimizes some estimate of $L(h)$.\n",
    "\n",
    "2. **Regression**.  Find an estimate $\\hat{r}$ of the regression function $r$ and define\n",
    "\n",
    "$$ \n",
    "\\hat{h}(x) = \\begin{cases}\n",
    "1 & \\text{if } \\hat{r} > \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "3. **Density Estimation**.  Estimate $f_0$ from the $X_i$'s for which $Y_i = 0$, estimate $f_1$ from the $X_i$'s for which $Y_i = 1$, and let $\\hat{\\pi} = n^{-1} \\sum_{i=1}^n Y_i$.  Define\n",
    "\n",
    "$$ \\hat{r}(x) = \\hat{\\mathbb{P}}(Y = 1 | X = x) = \\frac{\\hat{\\pi} \\hat{f}_1(x)}{\\hat{\\pi} \\hat{f}_1(x) + (1 - \\hat{\\pi}) \\hat{f}_0(x)} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \n",
    "\\hat{h}(x) = \\begin{cases}\n",
    "1 & \\text{if } \\hat{r} > \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to generalize to the case where $Y$ takes more than two values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.6**.  Suppose that $Y \\in \\mathcal{Y} = \\{ 1, \\dots, K \\}$.  The optimal rule is\n",
    "\n",
    "$$ h(x) = \\text{argmax}_h \\mathbb{P}(Y = k | X = x) = \\text{argmax}_h \\pi_k f_k(x) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\mathbb{P}(Y = k | X = x) = \\frac{f_k(x) \\pi_k}{\\sum_r f_r(x) \\pi_r} $$\n",
    "\n",
    "and $ \\pi_r = \\mathbb{P}(Y = r)$, $f_r(x) = f(x | Y = r)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.3 Gaussian and Linear Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the simplest approach to classification is to use the density estimation strategy and assume a parametric model for the densities.  Suppose that $\\mathcal{Y} = \\{ 0, 1 \\}$ and that $f_0(x) = f(x | Y = 0)$ and $f_1(x) = f(x | Y = 1)$ are both multivariate Gaussians:\n",
    "\n",
    "$$ f_k(x) = \\frac{1}{(2\\pi)^{d/2} | \\Sigma_k |^{1/2}} \\exp \\left\\{ -\\frac{1}{2} (x - \\mu_k)^T \\Sigma_k^{-1} (x - \\mu_k) \\right\\}, \\quad k = 0, 1$$\n",
    "\n",
    "Thus, $X | Y = 0 \\sim N(\\mu_0, \\Sigma_0)$ and $X | Y = 1 \\sim N(\\mu_1, \\Sigma_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.7**.  If $X | Y = 0 \\sim N(\\mu_0, \\Sigma_0)$ and $X | Y = 1 \\sim N(\\mu_1, \\Sigma_1)$, then the Bayes rule is\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } r_1^2 < r_0^2 + 2 \\log \\left( \\frac{\\pi_1}{\\pi_0} \\right) + \\log \\left( \\frac{| \\Sigma_0 | }{ | \\Sigma_1| }\n",
    "\\right) \\\\\n",
    "0 & \\text{otherwise} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ r_i^2 = (x - \\mu_i)^T \\Sigma_i^{-1}(x - \\mu_i), \\quad i = 1, 2 $$\n",
    "\n",
    "is the **Manalahobis distance**.  An equivalent way of expressing Bayes' rule is \n",
    "\n",
    "$$ h(x) = \\text{argmax}_k \\delta_k(x) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\delta_k(x) = -\\frac{1}{2} \\log | \\Sigma_k | - \\frac{1}{2} (x - \\mu_k)^T \\Sigma_k^{-1} (x - \\mu_k) + \\log \\pi_k $$\n",
    "\n",
    "and $|A|$ denotes the determinant of matrix $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary of the above classifier is quadratic so this procedure is often called **quadratic discriminant analysis (QDA)**.  In practice, we use sample estimates of $\\pi, \\mu_0, \\mu_1, \\Sigma_0, \\Sigma_1$ in place of the true value, namely:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "\\hat{\\pi}_0 = \\frac{1}{n} \\sum_{i=1}^n (1 - Y_i) & \\hat{\\pi}_1 = \\frac{1}{n} \\sum_{i=1}^n Y_i \\\\\n",
    "\\hat{\\mu}_0 = \\frac{1}{n_0} \\sum_{i: Y_i = 0} X_i & \\hat{\\mu}_1 = \\frac{1}{n_0} \\sum_{i: Y_i = 1} X_i \\\\\n",
    "S_0 = \\frac{1}{n_0} \\sum_{i: Y_i = 0} (X_i - \\hat{\\mu}_0) (X_i - \\hat{\\mu}_0)^T & \n",
    "S_1 = \\frac{1}{n_1} \\sum_{i: Y_i = 1} (X_i - \\hat{\\mu}_1) (X_i - \\hat{\\mu}_1)^T\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $n_0 = \\sum_i (1 - Y_i)$ and $n_1 = \\sum_i Y_i$ are the number of $Y_i$ variables equal to 0 or 1, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simplification occurs if we assume $\\Sigma_0 = \\Sigma_1 = \\Sigma$.  In that case, the Bayes rule is\n",
    "\n",
    "$$ h(x) = \\text{argmax}_k \\delta_k(x) $$\n",
    "\n",
    "where now\n",
    "\n",
    "$$ \\delta_k(x) = x^T \\Sigma^{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\Sigma^{-1} \\mu_k + \\log \\pi_k $$\n",
    "\n",
    "The parameters are estimated as before, except the MLE of $\\Sigma$ now is\n",
    "\n",
    "$$ S = \\frac{n_0 S_0 + n_1 S_1}{n_0 + n_1} $$\n",
    "\n",
    "The classification rule is\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 &\\text{if } \\delta_1(x) > \\delta_0(x) \\\\\n",
    "0 &\\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\delta_j(x) = x^T S \\hat{\\mu}_j - \\frac{1}{2} \\hat{\\mu}_j^T S^{-1} \\hat{\\mu}_j + \\log \\hat{\\pi}_j $$\n",
    "\n",
    "is called the **discriminant function**.  The decision boundary $ \\{ x : \\delta_0(x) = \\delta_1(x) \\}$ is linear so this method is called **linear discrimination analysis (LDA)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generalize to the case where $Y$ takes on more than two values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.9**.  Suppose that $Y \\in \\{ 1, \\dots, K \\}$.  If $f_k(x) = f(x | Y = k)$ is Gaussian, the Bayes rule is\n",
    "\n",
    "$$ h(x) = \\text{argmax}_k \\delta_k(x) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\delta_k(x) = -\\frac{1}{2} \\log | \\Sigma_k | - \\frac{1}{2} (x - \\mu_k)^T \\Sigma_k^{-1} (x - \\mu_k) + \\log \\pi_k $$\n",
    "\n",
    "If the variances of the Gaussians are equal then\n",
    "\n",
    "$$ \\delta_k(x) = x^T \\Sigma_{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\Sigma^{-1} \\mu_k + \\log \\pi_k $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate $\\delta_k(x)$ by inserting estimates of $\\mu_k$, $\\Sigma_k$, and $\\pi_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another version of LDA due to Fisher.  The idea is to first reduce the dimension of the covariates to one dimension by projecting the data onto a line.  Algebraically, this means replacing the covariate $X = (X_1, \\dots, X_d)$ with a linear combination $U = w^T X = \\sum_{j=1}^d w_j X_j$.  The goal is to choose the vector $w = (w_1, \\dots, w_d)$ that \"best separates the data\".  Then we perform classification with the new covariate $U$ instead of $X$.\n",
    "\n",
    "We need to define what we mean by separation of the groups.  We would like the two groups to have means that are far apart relative to their spread.  Let $\\mu_j$ denote the mean of $X$ for $Y = j$ and let $\\Sigma$ be the variance matrix of $X$.  Then $\\mathbb{E}(U | Y = j) = \\mathbb{E}(w^T X | Y = j) = w^T \\mu_j$ and $\\mathbb{V}(U) = w^T \\Sigma w$.  Define the separation by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J(w) &= \\frac{(\\mathbb{E}(U | Y = 0) - \\mathbb{E}(U | Y = 1))^2}{w^T \\Sigma w} \\\\\n",
    "&= \\frac{(w^T \\mu_0 - w^T \\mu_1)^2}{w^T \\Sigma w} \\\\\n",
    "&= \\frac{w^T (\\mu_0 - \\mu_1)(\\mu_0 - \\mu_1)^T w}{w^T \\Sigma w}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "*The quantity $J$ arises in physics, where it is called the Rayleight coefficient.*\n",
    "\n",
    "We estimate $J$ as follows.  Let $n_j = \\sum_{i=1}^n I(Y_i = j)$ be the number of observations in group $j$, let $\\overline{X}_j = n_j^{-1} \\sum_{i: Y_i = j} X_j$ be the sample mean vetor of $X$'s for group $j$, and let $S_j = (n_j - 1)^{-1} \\sum_{i: Y_i = j} (X_i - \\overline{X}_j)(X_i - \\overline{X}_j)^T $ be the sample covariance matrix in group $j$.  Define\n",
    "\n",
    "$$ \\hat{J}(w) = \\frac{w^T S_B w}{w^T S_W w} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \n",
    "S_B = (\\overline{X}_0 - \\overline{X}_1) (\\overline{X}_0 - \\overline{X}_1)^T\n",
    "\\quad \\text{and} \\quad\n",
    "S_W = \\frac{(n_0 - 1) S_0 + (n_1 - 1) S_1}{(n_0 - 1) + (n_1 -1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.10**.  The vector\n",
    "\n",
    "$$ w = S_W^{-1}(\\overline{X}_0 - \\overline{X}_1) $$\n",
    "\n",
    "is a minimizer of $\\hat{J}(w)$.  We call\n",
    "\n",
    "$$ U = w^T X = (\\overline{X}_0 - \\overline{X}_1)^T S_W^{-1} X $$\n",
    "\n",
    "the **Fisher linear discriminant function**.  The midpoint $m$ between $\\overline{X}_0$ and $\\overline{X}_1$ is\n",
    "\n",
    "$$ m = \\frac{1}{2} (\\overline{X}_0 + \\overline{X}_1) = \\frac{1}{2}  (\\overline{X}_0 - \\overline{X}_1)^T S_B^{-1}  (\\overline{X}_0 + \\overline{X}_1)$$\n",
    "\n",
    "Fisher's classification rule is\n",
    "\n",
    "$$\n",
    "h(x) = \\begin{cases}\n",
    "0 & \\text{if } w^T X \\geq m \\\\\n",
    "1 & \\text{if } w^T X < m\n",
    "\\end{cases}\n",
    "= \\begin{cases}\n",
    "0 & \\text{if } (\\overline{X}_0 - \\overline{X}_1)^T S_W^{-1}x \\geq m \\\\\n",
    "1 & \\text{if } (\\overline{X}_0 - \\overline{X}_1)^T S_W^{-1}x < m\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Fisher's rule is the same as the Bayes linear classifier when $\\hat{\\pi} = 1/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.4 Linear Regression and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more direct approach to classification is to estimate the regression function $r(x) = \\mathbb{E}(Y | X = x)$ without bothering to estimate the densities $f_k$.  For the rest of this section we will only consider the case where $\\mathcal{Y} = \\{ 0, 1 \\}$.  Thus, $r(x) = \\mathbb{P}(Y = 1 | X = x)$ and once we have an estimate $\\hat{r}$, we will use the classification rule\n",
    "\n",
    "$$ \n",
    "h(x) = \\begin{cases}\n",
    "1 &\\text{if } \\hat{r}(x) > \\frac{1}{2} \\\\\n",
    "0 &\\text{otherwise}\n",
    "\\end{cases} \n",
    "$$\n",
    "\n",
    "The simplest regression is the linear regression model\n",
    "\n",
    "$$ Y = r(x) + \\epsilon = \\beta_0 + \\sum_{j=1}^d \\beta_j X_j + \\epsilon $$\n",
    "\n",
    "where $\\mathbb{E}(\\epsilon) = 0$.  This model can't be correct since it doesn't force $Y \\in \\mathcal{Y}$.  Nonetheless, it can sometimes lead to a decent classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the least square estimate of $\\beta = (\\beta_0, \\beta_1, \\dots, \\beta_d)^T$ minimizes the residual sum of squares\n",
    "\n",
    "$$ \\text{RSS}(\\beta) = \\sum_{i=1}^n \\left( Y_i - \\left( \\beta_0  + \\sum_{j=1}^d X_{ij} \\beta_j \\right) \\right)^2 $$\n",
    "\n",
    "Briefly reviewing this estimator:  let\n",
    "\n",
    "$$ \n",
    "X = \\begin{bmatrix}\n",
    "1 & X_{11} & \\cdots & X_{1d} \\\\\n",
    "1 & X_{21} & \\cdots & X_{2d} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & X_{n1} & \\cdots & X_{nd}\n",
    "\\end{bmatrix}\n",
    "\\quad \\text{and} \\quad\n",
    "Y = (Y_1, \\dots, Y_n)^T\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$ \\text{RSS}(\\beta) = (Y - X \\beta)^T (Y - X \\beta) $$\n",
    "\n",
    "and the model can be written as\n",
    "\n",
    "$$ Y = X \\beta + \\epsilon $$\n",
    "\n",
    "where $ \\epsilon = (\\epsilon_1, \\dots, \\epsilon_n)^T$.  The least squares solution $\\hat{\\beta}$ that minimizes RSS is given by\n",
    "\n",
    "$$ \\hat{\\beta} = (X^T X)^{-1} X^T Y $$\n",
    "\n",
    "and the predicted values are\n",
    "\n",
    "$$ \\hat{Y} = X \\hat{\\beta} $$\n",
    "\n",
    "Now we can use $h(x)$ to classify, by taking $\\hat{r}(x) = \\hat{\\beta}_0 + \\sum_k \\hat{\\beta}_k x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems sensible to use a regression model that takes into account that $Y \\in \\{ 0, 1 \\}$.  The most common method for doing so is **logistic regression**.  Recall that the model is\n",
    "\n",
    "$$ r(x) = \\mathbb{P}(Y = 1 | X = x) = \\frac{\\exp \\left\\{ \\beta_0 + \\sum_j \\beta_j x_j \\right\\} }{1 + \\exp \\left\\{ \\beta_0 + \\sum_j \\beta_j x_j \\right\\} } $$\n",
    "\n",
    "We may write this as\n",
    "\n",
    "$$ \\text{logit} \\; \\mathbb{P}(Y = 1 | X = x) = \\beta_0 + \\sum_j \\beta_j x_j $$\n",
    "\n",
    "where $\\text{logit}(a) = \\log (a / (1 - a))$.  Under this model, each $Y_i$ is a Bernoulli with success probability\n",
    "\n",
    "$$ p_i(\\beta) = \\frac{\\exp \\left\\{ \\beta_0 + \\sum_j \\beta_j X_{ij} \\right\\} }{1 + \\exp \\left\\{ \\beta_0 + \\sum_j \\beta_j X_{ij} \\right\\} } $$\n",
    "\n",
    "The likelihood function for the data set is\n",
    "\n",
    "$$ \\mathcal{L}(\\beta) = \\prod_{i=1}^n p_i(\\beta)^{Y_i} (1 - p_i(\\beta))^{1 - Y_i}$$\n",
    "\n",
    "We obtain the MLE numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a better classifier by fitting a richer model.  For example we could fit\n",
    "\n",
    "$$ \\text{logit} \\; \\mathbb{P}(Y = 1 | X = x) = \\beta_0 + \\sum_j \\beta_j x_j + \\sum_{j, k} \\beta_{jk} x_j x_k $$\n",
    "\n",
    "More generally, we could add terms of up to order $r$ for some integer $r$.  Large values of $r$ give a more complicated model which should fit the data better.  But there is a bias-variance tradeoff which we'll discuss later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression can be easily extend to $k$ groups but we shall not give the details here.\n",
    "\n",
    "*(Student note: multiple treatments are easily found searching for \"multinomial logistic regression\")*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.5  Relationship Between Logistic Regression and LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA and logistic regression are almost the same thing.  \n",
    "\n",
    "If we assume each group is Gaussian with the same covariance matrix then\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\log \\left( \\frac{\\mathbb{P}(Y = 1 | X = x)}{\\mathbb{P}(Y = 0 | X = x)} \\right) \n",
    "&= \\log \\left( \\frac{\\pi_0}{\\pi_1} \\right) - \\frac{1}{2} (\\mu_0 + \\mu_1)^T \\Sigma^{-1} (\\mu_1 - \\mu_0) + x^T \\Sigma^{-1}( \\mu_1 - \\mu_0) \\\\\n",
    "&\\equiv \\alpha_0 + \\alpha^T x\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "On the other hand, the logistic model is, by assumption,\n",
    "\n",
    "$$ \\log \\left( \\frac{\\mathbb{P}(Y = 1 | X = x)}{\\mathbb{P}(Y = 0 | X = x)} \\right) = \\beta_0 + \\beta^T x $$\n",
    "\n",
    "These are the same model since they both lead to classification rules that are linear in $x$.  The difference is in how we estimate the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint density of a single observation is $f(x, y) = f(x | y) f(y) = f(y | x) f(x)$.  In LDA we estimated the whole distribution by estimating $f(x | y)$ and $f(y)$; specifically, we estimated $f_k(x) = f(x | Y = k)$, $\\pi_k = f_Y(k)$.  We maximized the likelihood\n",
    "\n",
    "$$ \\prod_i f(x_i, y_i) = \\underbrace{\\prod_i f(x_i | y_i)}_\\text{Gaussian} \\underbrace{ \\prod_i f(y_i) }_\\text{Bernoulli}$$\n",
    "\n",
    "In logistic regression, we maximized the conditional likelihood $\\prod_i f(y_i | x_i)$ but we ignored the second term $f(x_i)$:\n",
    "\n",
    "$$ \\prod_i f(x_i, y_i) = \\underbrace{\\prod_i f(y_i | x_i)}_\\text{logistic} \\underbrace{ \\prod_i f(x_i) }_\\text{ignored}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since classification requires only knowing $f(y | x)$, we don't really need to estimate the whole joint distribution.  Logistic regression leaves the marginal distribution $f(x)$ unspecified so it is more nonparametric than LDA.\n",
    "\n",
    "To summarize:  LDA and logistic regression both lead to a linear classification rule.  In LDA we estimate the whole joint distribution $f(x, y) = f(x | y) f(y)$.  In logistic regression we only estimate $f(y | x)$ and we don't bother estimating $f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.6 Density Estimation and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the Bayes rule is $h(x) = \\text{argmax}_k \\pi_k f_k(x)$.  If we can estimate $\\pi_k$ and $f_k$ then we can estimate the Bayes classification rule.  Estimating $\\pi_k$ is easy, but what about $f_k$? We did it previously by assuming $f_k$ was Gaussian.  Another strategy is to estimate $f_k$ with some nonparametric density estimator $\\hat{f}_k$ such as a kernel estimator.  But if $x = (x_1, \\dots, x_d)$ is high dimensional, nonparametric density estimation is not very reliable.  The problem is ameliorated if we assume that $X_1, \\dots, X_d$ are independent, for then $f_k(x_1, \\dots, x_d) = \\prod_{j=1}^d f_{kj}(x_j)$.  This reduces the problem to $d$ one-dimensional density estimation problems, within each of the $k$ groups.  The resulting classifier is called the **naive Bayes classifier**.  The assumption that the components of $X$ are independent is usually wrong yet the resulting classifier might still be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes Classifier**\n",
    "\n",
    "1.  For each group $k$, compute an estimate $\\hat{f}_{kj}$ of the density $f_{kj}$ for $X_j$, using the data for which $Y_i = k$.\n",
    "\n",
    "2.  Let\n",
    "\n",
    "$$ \\hat{f}_k(x) = \\hat{f}_k(x_1, \\dots, x_d) = \\prod_{j=1}^d \\hat{f}_{kj}(x_j) $$\n",
    "\n",
    "3. Let\n",
    "\n",
    "$$ \\hat{\\pi}_k = \\frac{1}{n} \\sum_{i=1}^n I(Y_i = k) $$\n",
    "\n",
    "where $I(t) = 1$ if $t$ and $I(t) = 0$ otherwise.\n",
    "\n",
    "4. Let\n",
    "\n",
    "$$ h(x) = \\text{argmax}_k \\hat{\\pi}_k \\hat{f}_k(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive Bayes classifier is especially popular when $x$ is high dimensional and discrete.  In that case, $\\hat{f}_{kj}(x_k)$ is especially simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.7 Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees are classification methods that partition the covariate space $\\mathcal{X}$ into disjoint pieces and then classify the observations according to which partition element they fall in.  As the name implies, the classifier can be represented as a tree.\n",
    "\n",
    "Here is how a tree is constructed.  For simplicity, we focus on the case where $\\mathcal{Y} = \\{ 0, 1 \\}$.  First, suppose there is a single covariate $X$.  We choose a split point $t$ that divides the real line into two sets, $A_1 = (-\\infty, t]$ and $A_2 = (t, \\infty)$.  Let $\\hat{p}_s(j)$ be the proportion of observations in $A_s$ such that $Y_i = j$:\n",
    "\n",
    "$$ \\hat{p}_s(j) = \\frac{\\sum_{i=1}^n I(Y_i = j, X_i \\in A_s)}{\\sum_{i=1}^n I(X_i \\in A_s)} $$\n",
    "\n",
    "for $s = 1, 2$ and $j = 0, 1$.  The **impurity** of the split $t$ is defined to be\n",
    "\n",
    "$$ I(t) = \\sum_{s=1}^2 \\gamma_s $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\gamma_s = 1 - \\sum_{j=0}^1 \\hat{p}_s(j)^2 $$\n",
    "\n",
    "This measure of impurity is known as the **Gini index**.  If a partition element $A_s$ contains all 0s or all 1s, then $\\gamma_s = 0$.  Otherwise, $\\gamma_s > 0$.  We choose the split point $t$ to minimize the impurity.  (Other indices of impurity may be used besides the Gini index.)\n",
    "\n",
    "When there are several covariates, we choose whatever covariate and split that leads to the lowest impurity.  This process is continued until some stopping criteria is met.  For example, we might stop when every partition element has fewer than $n_0$ data points, where $n_0$ is some fixed number.  The bottom nodes of the tree are called **leaves**.  Each leaf is assigned a 0 or 1 depending on whether there are more data points with $Y = 0$ or $Y = 1$ in the partition element.\n",
    "\n",
    "This procedure is easily generalized to the multiclass case, $\\mathcal{Y} = \\{ 1, \\dots, K \\}$.  We simply define the impurity by\n",
    "\n",
    "$$ \\gamma_s = 1 - \\sum_{j=1}^K \\hat{p}_s(j)^2 $$\n",
    "\n",
    "where $\\hat{p}_s(j)$ is the proportion of observations in the partition element for which $Y = j$.\n",
    "\n",
    "Our description of how to build trees is incomplete.  If we keep splitting until there are few cases in each leaf of the tree, we are likely to overfit the data.  We should choose the complexity of the tree in such a way that the estimated true error rate is low.  In the next section, we discuss estimation of the error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.8 Assessing Error Rates and Choosing a Good Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to have a classifier $h$ with a low true error rate $L(h)$.  Usually, we can't use the training error rate $\\hat{L}_n(h)$ as an estimate of the true error rate because it is biased downward.\n",
    "\n",
    "There are many ways to estimate the error rate.  We'll consider two:  **cross-validation** and **probability inequalities**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "The basic idea of cross-validation is to leave out some of the data when fitting a model.  The simplest version involves randomly splitting the data into two pieces: the **training set $\\mathcal{T}$** and the **validation set $\\mathcal{V}$**.  Often, about 10 percent of the data might be set aside as the validation set.  The classifier $h$ is constructed from the training set.  We then estimate the error by\n",
    "\n",
    "$$ \\hat{L}(h) = \\frac{1}{m} \\sum_{X_i \\in \\mathcal{V}} I(h(X_i) \\neq Y_i) $$\n",
    "\n",
    "where $m$ is the size of the validation set.\n",
    "\n",
    "Another approach to cross-validation is **K-fold cross-validation** which is obtained as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-fold cross-validation**\n",
    "\n",
    "1.  Randomly divide the data into $K$ chunks of approximately equal size.  A common choice is $K = 10$.\n",
    "\n",
    "2.  For $k = 1$ to $K$ do the following:\n",
    "\n",
    "   (a) Delete chunk $k$ from the data.\n",
    "   \n",
    "   (b) Compute the classifier $\\hat{h}_{(k)}$ from the rest of the data.\n",
    "   \n",
    "   (c) Use $\\hat{h}_{(k)}$ to predict the data in chunk $k$.  Let $\\hat{L}_{(k)}$ denote the observed error rate.\n",
    "   \n",
    "3. Let\n",
    "\n",
    "$$ \\hat{L}(h) = \\frac{1}{K} \\sum_{k=1}^K \\hat{L}_{(k)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation can be applied to any classification method.  To apply it to trees, one begins by fitting an initial tree.  Smaller trees are obtained by pruning tree.  We can do this for trees of various sizes, where size refers to the number of terminal nodes on the tree.  Cross-validation is then used to estimate error rate as a function of tree size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Inequalities\n",
    "\n",
    "Another approach to estimating the error rate is to find a confidence interval for $\\hat{L}_n(h)$ using probability inequalities.  This method is useful in the context of **empirical risk estimation**.\n",
    "\n",
    "Let $\\mathcal{H}$ be a set of classifiers, for example, all linear classifiers.  Empirical risk minimization means choosing the classifier $\\hat{h} \\in \\mathcal{H}$ to minimize the training error $\\hat{L}_n(h)$, also called the empirical risk.  Thus,\n",
    "\n",
    "$$ \\hat{h} = \\text{argmin}_{h \\in \\mathcal{H}} \\hat{L}_n(h) \n",
    "= \\text{argmin}_{h \\in \\mathcal{H}} \\left( \\frac{1}{n} \\sum_i I(h(X_i) \\neq Y_i) \\right) $$\n",
    "\n",
    "Typically, $\\hat{L}_n(\\hat{h})$ underestimates the true error rate $L(\\hat{h})$ because $\\hat{h}$ was chosen to minimize $\\hat{L}_n(\\hat{h})$.  Our goal is to assess how much underestimation is taking place.  Our main tool for this analysis is **Hoeffding's inequality**.  Recall that if $X_1, \\dots, X_n \\sim \\text{Bernoulli}(p)$, then, for any $\\epsilon > 0$,\n",
    "\n",
    "$$ \\mathbb{P}(|\\hat{p} - p| > \\epsilon) \\leq 2 e^{ -2 n \\epsilon^2 } $$\n",
    "\n",
    "where $\\hat{p} = n^{-1} \\sum_{i=1}^n X_i$.\n",
    "\n",
    "First, suppose that $\\mathcal{H} = \\{ h_1, \\dots, h_m \\}$ consists of finitely many classifiers.  For any fixed $h$, $\\hat{L}_n(h)$ converges in almost surely to $L(h)$ by the law of large numbers.  We will now establish a stronger result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.16 (Uniform Convergence)**.  Assume $\\mathcal{H}$ is finite and has $m$ elements.  Then,\n",
    "\n",
    "$$ \\mathbb{P} \\left( \\max_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon \\right) \\leq 2 m e^{-2 n \\epsilon^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof**.  We will use Hoeffding's inequality and we will also use the fact that if $A_1, \\dots, A_m$ is a set of events then $\\mathbb{P}(\\bigcup_{i=1}^m A_i) \\leq \\sum_{i=1}^m \\mathbb{P}(A_i)$.  Now,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{P} \\left( \\max_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon \\right)\n",
    "&= \\mathbb{P} \\left( \\bigcup_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon \\right) \\\\\n",
    "& \\leq \\sum_{h \\in \\mathcal{H}} \\mathbb{P} \\left( |\\hat{L}_n(h) - L(h) | > \\epsilon \\right) \\\\\n",
    "& \\leq \\sum_{h \\in \\mathcal{H}} 2 e^{-2 n \\epsilon^2} = 2 m e^{-2 n \\epsilon^2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.17**.  Let\n",
    "\n",
    "$$ \\epsilon = \\sqrt{\\frac{2}{n} \\log \\left( \\frac{2m}{\\alpha} \\right) } $$\n",
    "\n",
    "Then $\\hat{L}_n(\\hat{h}) \\pm \\epsilon$ is a $1 - \\alpha$ confidence interval for $L(\\hat{h})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof**.  This follows from the fact that\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(|\\hat{L}_n(\\hat{h}) - L(\\hat{h})| > \\epsilon) \n",
    "\\leq \\mathbb{P}( \\max_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon )\n",
    "\\leq 2 m e^{-2 n \\epsilon^2} = \\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\mathcal{H}$ is large the confidence interval for $L(\\hat{h})$ is large.  The more functions there are in $\\mathcal{H}$ the more likely it is we have \"overfit\" which we compensate for by having a larger confidence interval.\n",
    "\n",
    "In practice, we usually use sets $\\mathcal{H}$ that are infinite, such as the set of linear classifiers.  To extend our analysis to these cases we want to be able to say something like\n",
    "\n",
    "$$ \\mathbb{P} \\left( \\sup_{h \\in \\mathcal{H}} |\\hat{L}_n(h) - L(h) | > \\epsilon \\right) \\leq \\text{something not too big} $$\n",
    "\n",
    "All the other results followed from this inequality.  One way to develop such a generalization is by way of the **Vapnik-Chervonenkis** or **VC dimension**.  We now consider the main ideas in VC theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathcal{A}$ be a class of sets.  Given a finite set $F = \\{ x_1, \\dots, x_n \\}$ let\n",
    "\n",
    "$$ N_\\mathcal{A}(F) = \\# \\Big\\{ F \\cap A : A \\in \\mathcal{A} \\Big\\} $$\n",
    "\n",
    "be the number of subsets F \"picked out\" by $\\mathcal{A}$.  Here $\\#(B)$ denotes the number of elements of set $B$.  The **shatter coefficient** is defined by\n",
    "\n",
    "$$ s(\\mathcal{A}, n) = \\max_{F \\in \\mathcal{F}_n} N_\\mathcal{A}(F) $$\n",
    "\n",
    "where $\\mathcal{F}_n$ consists of all finite sets of size $n$.  Now let $X_1, \\dots, X_n \\sim \\mathbb{P}$ and let\n",
    "\n",
    "$$ \\mathbb{P}_n(A) = \\frac{1}{n} \\sum_i I(X_i \\in A) $$\n",
    "\n",
    "denote the empirical probability measure.  The following remarkable theorem bounds the distance between $\\mathbb{P}$ and $\\mathbb{P}_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.18 (Vapnik and Chervonenkis (1971))**.  For any $\\mathbb{P}$, $n$, and $\\epsilon > 0$,\n",
    "\n",
    "$$ \\mathbb{P} \\left\\{ \\sup_{A \\in \\mathcal{A}} | \\mathbb{P}_n(A) - \\mathbb{P}(A) | > \\epsilon \\right\\} \\leq 8 s(\\mathcal{A}, n) e^{-n \\epsilon^2 / 32} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proof, though very elegant, is long and we omit it.  If $\\mathcal{H}$ is a set of classifiers, define $\\mathcal{A}$ to be the class of sets of the form $\\{ x : h(x) = 1 \\}$.  Then we define $s(\\mathcal{H}, n) = s(\\mathcal{A}, n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.19**.\n",
    "\n",
    "$$ \\mathbb{P} \\left\\{ \\sup_{h \\in \\mathcal{H}} | \\hat{L}_n(h) - L(h) | > \\epsilon \\right\\} \\leq 8 s(\\mathcal{H}, n) e^{-n \\epsilon^2 / 32} $$ \n",
    "\n",
    "A $1 - \\alpha$ confidence interval for $L(\\hat{h})$ is $\\hat{L}_n(\\hat{h}) \\pm \\epsilon_n$ where\n",
    "\n",
    "$$ \\epsilon_n^2 = \\frac{32}{n} \\log \\left( \\frac{8 s(\\mathcal{H}, n)}{\\alpha} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These theorems are only useful if the shatter coefficients do not grow too quickly with $n$.  This is where the VC dimension enters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **VC (Vapnik-Chervonenkis) dimension** of a class of sets $\\mathcal{A}$ is defined as follows.  If $s(\\mathcal{A}, n) = 2^n$ for all $n$ set $\\text{VC}(\\mathcal{A}) = \\infty$.  Otherwise, define $\\text{VC}(\\mathcal{A})$ to be the largest $k$ for which $s(\\mathcal{A}, n) = 2^k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the VC-dimension is the size of the largest finite set $F$ that can be **shattered by $\\mathcal{A}$**, meaning that $\\mathcal{A}$ picks out each subset of $F$.  If $\\mathcal{H}$ is a set of classifiers we define $\\text{VC}(\\mathcal{H}) = \\text{VC}(\\mathcal{A})$ where $\\mathcal{A}$ is the class of sets of the form $\\{ x : h(x) = 1 \\}$ as $h$ varies in $\\mathcal{H}$.  The following theorem shows that if $\\mathcal{A}$ has finite VC-dimension then the shatter coefficients grow as a polynomial in $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.21**.  If $\\mathcal{A}$ has finite VC-dimension $v$, then\n",
    "\n",
    "$$ s(\\mathcal{A}, n) \\leq n^v + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.26**.  Let $x$ have dimension $d$ and let $\\mathcal{H}$ be the set of linear classifiers.  The VC dimension of $\\mathcal{H}$ is $d + 1$.  Hence, a $1 - \\alpha$ confidence interval for the true error rate is $\\hat{L}(\\hat{h}) \\pm \\epsilon$ where\n",
    "\n",
    "$$ \\epsilon_n^2 = \\frac{32}{n} \\log \\left( \\frac{8 (n^{d + 1} + 1)}{\\alpha} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.9 Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
