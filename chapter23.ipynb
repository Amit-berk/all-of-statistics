{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of predicting a discrete variable $Y$ from another random variable $X$ is called **classfication**, **supervised learning**, **discrimination** or **pattern recognition**.\n",
    "\n",
    "In more detail, consider IID data $(X_1, Y_1), \\dots, (X_n, Y_n)$ where\n",
    "\n",
    "$$ X_i = (X_{i1}, \\dots, X_{id}) \\in \\mathcal{X} \\subset \\mathbb{R}^d $$\n",
    "\n",
    "is a $d$-dimensional vector and $Y_i$ takes values in some finite set $\\mathcal{Y}$.  A **classification rule** is a function $h : \\mathcal{X} \\rightarrow \\mathcal{Y} $.  When we observe a new $X$, we predict $Y$ to be $h(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth revisiting the vocabulary:\n",
    "\n",
    "| Statistics     | Computer Science    | Meaning                                      |\n",
    "|----------------|---------------------|----------------------------------------------|\n",
    "| classification | supervised learning | predicting a discrete $Y$ from $X$           |\n",
    "| data           | training sample     | $(X_1, Y_1), \\dots, (X_n, Y_n)$              |\n",
    "| covariates     | features            | the $X_i$'s                                  |\n",
    "| classifier     | hypothesis          | map $h: \\mathcal{X} \\rightarrow \\mathcal{Y}$ |\n",
    "| estimation     | learning            | finding a good classifier                    |\n",
    "\n",
    "In most cases with this chapter, we deal with the case $\\mathcal{Y} = \\{ 0, 1 \\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.2 Error Rates and The Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **true error rate** of a classifier is \n",
    "\n",
    "$$ L(h) = \\mathbb{P}( \\{ h(X) \\neq Y\\} ) $$\n",
    "\n",
    "and the **empirical error rate** or **training error rate** is\n",
    "\n",
    "$$ \\hat{L}_n(h) = \\frac{1}{n} \\sum_{i=1}^n I(h(X_i) \\neq Y_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the special case where $\\mathcal{Y} = \\{0, 1\\}$.  Let\n",
    "\n",
    "$$ r(x) = \\frac{\\pi f_1(x)}{\\pi f_1(x) + (1 - \\pi) f_0(x)} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ f_0(x) = f(x | Y = 0)\n",
    "\\quad \\text{and} \\quad\n",
    "f_1(x) = f(x | Y = 1)$$\n",
    "\n",
    "and $\\pi = \\mathbb{P}(Y = 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Bayes classification rule** $h^*$ is defined to be\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } r(x) > \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The set $\\mathcal{D}(h) = \\{ x : \\mathbb{P}(Y = 1 | X = x) = \\mathbb{P}(Y = 0 | X = x) \\}$ is called the **decision boundary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the Bayes rule has nothing to do with Bayesian inference.  We could estimate the Bayes rule using either frequentist or Bayesian methods.\n",
    "\n",
    "The Bayes rule may be written in several different forms:\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } \\mathbb{P}(Y = 1 | X = x) > \\mathbb{P}(Y = 0 | X  = x)\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "h^*(x) = \\begin{cases}\n",
    "1 & \\text{if } \\pi f_1(x) > (1 - \\pi) f_0(x) \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.5**.  The Bayes rule is optimal, that is, if $h$ is any classification rule then $L(h^*) \\leq L(h)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes rule depends on unknown quantities so we need to use the data to find some approximation to the Bayes rule.  At the risk of oversimplifying, there are three main approaches:\n",
    "\n",
    "1. **Empirical Risk Maximization**.  Choose a set of classifiers $\\mathcal{H}$ and find $\\hat{h} \\in \\mathcal{H}$ that minimizes some estimate of $L(h)$.\n",
    "\n",
    "2. **Regression**.  Find an estimate $\\hat{r}$ of the regression function $r$ and define\n",
    "\n",
    "$$ \n",
    "\\hat{h}(x) = \\begin{cases}\n",
    "1 & \\text{if } \\hat{r} > \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "3. **Density Estimation**.  Estimate $f_0$ from the $X_i$'s for which $Y_i = 0$, estimate $f_1$ from the $X_i$'s for which $Y_i = 1$, and let $\\hat{\\pi} = n^{-1} \\sum_{i=1}^n Y_i$.  Define\n",
    "\n",
    "$$ \\hat{r}(x) = \\hat{\\mathbb{P}}(Y = 1 | X = x) = \\frac{\\hat{\\pi} \\hat{f}_1(x)}{\\hat{\\pi} \\hat{f}_1(x) + (1 - \\hat{\\pi}) \\hat{f}_0(x)} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \n",
    "\\hat{h}(x) = \\begin{cases}\n",
    "1 & \\text{if } \\hat{r} > \\frac{1}{2} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to generalize to the case where $Y$ takes more than two values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 23.6**.  Suppose that $Y \\in \\mathcal{Y} = \\{ 1, \\dots, K \\}$.  The optimal rule is\n",
    "\n",
    "$$ h(x) = \\text{argmax}_h \\mathbb{P}(Y = k | X = x) = \\text{argmax}_h \\pi_k f_k(x) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\mathbb{P}(Y = k | X = x) = \\frac{f_k(x) \\pi_k}{\\sum_r f_r(x) \\pi_r} $$\n",
    "\n",
    "and $ \\pi_r = \\mathbb{P}(Y = r)$, $f_r(x) = f(x | Y = r)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
